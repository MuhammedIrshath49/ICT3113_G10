{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8e4733",
   "metadata": {
    "id": "bb8e4733"
   },
   "source": [
    "# Agent CFO — Performance Optimization & Design\n",
    "\n",
    "---\n",
    "This is the starter notebook for your project. Follow the required structure below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wkMIj4Ssetku",
   "metadata": {
    "id": "wkMIj4Ssetku"
   },
   "source": [
    "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
    "\n",
    "Your system must:\n",
    "*   Ingest the company’s public filings.\n",
    "*   Retrieve relevant passages efficiently.\n",
    "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
    "*   Produce answers with valid citations to the correct page/table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c138dd7",
   "metadata": {
    "id": "0c138dd7"
   },
   "source": [
    "## 1. Config & Secrets\n",
    "\n",
    "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a6098a4",
   "metadata": {
    "id": "8a6098a4",
    "ExecuteTime": {
     "end_time": "2025-09-30T08:50:18.571144Z",
     "start_time": "2025-09-30T08:50:18.481826300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Example:\n",
    "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
    "\n",
    "COMPANY_NAME = \"DBS Bank\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a81e9",
   "metadata": {
    "id": "8b7a81e9"
   },
   "source": [
    "## 2. Data Download (Dropbox)\n",
    "\n",
    "*   Annual Reports: last 3–5 years.\n",
    "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
    "*   Investor Presentations and Press Releases.\n",
    "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
    "*   Upload them under `/content/data/`.\n",
    "\n",
    "Scope limit: each team will ingest minimally 15 PDF files total.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4e754",
   "metadata": {
    "id": "b0d4e754"
   },
   "source": [
    "## 3. System Requirements\n",
    "\n",
    "**Retrieval & RAG**\n",
    "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
    "*   Citations must include: report name, year, page number, section/table.\n",
    "\n",
    "**Agentic Reasoning**\n",
    "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
    "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
    "\n",
    "**Instrumentation**\n",
    "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
    "*   Log: tokens used, cache hits, tools invoked.\n",
    "*   Record p50/p95 latencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e08f5a0",
   "metadata": {
    "id": "5e08f5a0",
    "ExecuteTime": {
     "end_time": "2025-09-30T08:50:48.547363700Z",
     "start_time": "2025-09-30T08:50:18.503222900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:__main__:Initialized CFO RAG Pipeline\n",
      "INFO:__main__:Extracted 30 text chunks from content\\data\\2Q22_performance_summary.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting document ingestion ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Extracted 31 text chunks from content\\data\\2Q23_performance_summary.pdf\n",
      "INFO:__main__:Extracted 33 text chunks from content\\data\\2Q24_performance_summary.pdf\n",
      "INFO:__main__:Extracted 34 text chunks from content\\data\\2Q25_performance_summary.pdf\n",
      "INFO:__main__:Extracted 44 text chunks from content\\data\\4Q22_performance_summary.pdf\n",
      "INFO:__main__:Extracted 43 text chunks from content\\data\\4Q23_performance_summary.pdf\n",
      "INFO:__main__:Extracted 45 text chunks from content\\data\\4Q24_performance_summary.pdf\n",
      "INFO:__main__:Extracted 115 text chunks from content\\data\\DBS Annual Report 2023.pdf\n",
      "INFO:__main__:Extracted 114 text chunks from content\\data\\dbs-annual-report-2022.pdf\n",
      "INFO:__main__:Extracted 140 text chunks from content\\data\\dbs-annual-report-2024.pdf\n",
      "INFO:__main__:Extracted 19 text chunks from content\\data\\QuartelyResults_1Q23_CFO.pdf\n",
      "INFO:__main__:Extracted 17 text chunks from content\\data\\QuartelyResults_1Q24_CFO.pdf\n",
      "INFO:__main__:Extracted 18 text chunks from content\\data\\QuartelyResults_1Q25_CFO.pdf\n",
      "INFO:__main__:Extracted 30 text chunks from content\\data\\QuartelyResults_2Q23_CFO.pdf\n",
      "INFO:__main__:Extracted 30 text chunks from content\\data\\QuartelyResults_2Q24_CFO.pdf\n",
      "INFO:__main__:Extracted 29 text chunks from content\\data\\QuartelyResults_2Q25_CFO.pdf\n",
      "INFO:__main__:Extracted 18 text chunks from content\\data\\QuartelyResults_3Q23_CFO.pdf\n",
      "INFO:__main__:Extracted 21 text chunks from content\\data\\QuartelyResults_3Q24_CFO.pdf\n",
      "INFO:__main__:Extracted 31 text chunks from content\\data\\QuartelyResults_4Q23_CFO.pdf\n",
      "INFO:__main__:Extracted 30 text chunks from content\\data\\QuartelyResults_4Q24_CFO.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/28 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6382f037a134030afae797619906fc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved ingestion data to disk\n",
      "INFO:__main__:Ingested 872 documents in 26.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 20 PDFs\n",
      "Created: 872 text chunks\n",
      "Ingestion Time: 26.18 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27809707fc474afc8eb13d16eb5eadea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Retrieval Test ===\n",
      "Query: Net Interest Margin trend over the past 3 years\n",
      "Retrieved 3 documents:\n",
      "\n",
      "Document 1: DBS Annual Report 2023, Page 13\n",
      "Combined Score: 11.3025\n",
      "Text Preview: 20 DBS ANNUAL REPORT 2023       BUILDING A SUSTAINABLE ADVANTAGE CFO statement We achieved a record performance for the third consecutive year with  t...\n",
      "\n",
      "Document 2: 2Q22_performance_summary, Page 7\n",
      "Combined Score: 11.0513\n",
      "Text Preview: DBS GROUP HOLDINGS LTD AND ITS SUBSIDIARIES    5    First Half    First-half net profit was $3.62 billion, 3% below the  previous year’s record. Busin...\n",
      "\n",
      "Document 3: QuartelyResults_1Q25_CFO, Page 5\n",
      "Combined Score: 5.1649\n",
      "Text Preview: 5 Net interest margin (%) 2.14 2.14 2.11 2.15 2.12 2.77 2.83 2.83 2.77 2.68 3,647 3,769 3,796 3,831 3,719 -142 1Q24 -175 2Q24 -199 3Q24 -103 4Q24 -38 ...\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ingestion pipeline\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# RAG related libararies\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "from rank_bm25 import BM25Okapi\n",
    "import google.generativeai as genai # Gemini API for higher token limits\n",
    "\n",
    "# Initialise logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Tool for financial calculations\n",
    "class CalculatorTool:\n",
    "    def calculate_ratio(self, numerator: float, denominator: float, ratio_name: str = \"\") -> Dict[str, Any]:\n",
    "        try:\n",
    "            if denominator == 0:\n",
    "                return {\"error\": f\"Cannot calculate {ratio_name}: denominator is zero\"}\n",
    "\n",
    "            ratio = (numerator / denominator) * 100 if \"ratio\" in ratio_name.lower() else (numerator / denominator)\n",
    "            return {\n",
    "                \"ratio_name\": ratio_name,\n",
    "                \"numerator\": numerator,\n",
    "                \"denominator\": denominator,\n",
    "                \"result\": round(ratio, 2),\n",
    "                \"formula\": f\"{numerator} / {denominator}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "        \n",
    "    def trend_analysis(self, values: List[float], periods: List[str]) -> Dict[str, Any]:\n",
    "        if len(values) != len(periods):\n",
    "            return {\"error\": \"Values and periods must have the same length\"}\n",
    "        \n",
    "        if len(values) < 2:\n",
    "            return {\"error\": \"Need at least two data points for trend analysis\"}\n",
    "        \n",
    "        # Calculate period-over-period changes\n",
    "        changes = []\n",
    "        for i in range(1, len(values)):\n",
    "            if values[i-1] != 0:\n",
    "                pct_change = ((values[i] - values[i-1]) / values[i-1]) * 100\n",
    "                changes.append(round(pct_change, 2))\n",
    "            else:\n",
    "                changes.append(0)\n",
    "\n",
    "        return {\n",
    "            \"periods\": periods,\n",
    "            \"values\": values,\n",
    "            \"period_changes\": changes,\n",
    "            \"overall_trend\": \"increasing\" if values[-1] > values[0] else \"decreasing\",\n",
    "            \"average_change\": round(sum(changes) / len(changes), 2) if changes else 0\n",
    "        }\n",
    "    \n",
    "\n",
    "# Tool for extracting table from dataset\n",
    "class TableExtractionTool:\n",
    "    def extract_financial_numbers(self, text: str) -> List[Dict[str, Any]]:\n",
    "        # Pattern for numbers with currency/percentage\n",
    "        patterns = [\n",
    "            r'(\\$|S\\$|USD|SGD)?\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(million|billion|thousand|m|bn|k)?',\n",
    "            r'(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(%|percent|basis points|bps)',\n",
    "            r'(NIM|CTI|ROE|ROA|CET1)\\s*[:=]?\\s*(\\d+(?:\\.\\d+)?)\\s*(%|bps)?'\n",
    "        ]\n",
    "\n",
    "        extracted = []\n",
    "        for pattern in patterns:\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                extracted.append({\n",
    "                    \"text\": match.group(0),\n",
    "                    \"value\": match.group(2) if len(match.groups()) > 1 else match.group(1),\n",
    "                    \"context\": text[max(0, match.start()-50):match.end()+50]  # 50 chars before and after\n",
    "                })\n",
    "\n",
    "        return extracted\n",
    "    \n",
    "    def parse_table_structure(self, text: str) -> Dict[str, Any]:\n",
    "        lines = text.split('\\n')\n",
    "        table_lines = []\n",
    "\n",
    "        for line in lines:\n",
    "            # Look for lines that might be table rows (have multiple numbers/columns)\n",
    "            if re.search(r'\\d.*\\d', line) and ('|' in line or '\\t' in line or len(re.findall(r'\\d+', line)) > 1):\n",
    "                table_lines.append(line.strip())\n",
    "\n",
    "        return {\n",
    "            \"potential_table_rows\": table_lines[:10], # Return first 10 rows\n",
    "            \"row_count\": len(table_lines)\n",
    "        }\n",
    "    \n",
    "\n",
    "# Tool for comparing info across docs\n",
    "class DocumentComparisonTool:\n",
    "    def compare_metrics_across_docs(self, documents: List[Dict], metric_name: str) -> Dict[str, Any]:\n",
    "        comparisons = []\n",
    "        for doc in documents:\n",
    "            # Extract metric from document text\n",
    "            numbers = re.findall(r'\\d+(?:\\.\\d+)?', doc.get('text', ''))\n",
    "            filename = doc.get('metadata', {}).get('filename', 'unknown')\n",
    "            \n",
    "            comparisons.append({\n",
    "                \"document\": filename,\n",
    "                \"metric_candidates\": numbers[:5], # Return first 5 found numbers\n",
    "                \"text_snippet\": doc.get('text', '')[:200] # First 200 chars\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            \"metric_name\": metric_name,\n",
    "            \"comparisons\": comparisons\n",
    "        }\n",
    "        \n",
    "# RAG functions\n",
    "class CFORAGPipeline:\n",
    "    def __init__(self, persist_dir=\"./cfo_rag_data\"):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.persist_dir = persist_dir\n",
    "        self.documents = []\n",
    "        self.document_metadata = []\n",
    "        self.index = None\n",
    "        self.bm25 = None\n",
    "\n",
    "        # Initialise tools\n",
    "        self.calculator_tool = CalculatorTool()\n",
    "        self.table_extraction_tool = TableExtractionTool()\n",
    "        self.doc_comparison_tool = DocumentComparisonTool()\n",
    "\n",
    "        # Create directory for persistence\n",
    "        os.makedirs(self.persist_dir, exist_ok=True)\n",
    "\n",
    "        # Performance tracking\n",
    "        self.metrics = {\n",
    "            'T_ingest': 0,\n",
    "            'T_retrieve': 0,\n",
    "            'T_rerank': 0,        \n",
    "            'documents_ingested': 0,\n",
    "            }\n",
    "        \n",
    "        logger.info(\"Initialized CFO RAG Pipeline\")\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:\n",
    "        # for document chunking\n",
    "        chunks = []\n",
    "\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            filename = Path(pdf_path).stem\n",
    "\n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc[page_num]\n",
    "                text = page.get_text()\n",
    "\n",
    "                if text.strip():\n",
    "                    # split by sentences/paragraphs for chunking\n",
    "                    paragraphs = text.split('\\n\\n')\n",
    "\n",
    "                    for i, paragraph in enumerate(paragraphs):\n",
    "                        if len(paragraph.strip()) > 50:\n",
    "                            chunk = {\n",
    "                                'text': paragraph.strip(),\n",
    "                                'metadata': {\n",
    "                                    'filename': filename,\n",
    "                                    'page': page_num + 1,\n",
    "                                    'chunk_id': f\"{filename}_p{page_num+1}_c{i+1}\",\n",
    "                                    'source_type': self._classify_document_type(filename)\n",
    "                                }\n",
    "                            }\n",
    "                            chunks.append(chunk)\n",
    "\n",
    "            doc.close()\n",
    "            logger.info(f\"Extracted {len(chunks)} text chunks from {pdf_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "\n",
    "        return chunks\n",
    "    \n",
    "    def _classify_document_type(self, filename: str) -> str:\n",
    "        # based on filename\n",
    "        filename_lower = filename.lower()\n",
    "        if 'annual' in filename_lower:\n",
    "            return 'annual_report'\n",
    "        elif any(q in filename_lower for q in ['1q', '2q', '3q', '4q', 'quarter']):\n",
    "            return 'quarterly_report'\n",
    "        elif 'performance' in filename_lower:\n",
    "            return 'performance_summary'\n",
    "        else:\n",
    "            return 'financial_report'\n",
    "        \n",
    "        # document ingestion from data directory containing PDFs/datasets\n",
    "    def ingest_documents(self, data_dir: str = \"./content/data\") -> Dict[str, Any]:\n",
    "        # record time taken to ingest the documents\n",
    "        start_time = time.time()\n",
    "\n",
    "        pdf_files = list(Path(data_dir).glob(\"*.pdf\"))\n",
    "        if not pdf_files:\n",
    "            raise ValueError(f\"No PDF files found in {data_dir}\")\n",
    "        \n",
    "        all_chunks = []\n",
    "\n",
    "        # process each PDF file\n",
    "        for pdf_file in pdf_files:\n",
    "            chunks = self.extract_text_from_pdf(str(pdf_file))\n",
    "            all_chunks.extend(chunks)\n",
    "\n",
    "        # separate text and metadata\n",
    "        texts = [chunk['text'] for chunk in all_chunks]\n",
    "        metadatas = [chunk['metadata'] for chunk in all_chunks]\n",
    "\n",
    "        self.documents = texts\n",
    "        self.document_metadata = metadatas\n",
    "\n",
    "        # Create embeddings\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "        # Create FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.index.add(embeddings.astype('float32'))\n",
    "\n",
    "        # create BM25 index for keyword search\n",
    "        tokenised_docs = [doc.lower().split() for doc in texts]\n",
    "        self.bm25 = BM25Okapi(tokenised_docs)\n",
    "\n",
    "        # save data\n",
    "        self._save_data()\n",
    "\n",
    "        # update metrics\n",
    "        self.metrics['T_ingest'] = time.time() - start_time\n",
    "        self.metrics['documents_ingested'] = len(texts)\n",
    "        logger.info(f\"Ingested {len(texts)} documents in {self.metrics['T_ingest']:.2f} seconds\")\n",
    "\n",
    "        return {\n",
    "            'documents_processed': len(pdf_files),\n",
    "            'chunks_created': len(texts),\n",
    "            'ingestion_duration': self.metrics['T_ingest']\n",
    "        }\n",
    "    \n",
    "    # retrieve relevant documents using hybrid search\n",
    "    def hybrid_retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "        start_time = time.time()\n",
    "        if not self.documents or self.index is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # --- Vector search ---\n",
    "            query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
    "            vector_k = min(top_k * 2, len(self.documents))\n",
    "            distances, indices = self.index.search(query_embedding.astype('float32'), vector_k)\n",
    "    \n",
    "            # --- BM25 keyword search ---\n",
    "            bm25_scores = self.bm25.get_scores(query.lower().split())\n",
    "    \n",
    "            # --- Rerank step ---\n",
    "            start_rerank = time.time()\n",
    "            combined_results = []\n",
    "            for i, idx in enumerate(indices[0]):\n",
    "                if idx < len(self.documents):\n",
    "                    vector_score = 1 / (1 + distances[0][i])\n",
    "                    bm25_score = bm25_scores[idx] if idx < len(bm25_scores) else 0\n",
    "                    combined_score = vector_score + bm25_score\n",
    "    \n",
    "                    result = {\n",
    "                        'text': self.documents[idx],\n",
    "                        'metadata': self.document_metadata[idx],\n",
    "                        'combined_score': combined_score,\n",
    "                        'vector_score': vector_score,\n",
    "                        'bm25_score': bm25_score,\n",
    "                        'citation': f\"{self.document_metadata[idx]['filename']}, Page {self.document_metadata[idx]['page']}\"\n",
    "                    }\n",
    "                    combined_results.append(result)\n",
    "    \n",
    "            # sort and keep top_k\n",
    "            combined_results.sort(key=lambda x: x['combined_score'], reverse=True)\n",
    "            final_results = combined_results[:top_k]\n",
    "    \n",
    "            # save rerank timing\n",
    "            self.metrics['T_rerank'] = time.time() - start_rerank\n",
    "    \n",
    "            # save retrieve timing\n",
    "            self.metrics['T_retrieve'] = time.time() - start_time\n",
    "    \n",
    "            return final_results\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "        \n",
    "    def _save_data(self):\n",
    "        # Save FAISS index\n",
    "        try:\n",
    "            with open(os.path.join(self.persist_dir, 'documents.pkl'), 'wb') as f:\n",
    "                pickle.dump(self.documents, f)\n",
    "\n",
    "            with open(os.path.join(self.persist_dir, 'metadata.pkl'), 'wb') as f:\n",
    "                pickle.dump(self.document_metadata, f)\n",
    "\n",
    "            if self.index is not None:\n",
    "                faiss.write_index(self.index, os.path.join(self.persist_dir, 'faiss_index.bin'))\n",
    "\n",
    "            if self.bm25 is not None:\n",
    "                with open(os.path.join(self.persist_dir, 'bm25.pkl'), 'wb') as f:\n",
    "                    pickle.dump(self.bm25, f)\n",
    "        \n",
    "            logger.info(\"Saved ingestion data to disk\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving data: {e}\")\n",
    "\n",
    "cfo_rag = CFORAGPipeline()\n",
    "\n",
    "# Ingest documents from data directory\n",
    "print(\"=== Starting document ingestion ===\")\n",
    "ingestion_result = cfo_rag.ingest_documents(data_dir=\"./content/data\")\n",
    "print(f\"Processed: {ingestion_result['documents_processed']} PDFs\")\n",
    "print(f\"Created: {ingestion_result['chunks_created']} text chunks\")\n",
    "print(f\"Ingestion Time: {ingestion_result['ingestion_duration']:.2f} seconds\")\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"Net Interest Margin trend over the past 3 years\"\n",
    "retrieved_docs = cfo_rag.hybrid_retrieve(test_query, top_k=3)\n",
    "\n",
    "print(f\"\\n=== Retrieval Test ===\")\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents:\")\n",
    "\n",
    "\n",
    "if retrieved_docs:\n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"\\nDocument {i}: {doc['citation']}\")\n",
    "        print(f\"Combined Score: {doc['combined_score']:.4f}\")\n",
    "        print(f\"Text Preview: {doc['text'][:150].replace(chr(10), ' ')}...\")  # Print first 150 chars\n",
    "else:\n",
    "    print(\"No documents retrieved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb05fc",
   "metadata": {
    "id": "6ffb05fc"
   },
   "source": [
    "## 4. Baseline Pipeline\n",
    "\n",
    "**Baseline (starting point)**\n",
    "*   Naive chunking.\n",
    "*   Single-pass vector search.\n",
    "*   One LLM call, no caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "540b7020",
   "metadata": {
    "id": "540b7020",
    "ExecuteTime": {
     "end_time": "2025-09-30T08:51:09.837432100Z",
     "start_time": "2025-09-30T08:50:48.512300300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dc624f81ac64e5f9d1edaab0b7526df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Answer ===\n",
      "Over the past three years, the Net Interest Margin (NIM) of DBS Group Holdings Ltd showed an initial declining trend that reversed in 2022, leading to significant expansion through 2023.\n",
      "\n",
      "Here's the trend:\n",
      "*   **2021:** The Net Interest Margin had been declining since 2019. For the first half of 2021, the NIM was approximately 1.47% (derived from being five basis points lower than the H1 2022 NIM). (2Q22_performance_summary, Page 7)\n",
      "*   **2022:** The NIM began to rise in the first quarter of 2022, and this improvement accelerated throughout the year. The full-year Net Interest Margin for 2022 was 1.75% (calculated by subtracting the 40 basis point expansion in 2023 from the 2023 full-year NIM). (DBS Annual Report 2023, Page 13; 2Q22_performance_summary, Page 7)\n",
      "*   **2023:** The full-year Net Interest Margin expanded by 40 basis points to 2.15%. (DBS Annual Report 2023, Page 13)\n",
      "\n",
      "Citations: ['DBS Annual Report 2023, Page 13', '2Q22_performance_summary, Page 7', 'QuartelyResults_1Q25_CFO, Page 5']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement baseline retrieval + generation\n",
    "# =============================\n",
    "# Part 4. Baseline Pipeline\n",
    "# =============================\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyD9nOIYeshnVBJfV9Im7OUJz85CunBka_I\"\n",
    "\n",
    "# Configure Gemini using environment variable\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Load model\n",
    "llm_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "\n",
    "def baseline_pipeline(query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Runs naive RAG pipeline: retrieval + single LLM call.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant docs\n",
    "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k)\n",
    "    if not retrieved_docs:\n",
    "        return {\"error\": \"No documents retrieved.\"}\n",
    "    \n",
    "    # Build context\n",
    "    context = \"\\n\\n\".join([f\"{doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
    "    \n",
    "    # Prompt\n",
    "    prompt = f\"\"\"\n",
    "You are a financial analyst assistant. \n",
    "Answer the user query based only on the provided reports. \n",
    "Include citations (filename + page).\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Reports:\n",
    "{context}\n",
    "\"\"\"\n",
    "    # Call LLM\n",
    "    response = llm_model.generate_content(prompt)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
    "        \"raw_docs\": [doc[\"text\"][:300] for doc in retrieved_docs],  # preview only\n",
    "        \"answer\": response.text.strip()\n",
    "    }\n",
    "\n",
    "# 🔹 Example run\n",
    "result = baseline_pipeline(\"Net Interest Margin trend over the past 3 years\", top_k=3)\n",
    "print(\"=== Baseline Answer ===\")\n",
    "print(result[\"answer\"])\n",
    "print(\"\\nCitations:\", result[\"citations\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9e3ea",
   "metadata": {
    "id": "01e9e3ea"
   },
   "source": [
    "## 5. Benchmark Runner\n",
    "\n",
    "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
    "\n",
    "*   Net Interest Margin (NIM) trend over last 5 quarters, values and 1–2 lines of explanation.\n",
    "    *   Expected: quarterly financial highlights.\n",
    "*   Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\n",
    "    *   Expected: Opex table + MD&A commentary.\n",
    "*   Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\n",
    "    *   Expected: Operating Income & Opex lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7bddc40",
   "metadata": {
    "id": "e7bddc40",
    "ExecuteTime": {
     "end_time": "2025-09-30T08:51:55.689241200Z",
     "start_time": "2025-09-30T08:51:09.843145600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Benchmark: NIM Trend ===\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d0556e7cbcd4f0280b2eb7a0dfebdfc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Benchmark: Opex YoY ===\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56e73da8533a4936bc013a99836d8dd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Benchmark: Cost-to-Income Ratio ===\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cea699f144b4d018b56299a091aaa0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NIM Trend ===\n",
      "Query: Net Interest Margin (NIM) trend over last 5 quarters, values and 1–2 lines of explanation.\n",
      "Answer: The Net Interest Margin (NIM) trend over the last five quarters is as follows:\n",
      "\n",
      "*   **1Q24:** 2.77% (QuartelyResults_1Q25_CFO, Page 5)\n",
      "*   **2Q24:** 2.83% (QuartelyResults_1Q25_CFO, Page 5)\n",
      "*   **3Q24:** 2.83% (QuartelyResults_1Q25_CFO, Page 5)\n",
      "*   **4Q24:** 2.77% (QuartelyResults_1Q25_CFO, Page 5)\n",
      "*   **1Q25:** 2.68% (QuartelyResults_1Q25_CFO, Page 5)\n",
      "\n",
      "The NIM increased from 1Q24 to 2Q24, remained stable through 3Q24, and then began to decline in 4Q24, continuing into 1Q25. The decline in 1Q25 was due to lower interest rates (QuartelyResults_1Q25_CFO, Page 5).\n",
      "\n",
      "Citations: ['dbs-annual-report-2022, Page 15', 'QuartelyResults_4Q23_CFO, Page 7', 'QuartelyResults_1Q25_CFO, Page 5', 'QuartelyResults_1Q23_CFO, Page 5', 'QuartelyResults_1Q24_CFO, Page 5']\n",
      "\n",
      "=== Opex YoY ===\n",
      "Query: Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\n",
      "Answer: Based on the provided reports:\n",
      "\n",
      "**Operating Expenses (Opex) Year-over-Year (YoY) for the last 3 years:**\n",
      "\n",
      "*   **FY24:** Expenses were S$8,895 million, representing a **+10% YoY** increase. (QuartelyResults_4Q24_CFO, Page 3)\n",
      "*   **FY23:** Expenses were S$8,056 million, representing a **+14% YoY** increase. (QuartelyResults_4Q23_CFO, Page 23)\n",
      "*   **FY22:** Expenses were S$7,090 million. The YoY change for FY22 against FY21 is not explicitly provided in the given reports. (QuartelyResults_4Q23_CFO, Page 23)\n",
      "\n",
      "**Top 3 drivers of Operating Expenses from MD&A:**\n",
      "\n",
      "1.  **Citi Taiwan Acquisition:** This factor accounted for 3 percentage points of the expense increase in FY24. It was also mentioned in the context of expense growth for 4Q23.\n",
      "    (QuartelyResults_4Q24_CFO, Page 3; QuartelyResults_4Q23_CFO, Page 5)\n",
      "2.  **Higher staff cost:** This was noted as a driver for underlying expense increases.\n",
      "    (QuartelyResults_3Q23_CFO, Page 4)\n",
      "3.  **Non-recurring technology and other costs:** These were mentioned as contributing to expense growth.\n",
      "    (QuartelyResults_4Q23_CFO, Page 5)\n",
      "\n",
      "Citations: ['QuartelyResults_4Q24_CFO, Page 3', 'QuartelyResults_1Q25_CFO, Page 3', 'QuartelyResults_4Q23_CFO, Page 5', 'QuartelyResults_4Q23_CFO, Page 23', 'QuartelyResults_3Q23_CFO, Page 4']\n",
      "\n",
      "=== Cost-to-Income Ratio ===\n",
      "Query: Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\n",
      "Answer: Based on the provided reports, the Cost-to-Income Ratio (CTI) for the last two available full financial years is as follows. Data for FY21 is not available in the provided reports.\n",
      "\n",
      "---\n",
      "\n",
      "**Cost-to-Income Ratio (CTI)**\n",
      "\n",
      "**FY23:**\n",
      "*   **CTI:** 39%\n",
      "*   **Working:**\n",
      "    *   Total Staff Expenses (FY23): S$5,036 million (QuartelyResults_4Q23_CFO, Page 12)\n",
      "    *   Total Other Expenses (FY23): S$3,020 million (QuartelyResults_4Q23_CFO, Page 12)\n",
      "    *   Total Expenses (FY23): S$5,036 million + S$3,020 million = S$8,056 million\n",
      "    *   Total Income (FY23): S$20,656 million (derived from chart in QuartelyResults_4Q23_CFO, Page 12, where 8,056 / 0.39 = 20,656)\n",
      "    *   CTI = (Total Expenses / Total Income) * 100 = (S$8,056 million / S$20,656 million) * 100 = 39.00%\n",
      "*   **Citation:** QuartelyResults_4Q23_CFO, Page 12\n",
      "\n",
      "**FY22:**\n",
      "*   **CTI:** 43%\n",
      "*   **Working:**\n",
      "    *   Total Staff Expenses (FY22): S$4,376 million (QuartelyResults_4Q23_CFO, Page 12)\n",
      "    *   Total Other Expenses (FY22): S$2,714 million (QuartelyResults_4Q23_CFO, Page 12)\n",
      "    *   Total Expenses (FY22): S$4,376 million + S$2,714 million = S$7,090 million\n",
      "    *   Total Income (FY22): S$16,488 million (derived from chart in QuartelyResults_4Q23_CFO, Page 12, where 7,090 / 0.43 = 16,488)\n",
      "    *   CTI = (Total Expenses / Total Income) * 100 = (S$7,090 million / S$16,488 million) * 100 = 43.00%\n",
      "*   **Citation:** QuartelyResults_4Q23_CFO, Page 12\n",
      "\n",
      "---\n",
      "\n",
      "**Implications:**\n",
      "\n",
      "The Cost-to-Income Ratio (CTI) is a key indicator of operational efficiency for financial institutions. A lower CTI generally signifies better cost management relative to income generation.\n",
      "\n",
      "*   **Positive Trend:** The CTI decreased from 43% in FY22 to 39% in FY23. This 4 percentage point reduction indicates a significant improvement in the company's operational efficiency.\n",
      "*   **Improved Profitability:** A lower CTI implies that the company is spending less to generate each unit of income, which contributes positively to its overall profitability. For every S$100 of income, the company spent S$43 on operating expenses in FY22, while in FY23, this figure dropped to S$39.\n",
      "*   **Cost Management or Income Growth:** This improvement could be driven by effective cost control measures, stronger income growth outpacing expense growth, or a combination of both. Although specific drivers for the full year change are not detailed in the provided reports, the trend is a favorable sign for investors and stakeholders, suggesting more efficient utilization of resources.\n",
      "\n",
      "Citations: ['QuartelyResults_3Q24_CFO, Page 2', 'QuartelyResults_3Q24_CFO, Page 14', 'QuartelyResults_3Q23_CFO, Page 11', 'QuartelyResults_1Q23_CFO, Page 10', 'QuartelyResults_4Q23_CFO, Page 12']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement benchmark runner\n",
    "# =============================\n",
    "# Part 5. Benchmark Runner\n",
    "# =============================\n",
    "\n",
    "benchmark_queries = [\n",
    "    {\n",
    "        \"name\": \"NIM Trend\",\n",
    "        \"query\": \"Net Interest Margin (NIM) trend over last 5 quarters, values and 1–2 lines of explanation.\",\n",
    "        \"expected\": \"Quarterly financial highlights\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Opex YoY\",\n",
    "        \"query\": \"Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\",\n",
    "        \"expected\": \"Opex table + MD&A commentary\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Cost-to-Income Ratio\",\n",
    "        \"query\": \"Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\",\n",
    "        \"expected\": \"Operating Income & Opex lines\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# =============================\n",
    "# Benchmark Runner with Instrumentation\n",
    "# =============================\n",
    "\n",
    "def run_benchmark_instrumented(queries, top_k=5):\n",
    "    results = []\n",
    "    for q in queries:\n",
    "        print(f\"\\n=== Running Benchmark: {q['name']} ===\")\n",
    "        output = instrumented_pipeline(q[\"query\"], top_k=top_k)\n",
    "        results.append({\n",
    "            \"name\": q[\"name\"],\n",
    "            \"query\": q[\"query\"],\n",
    "            \"expected\": q[\"expected\"],\n",
    "            \"citations\": output.get(\"citations\", []),\n",
    "            \"answer\": output.get(\"answer\", \"Error: no answer\")\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 🔹 Run the benchmarks\n",
    "benchmark_results = run_benchmark_instrumented(benchmark_queries, top_k=5)\n",
    "\n",
    "# Show answers\n",
    "for res in benchmark_results:\n",
    "    print(f\"\\n=== {res['name']} ===\")\n",
    "    print(f\"Query: {res['query']}\")\n",
    "    print(f\"Answer: {res['answer']}\\n\")\n",
    "    print(f\"Citations: {res['citations']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ebeda",
   "metadata": {
    "id": "683ebeda"
   },
   "source": [
    "## 6. Instrumentation\n",
    "\n",
    "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5425de5",
   "metadata": {
    "id": "d5425de5",
    "ExecuteTime": {
     "end_time": "2025-09-30T08:53:01.118855100Z",
     "start_time": "2025-09-30T08:51:55.689241200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Instrumented Benchmark: NIM Trend ===\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e6f9b54208b4feb801f69bb9c65f157"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Instrumented Benchmark: Opex YoY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kerwin Loh\\AppData\\Local\\Temp\\ipykernel_14456\\2464890144.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  logs = pd.concat([logs, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4d72811c17046499ddd40993f2f185a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Instrumented Benchmark: Cost-to-Income Ratio ===\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad853d31d87f46d9ae9c826617af4bb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                               Query  T_ingest (sec)  \\\n0  Net Interest Margin (NIM) trend over last 5 qu...        26.18077   \n1  Operating Expenses (Opex) YoY for last 3 years...        26.18077   \n2  Cost-to-Income Ratio (CTI) for last 3 years; s...        26.18077   \n\n   T_retrieve (sec)  T_rerank (sec)  T_reason (sec)  T_generate (sec)  \\\n0          0.037177             0.0       11.959277          2.925130   \n1          0.029012             0.0       12.261808          4.194901   \n2          0.026147             0.0       27.726501          6.220154   \n\n   T_total (sec) Tokens CacheHits                       Tools  \n0      14.923590   None         0  [Retriever, Reranker, LLM]  \n1      16.485721   None         0  [Retriever, Reranker, LLM]  \n2      33.972802   None         0  [Retriever, Reranker, LLM]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Query</th>\n      <th>T_ingest (sec)</th>\n      <th>T_retrieve (sec)</th>\n      <th>T_rerank (sec)</th>\n      <th>T_reason (sec)</th>\n      <th>T_generate (sec)</th>\n      <th>T_total (sec)</th>\n      <th>Tokens</th>\n      <th>CacheHits</th>\n      <th>Tools</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Net Interest Margin (NIM) trend over last 5 qu...</td>\n      <td>26.18077</td>\n      <td>0.037177</td>\n      <td>0.0</td>\n      <td>11.959277</td>\n      <td>2.925130</td>\n      <td>14.923590</td>\n      <td>None</td>\n      <td>0</td>\n      <td>[Retriever, Reranker, LLM]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Operating Expenses (Opex) YoY for last 3 years...</td>\n      <td>26.18077</td>\n      <td>0.029012</td>\n      <td>0.0</td>\n      <td>12.261808</td>\n      <td>4.194901</td>\n      <td>16.485721</td>\n      <td>None</td>\n      <td>0</td>\n      <td>[Retriever, Reranker, LLM]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cost-to-Income Ratio (CTI) for last 3 years; s...</td>\n      <td>26.18077</td>\n      <td>0.026147</td>\n      <td>0.0</td>\n      <td>27.726501</td>\n      <td>6.220154</td>\n      <td>33.972802</td>\n      <td>None</td>\n      <td>0</td>\n      <td>[Retriever, Reranker, LLM]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "# Part 6. Instrumentation\n",
    "# =============================\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Create logs DataFrame\n",
    "logs = pd.DataFrame(columns=[\n",
    "    'Query', \n",
    "    'T_ingest (sec)', 'T_retrieve (sec)', 'T_rerank (sec)', 'T_reason (sec)', \n",
    "    'T_generate (sec)', 'T_total (sec)', \n",
    "    'Tokens', 'CacheHits', 'Tools'\n",
    "])\n",
    "\n",
    "def instrumented_pipeline(query: str, top_k: int = 5):\n",
    "    global logs\n",
    "    timings = {}\n",
    "    start_total = time.time()\n",
    "\n",
    "    # --- Retrieval ---\n",
    "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k)\n",
    "    timings['T_retrieve'] = cfo_rag.metrics.get('T_retrieve', 0)\n",
    "    timings['T_rerank'] = cfo_rag.metrics.get('T_rerank', 0)\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        return {\"error\": \"No documents retrieved.\"}\n",
    "\n",
    "    # --- Build context ---\n",
    "    context = \"\\n\\n\".join([f\"{doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
    "\n",
    "    # --- Reasoning step (simulate \"thinking\") ---\n",
    "    start_reason = time.time()\n",
    "    reasoning_prompt = f\"\"\"\n",
    "    Summarize the key financial figures and trends in a structured way.\n",
    "    Do not generate the final answer yet.\n",
    "    \n",
    "    Query: {query}\n",
    "    Reports:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    reasoning_output = llm_model.generate_content(reasoning_prompt)\n",
    "    timings['T_reason'] = time.time() - start_reason\n",
    "\n",
    "    # --- Generation step ---\n",
    "    start_generate = time.time()\n",
    "    final_prompt = f\"\"\"\n",
    "    You are a financial analyst assistant.\n",
    "    Based on the reasoning and reports, provide the final answer with citations.\n",
    "\n",
    "    Reasoning:\n",
    "    {reasoning_output.text}\n",
    "\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    "    response = llm_model.generate_content(final_prompt)\n",
    "    timings['T_generate'] = time.time() - start_generate\n",
    "\n",
    "    # --- Total ---\n",
    "    timings['T_total'] = time.time() - start_total\n",
    "\n",
    "    # --- Log row ---\n",
    "    new_row = {\n",
    "        'Query': query,\n",
    "        'T_ingest (sec)': cfo_rag.metrics.get('T_ingest', 0),\n",
    "        'T_retrieve (sec)': timings['T_retrieve'],\n",
    "        'T_rerank (sec)': timings['T_rerank'],\n",
    "        'T_reason (sec)': timings['T_reason'],\n",
    "        'T_generate (sec)': timings['T_generate'],\n",
    "        'T_total (sec)': timings['T_total'],\n",
    "        'Tokens': None,\n",
    "        'CacheHits': 0,\n",
    "        'Tools': ['Retriever', 'Reranker', 'LLM']\n",
    "    }\n",
    "    logs = pd.concat([logs, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
    "        \"reasoning\": reasoning_output.text.strip(),\n",
    "        \"answer\": response.text.strip()\n",
    "    }\n",
    "\n",
    "\n",
    "def run_benchmark_instrumented(queries, top_k=5):\n",
    "    results = []\n",
    "    for q in queries:\n",
    "        print(f\"\\n=== Running Instrumented Benchmark: {q['name']} ===\")\n",
    "        output = instrumented_pipeline(q[\"query\"], top_k=top_k)\n",
    "        results.append({\n",
    "            \"name\": q[\"name\"],\n",
    "            \"query\": q[\"query\"],\n",
    "            \"expected\": q[\"expected\"],\n",
    "            \"citations\": output.get(\"citations\", []),\n",
    "            \"answer\": output.get(\"answer\", \"Error: no answer\")\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 🔹 Run instrumented benchmarks\n",
    "benchmark_results_instrumented = run_benchmark_instrumented(benchmark_queries, top_k=5)\n",
    "\n",
    "# Show instrumentation logs (should have 3 rows now)\n",
    "logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c01bf4",
   "metadata": {
    "id": "e8c01bf4"
   },
   "source": [
    "## 7. Optimizations\n",
    "\n",
    "**Required Optimizations**\n",
    "\n",
    "Each team must implement at least:\n",
    "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
    "*   1 caching optimization (query cache or ratio cache).\n",
    "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
    "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "783f0e2e",
   "metadata": {
    "id": "783f0e2e",
    "ExecuteTime": {
     "end_time": "2025-09-30T08:53:01.130439200Z",
     "start_time": "2025-09-30T08:53:01.123555900Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement optimizations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ce833",
   "metadata": {
    "id": "a91ce833"
   },
   "source": [
    "## 8. Results & Plots\n",
    "\n",
    "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d96550f3",
   "metadata": {
    "id": "d96550f3",
    "ExecuteTime": {
     "end_time": "2025-09-30T08:53:01.130439200Z",
     "start_time": "2025-09-30T08:53:01.123555900Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Generate plots with matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2am56tlpjY9",
   "metadata": {
    "id": "s2am56tlpjY9"
   },
   "source": [
    "testing"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
