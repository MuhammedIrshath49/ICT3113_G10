{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO — Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is the starter notebook for your project. Follow the required structure below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the company’s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Example:\n",
        "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
        "\n",
        "COMPANY_NAME = \"DBS Bank\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3–5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e08f5a0",
      "metadata": {
        "id": "5e08f5a0"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement ingestion pipeline\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "# RAG related libararies\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz  # PyMuPDF for PDF processing\n",
        "from rank_bm25 import BM25Okapi\n",
        "import google.generativeai as genai # Gemini API for higher token limits\n",
        "\n",
        "# Initialise logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Tool for financial calculations\n",
        "class CalculatorTool:\n",
        "    def calculate_ratio(self, numerator: float, denominator: float, ratio_name: str = \"\") -> Dict[str, Any]:\n",
        "        try:\n",
        "            if denominator == 0:\n",
        "                return {\"error\": f\"Cannot calculate {ratio_name}: denominator is zero\"}\n",
        "\n",
        "            ratio = (numerator / denominator) * 100 if \"ratio\" in ratio_name.lower() else (numerator / denominator)\n",
        "            return {\n",
        "                \"ratio_name\": ratio_name,\n",
        "                \"numerator\": numerator,\n",
        "                \"denominator\": denominator,\n",
        "                \"result\": round(ratio, 2),\n",
        "                \"formula\": f\"{numerator} / {denominator}\"\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "        \n",
        "    def trend_analysis(self, values: List[float], periods: List[str]) -> Dict[str, Any]:\n",
        "        if len(values) != len(periods):\n",
        "            return {\"error\": \"Values and periods must have the same length\"}\n",
        "        \n",
        "        if len(values) < 2:\n",
        "            return {\"error\": \"Need at least two data points for trend analysis\"}\n",
        "        \n",
        "        # Calculate period-over-period changes\n",
        "        changes = []\n",
        "        for i in range(1, len(values)):\n",
        "            if values[i-1] != 0:\n",
        "                pct_change = ((values[i] - values[i-1]) / values[i-1]) * 100\n",
        "                changes.append(round(pct_change, 2))\n",
        "            else:\n",
        "                changes.append(0)\n",
        "\n",
        "        return {\n",
        "            \"periods\": periods,\n",
        "            \"values\": values,\n",
        "            \"period_changes\": changes,\n",
        "            \"overall_trend\": \"increasing\" if values[-1] > values[0] else \"decreasing\",\n",
        "            \"average_change\": round(sum(changes) / len(changes), 2) if changes else 0\n",
        "        }\n",
        "    \n",
        "\n",
        "# Tool for extracting table from dataset\n",
        "class TableExtractionTool:\n",
        "    def extract_financial_numbers(self, text: str) -> List[Dict[str, Any]]:\n",
        "        # Pattern for numbers with currency/percentage\n",
        "        patterns = [\n",
        "            r'(\\$|S\\$|USD|SGD)?\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(million|billion|thousand|m|bn|k)?',\n",
        "            r'(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(%|percent|basis points|bps)',\n",
        "            r'(NIM|CTI|ROE|ROA|CET1)\\s*[:=]?\\s*(\\d+(?:\\.\\d+)?)\\s*(%|bps)?'\n",
        "        ]\n",
        "\n",
        "        extracted = []\n",
        "        for pattern in patterns:\n",
        "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                extracted.append({\n",
        "                    \"text\": match.group(0),\n",
        "                    \"value\": match.group(2) if len(match.groups()) > 1 else match.group(1),\n",
        "                    \"context\": text[max(0, match.start()-50):match.end()+50]  # 50 chars before and after\n",
        "                })\n",
        "\n",
        "        return extracted\n",
        "    \n",
        "    def parse_table_structure(self, text: str) -> Dict[str, Any]:\n",
        "        lines = text.split('\\n')\n",
        "        table_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            # Look for lines that might be table rows (have multiple numbers/columns)\n",
        "            if re.search(r'\\d.*\\d', line) and ('|' in line or '\\t' in line or len(re.findall(r'\\d+', line)) > 1):\n",
        "                table_lines.append(line.strip())\n",
        "\n",
        "        return {\n",
        "            \"potential_table_rows\": table_lines[:10], # Return first 10 rows\n",
        "            \"row_count\": len(table_lines)\n",
        "        }\n",
        "    \n",
        "\n",
        "# Tool for comparing info across docs\n",
        "class DocumentComparisonTool:\n",
        "    def compare_metrics_across_docs(self, documents: List[Dict], metric_name: str) -> Dict[str, Any]:\n",
        "        comparisons = []\n",
        "        for doc in documents:\n",
        "            # Extract metric from document text\n",
        "            numbers = re.findall(r'\\d+(?:\\.\\d+)?', doc.get('text', ''))\n",
        "            filename = doc.get('metadata', {}).get('filename', 'unknown')\n",
        "            \n",
        "            comparisons.append({\n",
        "                \"document\": filename,\n",
        "                \"metric_candidates\": numbers[:5], # Return first 5 found numbers\n",
        "                \"text_snippet\": doc.get('text', '')[:200] # First 200 chars\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            \"metric_name\": metric_name,\n",
        "            \"comparisons\": comparisons\n",
        "        }\n",
        "        \n",
        "# RAG functions\n",
        "class CFORAGPipeline:\n",
        "    def __init__(self, persist_dir=\"./cfo_rag_data\"):\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.persist_dir = persist_dir\n",
        "        self.documents = []\n",
        "        self.document_metadata = []\n",
        "        self.index = None\n",
        "        self.bm25 = None\n",
        "\n",
        "        # Initialise tools\n",
        "        self.calculator_tool = CalculatorTool()\n",
        "        self.table_extraction_tool = TableExtractionTool()\n",
        "        self.doc_comparison_tool = DocumentComparisonTool()\n",
        "\n",
        "        # Create directory for persistence\n",
        "        os.makedirs(self.persist_dir, exist_ok=True)\n",
        "\n",
        "        # Performance tracking\n",
        "        self.metrics = {\n",
        "            'T_ingest': 0,\n",
        "            'T_retrieve': 0,\n",
        "            'T_rerank': 0,        \n",
        "            'documents_ingested': 0,\n",
        "            }\n",
        "        \n",
        "        logger.info(\"Initialized CFO RAG Pipeline\")\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:\n",
        "        # for document chunking\n",
        "        chunks = []\n",
        "\n",
        "        try:\n",
        "            doc = fitz.open(pdf_path)\n",
        "            filename = Path(pdf_path).stem\n",
        "\n",
        "            for page_num in range(len(doc)):\n",
        "                page = doc[page_num]\n",
        "                text = page.get_text()\n",
        "\n",
        "                if text.strip():\n",
        "                    # split by sentences/paragraphs for chunking\n",
        "                    paragraphs = text.split('\\n\\n')\n",
        "\n",
        "                    for i, paragraph in enumerate(paragraphs):\n",
        "                        if len(paragraph.strip()) > 50:\n",
        "                            chunk = {\n",
        "                                'text': paragraph.strip(),\n",
        "                                'metadata': {\n",
        "                                    'filename': filename,\n",
        "                                    'page': page_num + 1,\n",
        "                                    'chunk_id': f\"{filename}_p{page_num+1}_c{i+1}\",\n",
        "                                    'source_type': self._classify_document_type(filename)\n",
        "                                }\n",
        "                            }\n",
        "                            chunks.append(chunk)\n",
        "\n",
        "            doc.close()\n",
        "            logger.info(f\"Extracted {len(chunks)} text chunks from {pdf_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text from {pdf_path}: {e}\")\n",
        "\n",
        "        return chunks\n",
        "    \n",
        "    def _classify_document_type(self, filename: str) -> str:\n",
        "        # based on filename\n",
        "        filename_lower = filename.lower()\n",
        "        if 'annual' in filename_lower:\n",
        "            return 'annual_report'\n",
        "        elif any(q in filename_lower for q in ['1q', '2q', '3q', '4q', 'quarter']):\n",
        "            return 'quarterly_report'\n",
        "        elif 'performance' in filename_lower:\n",
        "            return 'performance_summary'\n",
        "        else:\n",
        "            return 'financial_report'\n",
        "        \n",
        "        # document ingestion from data directory containing PDFs/datasets\n",
        "    def ingest_documents(self, data_dir: str = \"./content/data\") -> Dict[str, Any]:\n",
        "        # record time taken to ingest the documents\n",
        "        start_time = time.time()\n",
        "\n",
        "        pdf_files = list(Path(data_dir).glob(\"*.pdf\"))\n",
        "        if not pdf_files:\n",
        "            raise ValueError(f\"No PDF files found in {data_dir}\")\n",
        "        \n",
        "        all_chunks = []\n",
        "\n",
        "        # process each PDF file\n",
        "        for pdf_file in pdf_files:\n",
        "            chunks = self.extract_text_from_pdf(str(pdf_file))\n",
        "            all_chunks.extend(chunks)\n",
        "\n",
        "        # separate text and metadata\n",
        "        texts = [chunk['text'] for chunk in all_chunks]\n",
        "        metadatas = [chunk['metadata'] for chunk in all_chunks]\n",
        "\n",
        "        self.documents = texts\n",
        "        self.document_metadata = metadatas\n",
        "\n",
        "        # Create embeddings\n",
        "        embeddings = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dimension)\n",
        "        self.index.add(embeddings.astype('float32'))\n",
        "\n",
        "        # create BM25 index for keyword search\n",
        "        tokenised_docs = [doc.lower().split() for doc in texts]\n",
        "        self.bm25 = BM25Okapi(tokenised_docs)\n",
        "\n",
        "        # save data\n",
        "        self._save_data()\n",
        "\n",
        "        # update metrics\n",
        "        self.metrics['T_ingest'] = time.time() - start_time\n",
        "        self.metrics['documents_ingested'] = len(texts)\n",
        "        logger.info(f\"Ingested {len(texts)} documents in {self.metrics['T_ingest']:.2f} seconds\")\n",
        "\n",
        "        return {\n",
        "            'documents_processed': len(pdf_files),\n",
        "            'chunks_created': len(texts),\n",
        "            'ingestion_duration': self.metrics['T_ingest']\n",
        "        }\n",
        "    \n",
        "    # retrieve relevant documents using hybrid search\n",
        "    def hybrid_retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
        "        start_time = time.time()\n",
        "\n",
        "        if not self.documents or self.index is None:\n",
        "            return []\n",
        "        \n",
        "        try: \n",
        "            # Vector search\n",
        "            query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
        "            vector_k = min(top_k * 2, len(self.documents))\n",
        "            distances, indices = self.index.search(query_embedding.astype('float32'), vector_k)\n",
        "\n",
        "            # BM25 keyword search\n",
        "            bm25_scores = self.bm25.get_scores(query.lower().split())\n",
        "\n",
        "            # merge and rerank\n",
        "            combined_results = []\n",
        "            for i, idx in enumerate(indices[0]):\n",
        "                if idx < len(self.documents):\n",
        "                    # normalise scores and combine\n",
        "                    vector_score = 1 / (1 + distances[0][i])  # convert distance to similarity\n",
        "                    bm25_score = bm25_scores[idx] if idx < len(bm25_scores) else 0\n",
        "\n",
        "                    combined_score = vector_score + bm25_score\n",
        "\n",
        "                    result = {\n",
        "                        'text': self.documents[idx],\n",
        "                        'metadata': self.document_metadata[idx],\n",
        "                        'combined_score': combined_score,\n",
        "                        'vector_score': vector_score,\n",
        "                        'bm25_score': bm25_score,\n",
        "                        'citation': f\"{self.document_metadata[idx]['filename']}, Page {self.document_metadata[idx]['page']}\"\n",
        "                    }\n",
        "                    combined_results.append(result)\n",
        "\n",
        "            # sort by combined score and take top k\n",
        "            combined_results.sort(key=lambda x: x['combined_score'], reverse=True)\n",
        "            final_results = combined_results[:top_k]\n",
        "\n",
        "            self.metrics['T_retrieve'] = time.time() - start_time\n",
        "            return final_results\n",
        "        \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during retrieval: {e}\")\n",
        "            return []\n",
        "        \n",
        "    def _save_data(self):\n",
        "        # Save FAISS index\n",
        "        try:\n",
        "            with open(os.path.join(self.persist_dir, 'documents.pkl'), 'wb') as f:\n",
        "                pickle.dump(self.documents, f)\n",
        "\n",
        "            with open(os.path.join(self.persist_dir, 'metadata.pkl'), 'wb') as f:\n",
        "                pickle.dump(self.document_metadata, f)\n",
        "\n",
        "            if self.index is not None:\n",
        "                faiss.write_index(self.index, os.path.join(self.persist_dir, 'faiss_index.bin'))\n",
        "\n",
        "            if self.bm25 is not None:\n",
        "                with open(os.path.join(self.persist_dir, 'bm25.pkl'), 'wb') as f:\n",
        "                    pickle.dump(self.bm25, f)\n",
        "        \n",
        "            logger.info(\"Saved ingestion data to disk\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error saving data: {e}\")\n",
        "\n",
        "cfo_rag = CFORAGPipeline()\n",
        "\n",
        "# Ingest documents from data directory\n",
        "print(\"=== Starting document ingestion ===\")\n",
        "ingestion_result = cfo_rag.ingest_documents(data_dir=\"./content/data\")\n",
        "print(f\"Processed: {ingestion_result['documents_processed']} PDFs\")\n",
        "print(f\"Created: {ingestion_result['chunks_created']} text chunks\")\n",
        "print(f\"Ingestion Time: {ingestion_result['ingestion_duration']:.2f} seconds\")\n",
        "\n",
        "# Test retrieval\n",
        "test_query = \"Net Interest Margin trend over the past 3 years\"\n",
        "retrieved_docs = cfo_rag.hybrid_retrieve(test_query, top_k=3)\n",
        "\n",
        "print(f\"\\n=== Retrieval Test ===\")\n",
        "print(f\"Query: {test_query}\")\n",
        "print(f\"Retrieved {len(retrieved_docs)} documents:\")\n",
        "\n",
        "\n",
        "if retrieved_docs:\n",
        "    for i, doc in enumerate(retrieved_docs, 1):\n",
        "        print(f\"\\nDocument {i}: {doc['citation']}\")\n",
        "        print(f\"Combined Score: {doc['combined_score']:.4f}\")\n",
        "        print(f\"Text Preview: {doc['text'][:150].replace(chr(10), ' ')}...\")  # Print first 150 chars\n",
        "else:\n",
        "    print(\"No documents retrieved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "540b7020",
      "metadata": {
        "id": "540b7020"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement baseline retrieval + generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Net Interest Margin (NIM) trend over last 5 quarters, values and 1–2 lines of explanation.\n",
        "    *   Expected: quarterly financial highlights.\n",
        "*   Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\n",
        "    *   Expected: Opex table + MD&A commentary.\n",
        "*   Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\n",
        "    *   Expected: Operating Income & Opex lines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bddc40",
      "metadata": {
        "id": "e7bddc40"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement benchmark runner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5"
      },
      "outputs": [],
      "source": [
        "# Example instrumentation schema\n",
        "import pandas as pd\n",
        "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
        "logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement optimizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3"
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s2am56tlpjY9",
      "metadata": {
        "id": "s2am56tlpjY9"
      },
      "source": [
        "testing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
