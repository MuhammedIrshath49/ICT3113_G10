{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammedIrshath49/ICT3113_G10/blob/main/Agent_CFO_Project_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO â€” Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is the starter notebook for your project. Follow the required structure below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6f8a4ed"
      },
      "source": [
        "Colab integrates well with GitHub, allowing you to clone repositories, save notebooks, and share your work.\n",
        "\n",
        "**1. Cloning a Repository**\n",
        "\n",
        "You can clone a public or private GitHub repository directly into your Colab environment using the `!git clone` command. For private repositories, you'll need to provide credentials."
      ],
      "id": "a6f8a4ed"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbeed6e6"
      },
      "source": [
        "# Clone a public repository\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# For a private repository, you might need to use credentials\n",
        "# !git clone https://<YOUR_GITHUB_USERNAME>:<YOUR_GITHUB_TOKEN>@github.com/<USERNAME>/<REPOSITORY>.git"
      ],
      "id": "dbeed6e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d74b9f6"
      },
      "source": [
        "**2. Saving a Notebook to GitHub**\n",
        "\n",
        "You can save your Colab notebook directly to GitHub. Go to `File > Save a copy to GitHub`. You'll be prompted to authorize Colab to access your GitHub account and then you can select the repository and commit message.\n",
        "\n",
        "**3. Loading a Notebook from GitHub**\n",
        "\n",
        "To open a notebook from GitHub, go to `File > Open notebook`. In the dialog, select the \"GitHub\" tab and enter the GitHub URL or search for the repository and notebook.\n",
        "\n",
        "**4. Authenticating with GitHub**\n",
        "\n",
        "If you need to perform actions like pushing changes to a private repository, you'll need to authenticate. You can use a Personal Access Token (PAT) with the necessary permissions. Store your PAT securely (e.g., in Colab's Secrets Manager) and use it in your commands."
      ],
      "id": "5d74b9f6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11f946f8"
      },
      "source": [
        "# Example of configuring git with your name and email\n",
        "!git config --global user.email \"you@example.com\"\n",
        "!git config --global user.name \"Your Name\"\n",
        "\n",
        "# Example of using a PAT for authentication (replace with your secret name)\n",
        "# from google.colab import userdata\n",
        "# github_token = userdata.get('github_pat')\n",
        "# !git remote set-url origin https://<YOUR_GITHUB_USERNAME>:$github_token@github.com/<USERNAME>/<REPOSITORY>.git"
      ],
      "id": "11f946f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eda7863"
      },
      "source": [
        "These are the basic steps to get you started with using GitHub in Google Colab."
      ],
      "id": "9eda7863"
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the companyâ€™s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4",
        "ExecuteTime": {
          "end_time": "2025-09-30T08:55:21.268657600Z",
          "start_time": "2025-09-30T08:55:21.203754400Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Example:\n",
        "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
        "\n",
        "COMPANY_NAME = \"DBS Bank\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3â€“5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e08f5a0",
      "metadata": {
        "id": "5e08f5a0",
        "ExecuteTime": {
          "end_time": "2025-09-30T09:08:36.387313200Z",
          "start_time": "2025-09-30T09:08:08.875497Z"
        },
        "colab": {
          "referenced_widgets": [
            "3730f9e1de7c4531816285fec9ce9557",
            "a4a2754f232f4cba93d3b8b8f509e034"
          ]
        },
        "outputId": "c0bdb508-30b8-4377-d5fc-ca94293d94f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "INFO:__main__:Initialized CFO RAG Pipeline\n",
            "INFO:__main__:Extracted 30 text chunks from content\\data\\2Q22_performance_summary.pdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Starting document ingestion ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Extracted 31 text chunks from content\\data\\2Q23_performance_summary.pdf\n",
            "INFO:__main__:Extracted 33 text chunks from content\\data\\2Q24_performance_summary.pdf\n",
            "INFO:__main__:Extracted 34 text chunks from content\\data\\2Q25_performance_summary.pdf\n",
            "INFO:__main__:Extracted 44 text chunks from content\\data\\4Q22_performance_summary.pdf\n",
            "INFO:__main__:Extracted 43 text chunks from content\\data\\4Q23_performance_summary.pdf\n",
            "INFO:__main__:Extracted 45 text chunks from content\\data\\4Q24_performance_summary.pdf\n",
            "INFO:__main__:Extracted 115 text chunks from content\\data\\DBS Annual Report 2023.pdf\n",
            "INFO:__main__:Extracted 114 text chunks from content\\data\\dbs-annual-report-2022.pdf\n",
            "INFO:__main__:Extracted 140 text chunks from content\\data\\dbs-annual-report-2024.pdf\n",
            "INFO:__main__:Extracted 19 text chunks from content\\data\\QuartelyResults_1Q23_CFO.pdf\n",
            "INFO:__main__:Extracted 17 text chunks from content\\data\\QuartelyResults_1Q24_CFO.pdf\n",
            "INFO:__main__:Extracted 18 text chunks from content\\data\\QuartelyResults_1Q25_CFO.pdf\n",
            "INFO:__main__:Extracted 30 text chunks from content\\data\\QuartelyResults_2Q23_CFO.pdf\n",
            "INFO:__main__:Extracted 30 text chunks from content\\data\\QuartelyResults_2Q24_CFO.pdf\n",
            "INFO:__main__:Extracted 29 text chunks from content\\data\\QuartelyResults_2Q25_CFO.pdf\n",
            "INFO:__main__:Extracted 18 text chunks from content\\data\\QuartelyResults_3Q23_CFO.pdf\n",
            "INFO:__main__:Extracted 21 text chunks from content\\data\\QuartelyResults_3Q24_CFO.pdf\n",
            "INFO:__main__:Extracted 31 text chunks from content\\data\\QuartelyResults_4Q23_CFO.pdf\n",
            "INFO:__main__:Extracted 30 text chunks from content\\data\\QuartelyResults_4Q24_CFO.pdf\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/28 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3730f9e1de7c4531816285fec9ce9557"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Saved ingestion data to disk\n",
            "INFO:__main__:Ingested 872 documents in 21.57 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 20 PDFs\n",
            "Created: 872 text chunks\n",
            "Ingestion Time: 21.57 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4a2754f232f4cba93d3b8b8f509e034"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Retrieval Test ===\n",
            "Query: Net Interest Margin trend over the past 3 years\n",
            "Retrieved 3 documents:\n",
            "\n",
            "Document 1: DBS Annual Report 2023, Page 13\n",
            "Combined Score: 11.3025\n",
            "Text Preview: 20 DBS ANNUAL REPORT 2023       BUILDING A SUSTAINABLE ADVANTAGE CFO statement We achieved a record performance for the third consecutive year with  t...\n",
            "\n",
            "Document 2: 2Q22_performance_summary, Page 7\n",
            "Combined Score: 11.0513\n",
            "Text Preview: DBS GROUP HOLDINGS LTD AND ITS SUBSIDIARIES    5    First Half    First-half net profit was $3.62 billion, 3% below the  previous yearâ€™s record. Busin...\n",
            "\n",
            "Document 3: QuartelyResults_1Q25_CFO, Page 5\n",
            "Combined Score: 5.1649\n",
            "Text Preview: 5 Net interest margin (%) 2.14 2.14 2.11 2.15 2.12 2.77 2.83 2.83 2.77 2.68 3,647 3,769 3,796 3,831 3,719 -142 1Q24 -175 2Q24 -199 3Q24 -103 4Q24 -38 ...\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement ingestion pipeline\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "# RAG related libararies\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz  # PyMuPDF for PDF processing\n",
        "from rank_bm25 import BM25Okapi\n",
        "import google.generativeai as genai # Gemini API for higher token limits\n",
        "\n",
        "# Initialise logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Tool for financial calculations\n",
        "class CalculatorTool:\n",
        "    def calculate_ratio(self, numerator: float, denominator: float, ratio_name: str = \"\") -> Dict[str, Any]:\n",
        "        try:\n",
        "            if denominator == 0:\n",
        "                return {\"error\": f\"Cannot calculate {ratio_name}: denominator is zero\"}\n",
        "\n",
        "            ratio = (numerator / denominator) * 100 if \"ratio\" in ratio_name.lower() else (numerator / denominator)\n",
        "            return {\n",
        "                \"ratio_name\": ratio_name,\n",
        "                \"numerator\": numerator,\n",
        "                \"denominator\": denominator,\n",
        "                \"result\": round(ratio, 2),\n",
        "                \"formula\": f\"{numerator} / {denominator}\"\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def trend_analysis(self, values: List[float], periods: List[str]) -> Dict[str, Any]:\n",
        "        if len(values) != len(periods):\n",
        "            return {\"error\": \"Values and periods must have the same length\"}\n",
        "\n",
        "        if len(values) < 2:\n",
        "            return {\"error\": \"Need at least two data points for trend analysis\"}\n",
        "\n",
        "        # Calculate period-over-period changes\n",
        "        changes = []\n",
        "        for i in range(1, len(values)):\n",
        "            if values[i-1] != 0:\n",
        "                pct_change = ((values[i] - values[i-1]) / values[i-1]) * 100\n",
        "                changes.append(round(pct_change, 2))\n",
        "            else:\n",
        "                changes.append(0)\n",
        "\n",
        "        return {\n",
        "            \"periods\": periods,\n",
        "            \"values\": values,\n",
        "            \"period_changes\": changes,\n",
        "            \"overall_trend\": \"increasing\" if values[-1] > values[0] else \"decreasing\",\n",
        "            \"average_change\": round(sum(changes) / len(changes), 2) if changes else 0\n",
        "        }\n",
        "\n",
        "\n",
        "# Tool for extracting table from dataset\n",
        "class TableExtractionTool:\n",
        "    def extract_financial_numbers(self, text: str) -> List[Dict[str, Any]]:\n",
        "        # Pattern for numbers with currency/percentage\n",
        "        patterns = [\n",
        "            r'(\\$|S\\$|USD|SGD)?\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(million|billion|thousand|m|bn|k)?',\n",
        "            r'(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(%|percent|basis points|bps)',\n",
        "            r'(NIM|CTI|ROE|ROA|CET1)\\s*[:=]?\\s*(\\d+(?:\\.\\d+)?)\\s*(%|bps)?'\n",
        "        ]\n",
        "\n",
        "        extracted = []\n",
        "        for pattern in patterns:\n",
        "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                extracted.append({\n",
        "                    \"text\": match.group(0),\n",
        "                    \"value\": match.group(2) if len(match.groups()) > 1 else match.group(1),\n",
        "                    \"context\": text[max(0, match.start()-50):match.end()+50]  # 50 chars before and after\n",
        "                })\n",
        "\n",
        "        return extracted\n",
        "\n",
        "    def parse_table_structure(self, text: str) -> Dict[str, Any]:\n",
        "        lines = text.split('\\n')\n",
        "        table_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            # Look for lines that might be table rows (have multiple numbers/columns)\n",
        "            if re.search(r'\\d.*\\d', line) and ('|' in line or '\\t' in line or len(re.findall(r'\\d+', line)) > 1):\n",
        "                table_lines.append(line.strip())\n",
        "\n",
        "        return {\n",
        "            \"potential_table_rows\": table_lines[:10], # Return first 10 rows\n",
        "            \"row_count\": len(table_lines)\n",
        "        }\n",
        "\n",
        "\n",
        "# Tool for comparing info across docs\n",
        "class DocumentComparisonTool:\n",
        "    def compare_metrics_across_docs(self, documents: List[Dict], metric_name: str) -> Dict[str, Any]:\n",
        "        comparisons = []\n",
        "        for doc in documents:\n",
        "            # Extract metric from document text\n",
        "            numbers = re.findall(r'\\d+(?:\\.\\d+)?', doc.get('text', ''))\n",
        "            filename = doc.get('metadata', {}).get('filename', 'unknown')\n",
        "\n",
        "            comparisons.append({\n",
        "                \"document\": filename,\n",
        "                \"metric_candidates\": numbers[:5], # Return first 5 found numbers\n",
        "                \"text_snippet\": doc.get('text', '')[:200] # First 200 chars\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            \"metric_name\": metric_name,\n",
        "            \"comparisons\": comparisons\n",
        "        }\n",
        "\n",
        "# RAG functions\n",
        "class CFORAGPipeline:\n",
        "    def __init__(self, persist_dir=\"./cfo_rag_data\"):\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.persist_dir = persist_dir\n",
        "        self.documents = []\n",
        "        self.document_metadata = []\n",
        "        self.index = None\n",
        "        self.bm25 = None\n",
        "\n",
        "        # Initialise tools\n",
        "        self.calculator_tool = CalculatorTool()\n",
        "        self.table_extraction_tool = TableExtractionTool()\n",
        "        self.doc_comparison_tool = DocumentComparisonTool()\n",
        "\n",
        "        # Create directory for persistence\n",
        "        os.makedirs(self.persist_dir, exist_ok=True)\n",
        "\n",
        "        # Performance tracking\n",
        "        self.metrics = {\n",
        "            'T_ingest': 0,\n",
        "            'T_retrieve': 0,\n",
        "            'T_rerank': 0,\n",
        "            'documents_ingested': 0,\n",
        "            }\n",
        "\n",
        "        logger.info(\"Initialized CFO RAG Pipeline\")\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:\n",
        "        # for document chunking\n",
        "        chunks = []\n",
        "\n",
        "        try:\n",
        "            doc = fitz.open(pdf_path)\n",
        "            filename = Path(pdf_path).stem\n",
        "\n",
        "            for page_num in range(len(doc)):\n",
        "                page = doc[page_num]\n",
        "                text = page.get_text()\n",
        "\n",
        "                if text.strip():\n",
        "                    # split by sentences/paragraphs for chunking\n",
        "                    paragraphs = text.split('\\n\\n')\n",
        "\n",
        "                    for i, paragraph in enumerate(paragraphs):\n",
        "                        if len(paragraph.strip()) > 50:\n",
        "                            chunk = {\n",
        "                                'text': paragraph.strip(),\n",
        "                                'metadata': {\n",
        "                                    'filename': filename,\n",
        "                                    'page': page_num + 1,\n",
        "                                    'chunk_id': f\"{filename}_p{page_num+1}_c{i+1}\",\n",
        "                                    'source_type': self._classify_document_type(filename)\n",
        "                                }\n",
        "                            }\n",
        "                            chunks.append(chunk)\n",
        "\n",
        "            doc.close()\n",
        "            logger.info(f\"Extracted {len(chunks)} text chunks from {pdf_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text from {pdf_path}: {e}\")\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def _classify_document_type(self, filename: str) -> str:\n",
        "        # based on filename\n",
        "        filename_lower = filename.lower()\n",
        "        if 'annual' in filename_lower:\n",
        "            return 'annual_report'\n",
        "        elif any(q in filename_lower for q in ['1q', '2q', '3q', '4q', 'quarter']):\n",
        "            return 'quarterly_report'\n",
        "        elif 'performance' in filename_lower:\n",
        "            return 'performance_summary'\n",
        "        else:\n",
        "            return 'financial_report'\n",
        "\n",
        "        # document ingestion from data directory containing PDFs/datasets\n",
        "    def ingest_documents(self, data_dir: str = \"./content/data\") -> Dict[str, Any]:\n",
        "        # record time taken to ingest the documents\n",
        "        start_time = time.time()\n",
        "\n",
        "        pdf_files = list(Path(data_dir).glob(\"*.pdf\"))\n",
        "        if not pdf_files:\n",
        "            raise ValueError(f\"No PDF files found in {data_dir}\")\n",
        "\n",
        "        all_chunks = []\n",
        "\n",
        "        # process each PDF file\n",
        "        for pdf_file in pdf_files:\n",
        "            chunks = self.extract_text_from_pdf(str(pdf_file))\n",
        "            all_chunks.extend(chunks)\n",
        "\n",
        "        # separate text and metadata\n",
        "        texts = [chunk['text'] for chunk in all_chunks]\n",
        "        metadatas = [chunk['metadata'] for chunk in all_chunks]\n",
        "\n",
        "        self.documents = texts\n",
        "        self.document_metadata = metadatas\n",
        "\n",
        "        # Create embeddings\n",
        "        embeddings = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dimension)\n",
        "        self.index.add(embeddings.astype('float32'))\n",
        "\n",
        "        # create BM25 index for keyword search\n",
        "        tokenised_docs = [doc.lower().split() for doc in texts]\n",
        "        self.bm25 = BM25Okapi(tokenised_docs)\n",
        "\n",
        "        # save data\n",
        "        self._save_data()\n",
        "\n",
        "        # update metrics\n",
        "        self.metrics['T_ingest'] = time.time() - start_time\n",
        "        self.metrics['documents_ingested'] = len(texts)\n",
        "        logger.info(f\"Ingested {len(texts)} documents in {self.metrics['T_ingest']:.2f} seconds\")\n",
        "\n",
        "        return {\n",
        "            'documents_processed': len(pdf_files),\n",
        "            'chunks_created': len(texts),\n",
        "            'ingestion_duration': self.metrics['T_ingest']\n",
        "        }\n",
        "\n",
        "    # retrieve relevant documents using hybrid search\n",
        "    def hybrid_retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
        "        if not self.documents or self.index is None:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            # --- Start retrieval timer ---\n",
        "            start_retrieve = time.time()\n",
        "\n",
        "            # Vector search\n",
        "            query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
        "            vector_k = min(top_k * 2, len(self.documents))\n",
        "            distances, indices = self.index.search(query_embedding.astype('float32'), vector_k)\n",
        "\n",
        "            # BM25 keyword search\n",
        "            bm25_scores = self.bm25.get_scores(query.lower().split())\n",
        "\n",
        "            # Stop retrieval timer (only covers FAISS + BM25)\n",
        "            self.metrics['T_retrieve'] = time.time() - start_retrieve\n",
        "\n",
        "            # --- Start rerank timer ---\n",
        "            start_rerank = time.perf_counter()\n",
        "\n",
        "            combined_results = []\n",
        "            for i, idx in enumerate(indices[0]):\n",
        "                if idx < len(self.documents):\n",
        "                    vector_score = 1 / (1 + distances[0][i])\n",
        "                    bm25_score = bm25_scores[idx] if idx < len(bm25_scores) else 0\n",
        "                    combined_score = vector_score + bm25_score\n",
        "\n",
        "                    result = {\n",
        "                        'text': self.documents[idx],\n",
        "                        'metadata': self.document_metadata[idx],\n",
        "                        'combined_score': combined_score,\n",
        "                        'vector_score': vector_score,\n",
        "                        'bm25_score': bm25_score,\n",
        "                        'citation': f\"{self.document_metadata[idx]['filename']}, Page {self.document_metadata[idx]['page']}\"\n",
        "                    }\n",
        "                    combined_results.append(result)\n",
        "\n",
        "            # Sorting and taking top_k\n",
        "            combined_results.sort(key=lambda x: x['combined_score'], reverse=True)\n",
        "            final_results = combined_results[:top_k]\n",
        "\n",
        "            # Stop rerank timer (store in ms)\n",
        "            self.metrics['T_rerank'] = (time.perf_counter() - start_rerank) * 1000\n",
        "\n",
        "            return final_results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during retrieval: {e}\")\n",
        "            return []\n",
        "\n",
        "\n",
        "    def _save_data(self):\n",
        "        # Save FAISS index\n",
        "        try:\n",
        "            with open(os.path.join(self.persist_dir, 'documents.pkl'), 'wb') as f:\n",
        "                pickle.dump(self.documents, f)\n",
        "\n",
        "            with open(os.path.join(self.persist_dir, 'metadata.pkl'), 'wb') as f:\n",
        "                pickle.dump(self.document_metadata, f)\n",
        "\n",
        "            if self.index is not None:\n",
        "                faiss.write_index(self.index, os.path.join(self.persist_dir, 'faiss_index.bin'))\n",
        "\n",
        "            if self.bm25 is not None:\n",
        "                with open(os.path.join(self.persist_dir, 'bm25.pkl'), 'wb') as f:\n",
        "                    pickle.dump(self.bm25, f)\n",
        "\n",
        "            logger.info(\"Saved ingestion data to disk\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error saving data: {e}\")\n",
        "\n",
        "cfo_rag = CFORAGPipeline()\n",
        "\n",
        "# Ingest documents from data directory\n",
        "print(\"=== Starting document ingestion ===\")\n",
        "ingestion_result = cfo_rag.ingest_documents(data_dir=\"./content/data\")\n",
        "print(f\"Processed: {ingestion_result['documents_processed']} PDFs\")\n",
        "print(f\"Created: {ingestion_result['chunks_created']} text chunks\")\n",
        "print(f\"Ingestion Time: {ingestion_result['ingestion_duration']:.2f} seconds\")\n",
        "\n",
        "# Test retrieval\n",
        "test_query = \"Net Interest Margin trend over the past 3 years\"\n",
        "retrieved_docs = cfo_rag.hybrid_retrieve(test_query, top_k=3)\n",
        "\n",
        "print(f\"\\n=== Retrieval Test ===\")\n",
        "print(f\"Query: {test_query}\")\n",
        "print(f\"Retrieved {len(retrieved_docs)} documents:\")\n",
        "\n",
        "\n",
        "if retrieved_docs:\n",
        "    for i, doc in enumerate(retrieved_docs, 1):\n",
        "        print(f\"\\nDocument {i}: {doc['citation']}\")\n",
        "        print(f\"Combined Score: {doc['combined_score']:.4f}\")\n",
        "        print(f\"Text Preview: {doc['text'][:150].replace(chr(10), ' ')}...\")  # Print first 150 chars\n",
        "else:\n",
        "    print(\"No documents retrieved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540b7020",
      "metadata": {
        "id": "540b7020",
        "ExecuteTime": {
          "end_time": "2025-09-30T09:09:29.110581200Z",
          "start_time": "2025-09-30T09:08:44.027346100Z"
        },
        "colab": {
          "referenced_widgets": [
            "62db07293aa34fbe9ab7c7a850a1cf01"
          ]
        },
        "outputId": "38d2df88-6d4e-4175-906e-4bb27de80c5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62db07293aa34fbe9ab7c7a850a1cf01"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Baseline Answer ===\n",
            "The Net Interest Margin (NIM) trend for DBS Group over the past three years (2021-2023) is as follows:\n",
            "\n",
            "*   **2021**: The Net Interest Margin had been declining since 2019 (2Q22_performance_summary, Page 7). The NIM for the first half of 2021 was 1.47% (calculated as 1.52% for H1 2022 minus the 5 basis points increase from a year ago) (2Q22_performance_summary, Page 7).\n",
            "*   **2022**: The Net Interest Margin began to rise, with the first-half NIM at 1.52% (2Q22_performance_summary, Page 7). For the full year, the net interest margin was 1.75%, calculated from the 2023 full-year NIM of 2.15% which expanded by 40 basis points from 2022 (DBS Annual Report 2023, Page 13). The quarterly net interest margin increased by 62 basis points over the four quarters of 2022 (DBS Annual Report 2023, Page 13).\n",
            "*   **2023**: The full-year Net Interest Margin expanded to 2.15% (DBS Annual Report 2023, Page 13). The quarterly net interest margin continued to rise in the first three quarters before easing in the fourth quarter (DBS Annual Report 2023, Page 13).\n",
            "\n",
            "Citations: ['DBS Annual Report 2023, Page 13', '2Q22_performance_summary, Page 7', 'QuartelyResults_1Q25_CFO, Page 5']\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement baseline retrieval + generation\n",
        "# =============================\n",
        "# Part 4. Baseline Pipeline\n",
        "# =============================\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyD9nOIYeshnVBJfV9Im7OUJz85CunBka_I\"\n",
        "\n",
        "# Configure Gemini using environment variable\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# Load model\n",
        "llm_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "\n",
        "def baseline_pipeline(query: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Runs naive RAG pipeline: retrieval + single LLM call.\n",
        "    \"\"\"\n",
        "    # Retrieve relevant docs\n",
        "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k)\n",
        "    if not retrieved_docs:\n",
        "        return {\"error\": \"No documents retrieved.\"}\n",
        "\n",
        "    # Build context\n",
        "    context = \"\\n\\n\".join([f\"{doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
        "\n",
        "    # Prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a financial analyst assistant.\n",
        "Answer the user query based only on the provided reports.\n",
        "Include citations (filename + page).\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Reports:\n",
        "{context}\n",
        "\"\"\"\n",
        "    # Call LLM\n",
        "    response = llm_model.generate_content(prompt)\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
        "        \"raw_docs\": [doc[\"text\"][:300] for doc in retrieved_docs],  # preview only\n",
        "        \"answer\": response.text.strip()\n",
        "    }\n",
        "\n",
        "# ðŸ”¹ Example run\n",
        "result = baseline_pipeline(\"Net Interest Margin trend over the past 3 years\", top_k=3)\n",
        "print(\"=== Baseline Answer ===\")\n",
        "print(result[\"answer\"])\n",
        "print(\"\\nCitations:\", result[\"citations\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Net Interest Margin (NIM) trend over last 5 quarters, values and 1â€“2 lines of explanation.\n",
        "    *   Expected: quarterly financial highlights.\n",
        "*   Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\n",
        "    *   Expected: Opex table + MD&A commentary.\n",
        "*   Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\n",
        "    *   Expected: Operating Income & Opex lines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bddc40",
      "metadata": {
        "id": "e7bddc40",
        "ExecuteTime": {
          "end_time": "2025-09-30T09:11:32.887486200Z",
          "start_time": "2025-09-30T09:09:32.019818900Z"
        },
        "colab": {
          "referenced_widgets": [
            "089d43fc6c244984a1254da6f2eb4056",
            "6bba50f104f14d8892bc33fc5c5dfa47",
            "bf12be2cc7504b719a407b7e34a29343"
          ]
        },
        "outputId": "1a92103c-66f9-4cd8-c578-1606be95d159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running Benchmark: NIM Trend ===\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "089d43fc6c244984a1254da6f2eb4056"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Timing Summary for Query: Net Interest Margin (NIM) trend over last 5 quarters, values and 1â€“2 lines of explanation. ===\n",
            "| Stage    | Time        |\n",
            "|----------|-------------|\n",
            "| Retrieve | 0.0229 sec  |\n",
            "| Rerank   | 0.046 ms    |\n",
            "| Reason   | 11.0974 sec |\n",
            "| Generate | 4.6763 sec  |\n",
            "| Total    | 15.7966 sec |\n",
            "\n",
            "=== Running Benchmark: Opex YoY ===\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bba50f104f14d8892bc33fc5c5dfa47"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Timing Summary for Query: Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A. ===\n",
            "| Stage    | Time        |\n",
            "|----------|-------------|\n",
            "| Retrieve | 0.0315 sec  |\n",
            "| Rerank   | 0.051 ms    |\n",
            "| Reason   | 20.6879 sec |\n",
            "| Generate | 7.2774 sec  |\n",
            "| Total    | 27.9968 sec |\n",
            "\n",
            "=== Running Benchmark: Cost-to-Income Ratio ===\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf12be2cc7504b719a407b7e34a29343"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Timing Summary for Query: Cost-to-Income Ratio (CTI) for last 3 years; show working + implications. ===\n",
            "| Stage    | Time        |\n",
            "|----------|-------------|\n",
            "| Retrieve | 0.0279 sec  |\n",
            "| Rerank   | 0.073 ms    |\n",
            "| Reason   | 63.7366 sec |\n",
            "| Generate | 13.2889 sec |\n",
            "| Total    | 77.0534 sec |\n",
            "\n",
            "=== NIM Trend ===\n",
            "Query: Net Interest Margin (NIM) trend over last 5 quarters, values and 1â€“2 lines of explanation.\n",
            "Answer: **Net Interest Margin (NIM) Trend (Last 5 Quarters)**\n",
            "\n",
            "The Group's Net Interest Margin (NIM) has shown relative stability over the past five quarters, fluctuating within a narrow range.\n",
            "\n",
            "*   **1Q24:** 2.14%\n",
            "*   **2Q24:** 2.14%\n",
            "*   **3Q24:** 2.11%\n",
            "*   **4Q24:** 2.15%\n",
            "*   **1Q25:** 2.12%\n",
            "\n",
            "The NIM remained stable between 2.11% and 2.15% over this period. The slight decline observed in 1Q25 was attributed to lower interest rates [Reasoning].\n",
            "\n",
            "Citations: ['dbs-annual-report-2022, Page 15', 'QuartelyResults_4Q23_CFO, Page 7', 'QuartelyResults_1Q25_CFO, Page 5', 'QuartelyResults_1Q23_CFO, Page 5', 'QuartelyResults_1Q24_CFO, Page 5']\n",
            "\n",
            "=== Opex YoY ===\n",
            "Query: Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\n",
            "Answer: Here is a summary of the Operating Expenses (Opex) Year-over-Year (YoY) for the last three years and their top drivers:\n",
            "\n",
            "**1. FY24 Operating Expenses (Opex)**\n",
            "*   **Opex Figure:** S$8,895 million [1. FY24 Operating Expenses (Opex)]\n",
            "*   **YoY Change:** +10% [1. FY24 Operating Expenses (Opex)]\n",
            "*   **Top Driver:**\n",
            "    1.  The acquisition of Citi Taiwan accounted for 3 percentage points of the overall 10% increase in expenses. [1. FY24 Operating Expenses (Opex)]\n",
            "\n",
            "**2. FY23 Operating Expenses (Opex)**\n",
            "*   **Opex Figure:** S$8,056 million [2. FY23 Operating Expenses (Opex)]\n",
            "*   **YoY Change:** +14% (from S$7,090 million in FY22) [2. FY23 Operating Expenses (Opex)]\n",
            "*   **Top Drivers:**\n",
            "    1.  Increase in Staff expenses (+15% YoY to S$5,036 million). [2. FY23 Operating Expenses (Opex)]\n",
            "    2.  Increase in Other expenses (+11% YoY to S$3,020 million). [2. FY23 Operating Expenses (Opex)]\n",
            "\n",
            "**3. FY22 Operating Expenses (Opex)**\n",
            "*   **Opex Figure:** S$7,090 million [3. FY22 Operating Expenses (Opex)]\n",
            "*   **YoY Change:** +14% (from FY21) [2. FY23 Operating Expenses (Opex) mentions FY22 as the base for FY23's +14% increase from FY21]\n",
            "*   **Top Drivers:**\n",
            "    *   No specific drivers for FY22 Opex increase are detailed within the provided MD&A sections for the full-year comparison. [3. FY22 Operating Expenses (Opex)]\n",
            "\n",
            "Citations: ['QuartelyResults_4Q24_CFO, Page 3', 'QuartelyResults_1Q25_CFO, Page 3', 'QuartelyResults_4Q23_CFO, Page 5', 'QuartelyResults_4Q23_CFO, Page 23', 'QuartelyResults_3Q23_CFO, Page 4']\n",
            "\n",
            "=== Cost-to-Income Ratio ===\n",
            "Query: Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\n",
            "Answer: Here is the Cost-to-Income Ratio (CTI) for the last 3 years, including working and implications:\n",
            "\n",
            "### Cost-to-Income Ratio (CTI) for the Last 3 Years\n",
            "\n",
            "The Cost-to-Income Ratio (CTI) has shown a positive trend, decreasing significantly from FY22 to FY23 and then stabilizing at a favorable level.\n",
            "\n",
            "---\n",
            "\n",
            "**1. FY24 (Based on 9M24 data)**\n",
            "\n",
            "*   **CTI:** 39%\n",
            "*   **Working:**\n",
            "    *   The CTI for 9M24 is explicitly stated as 39% in the report.\n",
            "    *   **Source:** QuartelyResults_3Q24_CFO, Page 14, states \"9M cost-income ratio stable at 39%\".\n",
            "    *   *(Note on Discrepancy):* While a direct calculation using stated Total Expenses (6,041 S$m from Staff 3,691 S$m + Other 2,350 S$m) and Total Income (16,800 S$m) yields approximately 36.0%, we prioritize the explicitly reported and graphically presented CTI of 39% as provided in the source.\n",
            "*   **Implications:** The CTI has remained stable at 39% through the first nine months of FY24. This suggests continued strong cost management and operational efficiency, building upon the improvement seen in the previous year. The report indicates that while expenses increased by 10%, total income also rose by 11%, allowing for this stability in the ratio.\n",
            "\n",
            "---\n",
            "\n",
            "**2. FY23**\n",
            "\n",
            "*   **CTI:** 39%\n",
            "*   **Working:**\n",
            "    *   The full-year underlying CTI for FY23 is explicitly stated in the report.\n",
            "    *   **Source:** QuartelyResults_4Q23_CFO, Page 12, explicitly states \"Full-year underlying cost-income ratio at 39%\" for FY23.\n",
            "    *   *Calculation for validation:*\n",
            "        *   Total Expenses (FY23) = Staff expenses (5,036 S$m) + Other expenses (3,020 S$m) = 8,056 S$m.\n",
            "        *   Implied Total Income (FY23) = Total Expenses / CTI = 8,056 S$m / 0.39 â‰ˆ 20,656.41 S$m.\n",
            "        *   Calculated CTI = 8,056 S$m / 20,656.41 S$m â‰ˆ 39%. This calculation is consistent with the stated figure.\n",
            "*   **Implications:** A significant improvement in efficiency was achieved in FY23, bringing the CTI down by 4 percentage points from FY22. This indicates better cost control relative to income generation, reflecting enhanced operational efficiency.\n",
            "\n",
            "---\n",
            "\n",
            "**3. FY22**\n",
            "\n",
            "*   **CTI:** 43%\n",
            "*   **Working:**\n",
            "    *   The CTI for FY22 is clearly indicated in a chart within the report.\n",
            "    *   **Source:** QuartelyResults_4Q23_CFO, Page 12, chart clearly indicates CTI for FY22 as 43%.\n",
            "    *   *Calculation for validation:*\n",
            "        *   Total Expenses (FY22) = Staff expenses (4,376 S$m) + Other expenses (2,714 S$m) = 7,090 S$m.\n",
            "        *   Implied Total Income (FY22) = Total Expenses / CTI = 7,090 S$m / 0.43 â‰ˆ 16,488.37 S$m.\n",
            "        *   Calculated CTI = 7,090 S$m / 16,488.37 S$m â‰ˆ 43%. This calculation is consistent with the stated figure.\n",
            "*   **Implications:** This figure serves as the baseline, highlighting that the company had a higher cost burden relative to its income compared to subsequent years. This was the least efficient year in the observed period.\n",
            "\n",
            "---\n",
            "\n",
            "**Overall Trend and Implications:**\n",
            "\n",
            "The company has successfully improved its operational efficiency over the last three years. The Cost-to-Income Ratio significantly decreased from **43% in FY22** to **39% in FY23**, and this improved efficiency has been maintained through **9M24 (39%)**. This positive trend indicates strong cost management capabilities and effective income generation relative to operational expenses, which is a key indicator for profitability and financial health. The stability around 39% suggests that efficiency gains have been sustained and potentially embedded into the company's operations.\n",
            "\n",
            "Citations: ['QuartelyResults_3Q24_CFO, Page 2', 'QuartelyResults_3Q24_CFO, Page 14', 'QuartelyResults_3Q23_CFO, Page 11', 'QuartelyResults_1Q23_CFO, Page 10', 'QuartelyResults_4Q23_CFO, Page 12']\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement benchmark runner\n",
        "# =============================\n",
        "# Part 5. Benchmark Runner\n",
        "# =============================\n",
        "\n",
        "benchmark_queries = [\n",
        "    {\n",
        "        \"name\": \"NIM Trend\",\n",
        "        \"query\": \"Net Interest Margin (NIM) trend over last 5 quarters, values and 1â€“2 lines of explanation.\",\n",
        "        \"expected\": \"Quarterly financial highlights\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Opex YoY\",\n",
        "        \"query\": \"Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\",\n",
        "        \"expected\": \"Opex table + MD&A commentary\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Cost-to-Income Ratio\",\n",
        "        \"query\": \"Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\",\n",
        "        \"expected\": \"Operating Income & Opex lines\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# =============================\n",
        "# Benchmark Runner with Instrumentation\n",
        "# =============================\n",
        "\n",
        "def run_benchmark_instrumented(queries, top_k=5):\n",
        "    results = []\n",
        "    for q in queries:\n",
        "        print(f\"\\n=== Running Benchmark: {q['name']} ===\")\n",
        "        output = instrumented_pipeline(q[\"query\"], top_k=top_k)\n",
        "        results.append({\n",
        "            \"name\": q[\"name\"],\n",
        "            \"query\": q[\"query\"],\n",
        "            \"expected\": q[\"expected\"],\n",
        "            \"citations\": output.get(\"citations\", []),\n",
        "            \"answer\": output.get(\"answer\", \"Error: no answer\")\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# ðŸ”¹ Run the benchmarks\n",
        "benchmark_results = run_benchmark_instrumented(benchmark_queries, top_k=5)\n",
        "\n",
        "# Show answers\n",
        "for res in benchmark_results:\n",
        "    print(f\"\\n=== {res['name']} ===\")\n",
        "    print(f\"Query: {res['query']}\")\n",
        "    print(f\"Answer: {res['answer']}\\n\")\n",
        "    print(f\"Citations: {res['citations']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5",
        "ExecuteTime": {
          "end_time": "2025-09-30T09:13:04.577246400Z",
          "start_time": "2025-09-30T09:11:32.887486200Z"
        },
        "colab": {
          "referenced_widgets": [
            "58a073582eff4cf9acde0e668760325c",
            "6fc9f4d4c6aa4dc9ad16c6c6afd5afa0",
            "914baea189254a3b8f01d037fb111acc"
          ]
        },
        "outputId": "c3fbb139-07da-4690-9d05-d7a1630539b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running Instrumented Benchmark: NIM Trend ===\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58a073582eff4cf9acde0e668760325c"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Timing Summary for Query: Net Interest Margin (NIM) trend over last 5 quarters, values and 1â€“2 lines of explanation. ===\n",
            "| Stage    | Time        |\n",
            "|----------|-------------|\n",
            "| Retrieve | 0.0271 sec  |\n",
            "| Rerank   | 0.044 ms    |\n",
            "| Reason   | 10.2358 sec |\n",
            "| Generate | 5.1836 sec  |\n",
            "| Total    | 15.4464 sec |\n",
            "\n",
            "=== Running Instrumented Benchmark: Opex YoY ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kerwin Loh\\AppData\\Local\\Temp\\ipykernel_14456\\1836018613.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  logs = pd.concat([logs, pd.DataFrame([new_row])], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fc9f4d4c6aa4dc9ad16c6c6afd5afa0"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Timing Summary for Query: Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A. ===\n",
            "| Stage    | Time        |\n",
            "|----------|-------------|\n",
            "| Retrieve | 0.0334 sec  |\n",
            "| Rerank   | 0.131 ms    |\n",
            "| Reason   | 22.2798 sec |\n",
            "| Generate | 9.0138 sec  |\n",
            "| Total    | 31.3290 sec |\n",
            "\n",
            "=== Running Instrumented Benchmark: Cost-to-Income Ratio ===\n"
          ]
        },
        {
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "914baea189254a3b8f01d037fb111acc"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Timing Summary for Query: Cost-to-Income Ratio (CTI) for last 3 years; show working + implications. ===\n",
            "| Stage    | Time        |\n",
            "|----------|-------------|\n",
            "| Retrieve | 0.0338 sec  |\n",
            "| Rerank   | 0.041 ms    |\n",
            "| Reason   | 35.2121 sec |\n",
            "| Generate | 9.6308 sec  |\n",
            "| Total    | 44.8768 sec |\n"
          ]
        },
        {
          "data": {
            "text/plain": "                                               Query  T_ingest (sec)  \\\n0  Net Interest Margin (NIM) trend over last 5 qu...       21.565022   \n1  Operating Expenses (Opex) YoY for last 3 years...       21.565022   \n2  Cost-to-Income Ratio (CTI) for last 3 years; s...       21.565022   \n\n   T_retrieve (sec)  T_rerank (ms)  T_reason (sec)  T_generate (sec)  \\\n0          0.027091         0.0444       10.235753          5.183600   \n1          0.033355         0.1314       22.279808          9.013831   \n2          0.033838         0.0413       35.212143          9.630805   \n\n   T_total (sec) Tokens CacheHits                       Tools  \n0      15.446443   None         0  [Retriever, Reranker, LLM]  \n1      31.329000   None         0  [Retriever, Reranker, LLM]  \n2      44.876786   None         0  [Retriever, Reranker, LLM]  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Query</th>\n      <th>T_ingest (sec)</th>\n      <th>T_retrieve (sec)</th>\n      <th>T_rerank (ms)</th>\n      <th>T_reason (sec)</th>\n      <th>T_generate (sec)</th>\n      <th>T_total (sec)</th>\n      <th>Tokens</th>\n      <th>CacheHits</th>\n      <th>Tools</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Net Interest Margin (NIM) trend over last 5 qu...</td>\n      <td>21.565022</td>\n      <td>0.027091</td>\n      <td>0.0444</td>\n      <td>10.235753</td>\n      <td>5.183600</td>\n      <td>15.446443</td>\n      <td>None</td>\n      <td>0</td>\n      <td>[Retriever, Reranker, LLM]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Operating Expenses (Opex) YoY for last 3 years...</td>\n      <td>21.565022</td>\n      <td>0.033355</td>\n      <td>0.1314</td>\n      <td>22.279808</td>\n      <td>9.013831</td>\n      <td>31.329000</td>\n      <td>None</td>\n      <td>0</td>\n      <td>[Retriever, Reranker, LLM]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cost-to-Income Ratio (CTI) for last 3 years; s...</td>\n      <td>21.565022</td>\n      <td>0.033838</td>\n      <td>0.0413</td>\n      <td>35.212143</td>\n      <td>9.630805</td>\n      <td>44.876786</td>\n      <td>None</td>\n      <td>0</td>\n      <td>[Retriever, Reranker, LLM]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =============================\n",
        "# Part 6. Instrumentation (Final Version)\n",
        "# =============================\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from tabulate import tabulate  # pretty summary tables\n",
        "\n",
        "# Create logs DataFrame\n",
        "logs = pd.DataFrame(columns=[\n",
        "    'Query',\n",
        "    'T_ingest (sec)', 'T_retrieve (sec)', 'T_rerank (ms)', 'T_reason (sec)',\n",
        "    'T_generate (sec)', 'T_total (sec)',\n",
        "    'Tokens', 'CacheHits', 'Tools'\n",
        "])\n",
        "\n",
        "def instrumented_pipeline(query: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Runs pipeline with instrumentation (timing + usage logging).\n",
        "    \"\"\"\n",
        "    global logs\n",
        "    timings = {}\n",
        "    start_total = time.time()\n",
        "\n",
        "    # --- Retrieval ---\n",
        "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k)\n",
        "    timings['T_retrieve'] = cfo_rag.metrics.get('T_retrieve', 0)\n",
        "    timings['T_rerank']  = cfo_rag.metrics.get('T_rerank', 0)  # already in ms\n",
        "\n",
        "    if not retrieved_docs:\n",
        "        return {\"error\": \"No documents retrieved.\"}\n",
        "\n",
        "    # --- Build context ---\n",
        "    context = \"\\n\\n\".join([f\"{doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
        "\n",
        "    # --- Reasoning step ---\n",
        "    start_reason = time.time()\n",
        "    reasoning_prompt = f\"\"\"\n",
        "    Summarize the key financial figures and trends in a structured way.\n",
        "    Do not generate the final answer yet.\n",
        "\n",
        "    Query: {query}\n",
        "    Reports:\n",
        "    {context}\n",
        "    \"\"\"\n",
        "    reasoning_output = llm_model.generate_content(reasoning_prompt)\n",
        "    timings['T_reason'] = time.time() - start_reason\n",
        "\n",
        "    # --- Generation step ---\n",
        "    start_generate = time.time()\n",
        "    final_prompt = f\"\"\"\n",
        "    You are a financial analyst assistant.\n",
        "    Based on the reasoning and reports, provide the final answer with citations.\n",
        "\n",
        "    Reasoning:\n",
        "    {reasoning_output.text}\n",
        "\n",
        "    Query: {query}\n",
        "    \"\"\"\n",
        "    response = llm_model.generate_content(final_prompt)\n",
        "    timings['T_generate'] = time.time() - start_generate\n",
        "\n",
        "    # --- Total ---\n",
        "    timings['T_total'] = time.time() - start_total\n",
        "\n",
        "    # --- Log row ---\n",
        "    new_row = {\n",
        "        'Query': query,\n",
        "        'T_ingest (sec)': cfo_rag.metrics.get('T_ingest', 0),\n",
        "        'T_retrieve (sec)': timings['T_retrieve'],\n",
        "        'T_rerank (ms)': timings['T_rerank'],\n",
        "        'T_reason (sec)': timings['T_reason'],\n",
        "        'T_generate (sec)': timings['T_generate'],\n",
        "        'T_total (sec)': timings['T_total'],\n",
        "        'Tokens': None,\n",
        "        'CacheHits': 0,\n",
        "        'Tools': ['Retriever', 'Reranker', 'LLM']\n",
        "    }\n",
        "    logs = pd.concat([logs, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    # --- Print per-query summary ---\n",
        "    summary = [\n",
        "        [\"Retrieve\", f\"{timings['T_retrieve']:.4f} sec\"],\n",
        "        [\"Rerank\",   f\"{timings['T_rerank']:.3f} ms\"],\n",
        "        [\"Reason\",   f\"{timings['T_reason']:.4f} sec\"],\n",
        "        [\"Generate\", f\"{timings['T_generate']:.4f} sec\"],\n",
        "        [\"Total\",    f\"{timings['T_total']:.4f} sec\"],\n",
        "    ]\n",
        "    print(f\"\\n=== Timing Summary for Query: {query} ===\")\n",
        "    print(tabulate(summary, headers=[\"Stage\", \"Time\"], tablefmt=\"github\"))\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
        "        \"reasoning\": reasoning_output.text.strip(),\n",
        "        \"answer\": response.text.strip()\n",
        "    }\n",
        "\n",
        "\n",
        "def run_benchmark_instrumented(queries, top_k=5):\n",
        "    results = []\n",
        "    for q in queries:\n",
        "        print(f\"\\n=== Running Instrumented Benchmark: {q['name']} ===\")\n",
        "        output = instrumented_pipeline(q[\"query\"], top_k=top_k)\n",
        "        results.append({\n",
        "            \"name\": q[\"name\"],\n",
        "            \"query\": q[\"query\"],\n",
        "            \"expected\": q[\"expected\"],\n",
        "            \"citations\": output.get(\"citations\", []),\n",
        "            \"reasoning\": output.get(\"reasoning\", \"N/A\"),\n",
        "            \"answer\": output.get(\"answer\", \"Error: no answer\")\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# ðŸ”¹ Run instrumented benchmarks\n",
        "benchmark_results_instrumented = run_benchmark_instrumented(benchmark_queries, top_k=5)\n",
        "\n",
        "# ðŸ”¹ Show instrumentation logs (DataFrame)\n",
        "logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e",
        "ExecuteTime": {
          "end_time": "2025-09-30T08:58:38.646714Z",
          "start_time": "2025-09-30T08:58:38.639026800Z"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: Implement optimizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3",
        "ExecuteTime": {
          "end_time": "2025-09-30T08:58:38.648719100Z",
          "start_time": "2025-09-30T08:58:38.642546300Z"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s2am56tlpjY9",
      "metadata": {
        "id": "s2am56tlpjY9"
      },
      "source": [
        "testing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}