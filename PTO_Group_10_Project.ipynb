{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO â€” Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is the starter notebook for your project. Follow the required structure below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the companyâ€™s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4",
        "ExecuteTime": {
          "end_time": "2025-09-30T08:55:21.268657600Z",
          "start_time": "2025-09-30T08:55:21.203754400Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "COMPANY_NAME = \"DBS Bank\"\n",
        "DATA_DIR = \"/content/drive/MyDrive/ICT3113 Group 10/Data\" # Define data directory here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ec3fd90"
      },
      "source": [
        "### API Keys and Secrets Management\n",
        "\n",
        "This project utilizes the Google Gemini API. To use it, you will need a Gemini API key.\n",
        "\n",
        "**How to obtain a Gemini API Key:**\n",
        "1.  Go to Google AI Studio ([https://aistudio.google.com/](https://aistudio.google.com/)).\n",
        "2.  Create or select a project.\n",
        "3.  Generate an API key.\n",
        "\n",
        "**How to store your API Key securely in Colab Secrets:**\n",
        "1.  In the left sidebar of your Colab notebook, click on the \"ðŸ”‘ Secrets\" tab.\n",
        "2.  Click on \"Add new secret\".\n",
        "3.  For the **Name**, enter `GOOGLE_API_KEY`. This is the name the code will use to access the key.\n",
        "4.  For the **Value**, paste your Gemini API key.\n",
        "5.  Make sure the \"Notebook access\" toggle is turned ON for this secret.\n",
        "\n",
        "You can then access the secret in your code using:"
      ],
      "id": "0ec3fd90"
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3â€“5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import from Google Drive. Change File path according to your file structure\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JsE2rc9-3Ex3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871499f4-f189-4834-cf2e-044e1e719b0c"
      },
      "id": "JsE2rc9-3Ex3",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers faiss-cpu numpy pandas scikit-learn PyMuPDF rank-bm25 google-generativeai tqdm"
      ],
      "metadata": {
        "id": "uGS12oor3Q7o"
      },
      "id": "uGS12oor3Q7o",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5e08f5a0",
      "metadata": {
        "id": "5e08f5a0",
        "ExecuteTime": {
          "end_time": "2025-09-30T09:08:36.387313200Z",
          "start_time": "2025-09-30T09:08:08.875497Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538,
          "referenced_widgets": [
            "c9e802a308ae488f94ff6dfd60cf50b3",
            "2ef7975a28414ee4b7b45092d74b9c64",
            "513979dfda264d11b08bac5951b6f599",
            "43d8ab5582e74965837db5b8b7450057",
            "64b0daeb496f4a6f959c2dd810e2b22f",
            "aff93e2e6f1b4a41b64cabbe4e123a08",
            "7002d145df5c4faa88a01e46f19e9a39",
            "23bc98f63858419eabed273cc9286807",
            "c43bc3acdae1438d9a509aa2275656f2",
            "7fa135e14e604ddb91f513936896581c",
            "70c478aadf0146479350f4dbdb7b0360"
          ]
        },
        "outputId": "831de1fc-1889-4080-9dfd-aba290cf2987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Starting document ingestion ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9e802a308ae488f94ff6dfd60cf50b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: 24 PDFs\n",
            "Created: 935 text chunks\n",
            "Ingestion Time: 109.93 seconds\n",
            "\n",
            "=== Retrieval Test ===\n",
            "Query: Net Interest Margin trend over the past 3 years\n",
            "Retrieved 3 documents:\n",
            "\n",
            "Document 1: DBS Annual Report 2023, Page 13\n",
            "Combined Score: 11.2410\n",
            "Text Preview: 20 DBS ANNUAL REPORT 2023       BUILDING A SUSTAINABLE ADVANTAGE CFO statement We achieved a record performance for the third consecutive year with  t...\n",
            "\n",
            "Document 2: 2Q22_performance_summary, Page 7\n",
            "Combined Score: 10.9726\n",
            "Text Preview: DBS GROUP HOLDINGS LTD AND ITS SUBSIDIARIES    5    First Half    First-half net profit was $3.62 billion, 3% below the  previous yearâ€™s record. Busin...\n",
            "\n",
            "Document 3: 1Q22_CFO_presentation, Page 15\n",
            "Combined Score: 8.0486\n",
            "Text Preview: In summary â€“ strong first-quarter operating performance 15 Strong first quarter as business momentum healthy and growth broad-based,  expenses well-ma...\n",
            "Agentic tools are defined and mapped.\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement ingestion pipeline\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "# RAG related libararies\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz  # PyMuPDF for PDF processing\n",
        "from rank_bm25 import BM25Okapi\n",
        "import google.generativeai as genai # Gemini API for higher token limits\n",
        "\n",
        "# Initialise logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Tool for financial calculations\n",
        "class CalculatorTool:\n",
        "    def calculate_ratio(self, numerator: float, denominator: float, ratio_name: str = \"\") -> Dict[str, Any]:\n",
        "        try:\n",
        "            if denominator == 0:\n",
        "                return {\"error\": f\"Cannot calculate {ratio_name}: denominator is zero\"}\n",
        "\n",
        "            ratio = (numerator / denominator) * 100 if \"ratio\" in ratio_name.lower() else (numerator / denominator)\n",
        "            return {\n",
        "                \"ratio_name\": ratio_name,\n",
        "                \"numerator\": numerator,\n",
        "                \"denominator\": denominator,\n",
        "                \"result\": round(ratio, 2),\n",
        "                \"formula\": f\"{numerator} / {denominator}\"\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def trend_analysis(self, values: List[float], periods: List[str]) -> Dict[str, Any]:\n",
        "        if len(values) != len(periods):\n",
        "            return {\"error\": \"Values and periods must have the same length\"}\n",
        "\n",
        "        if len(values) < 2:\n",
        "            return {\"error\": \"Need at least two data points for trend analysis\"}\n",
        "\n",
        "        # Calculate period-over-period changes\n",
        "        changes = []\n",
        "        for i in range(1, len(values)):\n",
        "            if values[i-1] != 0:\n",
        "                pct_change = ((values[i] - values[i-1]) / values[i-1]) * 100\n",
        "                changes.append(round(pct_change, 2))\n",
        "            else:\n",
        "                changes.append(0)\n",
        "\n",
        "        return {\n",
        "            \"periods\": periods,\n",
        "            \"values\": values,\n",
        "            \"period_changes\": changes,\n",
        "            \"overall_trend\": \"increasing\" if values[-1] > values[0] else \"decreasing\",\n",
        "            \"average_change\": round(sum(changes) / len(changes), 2) if changes else 0\n",
        "        }\n",
        "\n",
        "\n",
        "# Tool for extracting table from dataset\n",
        "class TableExtractionTool:\n",
        "    def extract_financial_numbers(self, text: str) -> List[Dict[str, Any]]:\n",
        "        # Pattern for numbers with currency/percentage\n",
        "        patterns = [\n",
        "            r'(\\$|S\\$|USD|SGD)?\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(million|billion|thousand|m|bn|k)?',\n",
        "            r'(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(%|percent|basis points|bps)',\n",
        "            r'(NIM|CTI|ROE|ROA|CET1)\\s*[:=]?\\s*(\\d+(?:\\.\\d+)?)\\s*(%|bps)?'\n",
        "        ]\n",
        "\n",
        "        extracted = []\n",
        "        for pattern in patterns:\n",
        "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                extracted.append({\n",
        "                    \"text\": match.group(0),\n",
        "                    \"value\": match.group(2) if len(match.groups()) > 1 else match.group(1),\n",
        "                    \"context\": text[max(0, match.start()-50):match.end()+50]  # 50 chars before and after\n",
        "                })\n",
        "\n",
        "        return extracted\n",
        "\n",
        "    def parse_table_structure(self, text: str) -> Dict[str, Any]:\n",
        "        lines = text.split('\\n')\n",
        "        table_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            # Look for lines that might be table rows (have multiple numbers/columns)\n",
        "            if re.search(r'\\d.*\\d', line) and ('|' in line or '\\t' in line or len(re.findall(r'\\d+', line)) > 1):\n",
        "                table_lines.append(line.strip())\n",
        "\n",
        "        return {\n",
        "            \"potential_table_rows\": table_lines[:10], # Return first 10 rows\n",
        "            \"row_count\": len(table_lines)\n",
        "        }\n",
        "\n",
        "\n",
        "# Tool for comparing info across docs\n",
        "class DocumentComparisonTool:\n",
        "    def compare_metrics_across_docs(self, documents: List[Dict], metric_name: str) -> Dict[str, Any]:\n",
        "        comparisons = []\n",
        "        for doc in documents:\n",
        "            # Extract metric from document text\n",
        "            numbers = re.findall(r'\\d+(?:\\.\\d+)?', doc.get('text', ''))\n",
        "            filename = doc.get('metadata', {}).get('filename', 'unknown')\n",
        "\n",
        "            comparisons.append({\n",
        "                \"document\": filename,\n",
        "                \"metric_candidates\": numbers[:5], # Return first 5 found numbers\n",
        "                \"text_snippet\": doc.get('text', '')[:200] # First 200 chars\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            \"metric_name\": metric_name,\n",
        "            \"comparisons\": comparisons\n",
        "        }\n",
        "\n",
        "# RAG functions\n",
        "class CFORAGPipeline:\n",
        "    def __init__(self, persist_dir=\"./cfo_rag_data\"):\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.persist_dir = persist_dir\n",
        "        self.documents = []\n",
        "        self.document_metadata = []\n",
        "        self.index = None\n",
        "        self.bm25 = None\n",
        "\n",
        "        # Initialise tools\n",
        "        self.calculator_tool = CalculatorTool()\n",
        "        self.table_extraction_tool = TableExtractionTool()\n",
        "        self.doc_comparison_tool = DocumentComparisonTool()\n",
        "\n",
        "        # Create directory for persistence\n",
        "        os.makedirs(self.persist_dir, exist_ok=True)\n",
        "\n",
        "        # Performance tracking\n",
        "        self.metrics = {\n",
        "            'T_ingest': 0,\n",
        "            'T_retrieve': 0,\n",
        "            'T_rerank': 0,\n",
        "            'documents_ingested': 0,\n",
        "            }\n",
        "\n",
        "        logger.info(\"Initialized CFO RAG Pipeline\")\n",
        "\n",
        "    # method for RAG Pipeline evaluation testing\n",
        "    def load_data(self):\n",
        "      # load saved index and documents\n",
        "        try:\n",
        "          with open(os.path.join(self.persist_dir, 'documents.pkl'), 'rb') as f:\n",
        "              self.documents = pickle.load(f)\n",
        "\n",
        "          with open(os.path.join(self.persist_dir, 'metadata.pkl'), 'rb') as f:\n",
        "              self.document_metadata = pickle.load(f)\n",
        "\n",
        "          self.index = faiss.read_index(os.path.join(self.persist_dir, 'faiss_index.bin'))\n",
        "\n",
        "          with open(os.path.join(self.persist_dir, 'bm25.pkl'), 'rb') as f:\n",
        "              self.bm25 = pickle.load(f)\n",
        "\n",
        "          logger.info(f\"Loaded {len(self.documents)} documents from {self.persist_dir}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading data: {e}\")\n",
        "\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:\n",
        "        # for document chunking\n",
        "        chunks = []\n",
        "\n",
        "        try:\n",
        "            doc = fitz.open(pdf_path)\n",
        "            filename = Path(pdf_path).stem\n",
        "\n",
        "            for page_num in range(len(doc)):\n",
        "                page = doc[page_num]\n",
        "                text = page.get_text()\n",
        "\n",
        "                if text.strip():\n",
        "                  # page-wise chunking to keep tables intact\n",
        "                  chunk = {\n",
        "                      'text': text.strip(),\n",
        "                      'metadata': {\n",
        "                          'filename': filename,\n",
        "                          'page': page_num + 1,\n",
        "                          'chunk_id': f\"{filename}_p{page_num+1}\",\n",
        "                          'source_type': self._classify_document_type(filename)\n",
        "                      }\n",
        "                  }\n",
        "                  chunks.append(chunk)\n",
        "                    # split by sentences/paragraphs for chunking\n",
        "                    #paragraphs = text.split('\\n\\n')\n",
        "\n",
        "                    #for i, paragraph in enumerate(paragraphs):\n",
        "                    #    if len(paragraph.strip()) > 50:\n",
        "                    #        chunk = {\n",
        "                    #            'text': paragraph.strip(),\n",
        "                    #            'metadata': {\n",
        "                    #                'filename': filename,\n",
        "                    #                'page': page_num + 1,\n",
        "                    #                'chunk_id': f\"{filename}_p{page_num+1}_c{i+1}\",\n",
        "                    #                'source_type': self._classify_document_type(filename)\n",
        "                    #            }\n",
        "                    #        }\n",
        "                    #        chunks.append(chunk)\n",
        "\n",
        "            doc.close()\n",
        "            logger.info(f\"Extracted {len(chunks)} text chunks from {pdf_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text from {pdf_path}: {e}\")\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def _classify_document_type(self, filename: str) -> str:\n",
        "        # based on filename\n",
        "        filename_lower = filename.lower()\n",
        "        if 'annual' in filename_lower:\n",
        "            return 'annual_report'\n",
        "        elif any(q in filename_lower for q in ['1q', '2q', '3q', '4q', 'quarter']):\n",
        "            return 'quarterly_report'\n",
        "        elif 'performance' in filename_lower:\n",
        "            return 'performance_summary'\n",
        "        else:\n",
        "            return 'financial_report'\n",
        "\n",
        "        # document ingestion from data directory containing PDFs/datasets\n",
        "    def ingest_documents(self, data_dir: str = \"./content/data\") -> Dict[str, Any]:\n",
        "        # record time taken to ingest the documents\n",
        "        start_time = time.time()\n",
        "\n",
        "        pdf_files = list(Path(data_dir).glob(\"*.pdf\"))\n",
        "        if not pdf_files:\n",
        "            raise ValueError(f\"No PDF files found in {data_dir}\")\n",
        "\n",
        "        all_chunks = []\n",
        "\n",
        "        # process each PDF file\n",
        "        for pdf_file in pdf_files:\n",
        "            chunks = self.extract_text_from_pdf(str(pdf_file))\n",
        "            all_chunks.extend(chunks)\n",
        "\n",
        "        # separate text and metadata\n",
        "        texts = [chunk['text'] for chunk in all_chunks]\n",
        "        metadatas = [chunk['metadata'] for chunk in all_chunks]\n",
        "\n",
        "        self.documents = texts\n",
        "        self.document_metadata = metadatas\n",
        "\n",
        "        # Create embeddings\n",
        "        embeddings = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dimension)\n",
        "        self.index.add(embeddings.astype('float32'))\n",
        "\n",
        "        # create BM25 index for keyword search\n",
        "        tokenised_docs = [doc.lower().split() for doc in texts]\n",
        "        self.bm25 = BM25Okapi(tokenised_docs)\n",
        "\n",
        "        # save data\n",
        "        self._save_data()\n",
        "\n",
        "        # update metrics\n",
        "        self.metrics['T_ingest'] = time.time() - start_time\n",
        "        self.metrics['documents_ingested'] = len(texts)\n",
        "        logger.info(f\"Ingested {len(texts)} documents in {self.metrics['T_ingest']:.2f} seconds\")\n",
        "\n",
        "        return {\n",
        "            'documents_processed': len(pdf_files),\n",
        "            'chunks_created': len(texts),\n",
        "            'ingestion_duration': self.metrics['T_ingest']\n",
        "        }\n",
        "\n",
        "    # retrieve relevant documents using hybrid search\n",
        "    def hybrid_retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
        "        if not self.documents or self.index is None:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            # --- Start retrieval timer ---\n",
        "            start_retrieve = time.time()\n",
        "\n",
        "            # Vector search\n",
        "            query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
        "            vector_k = min(top_k * 2, len(self.documents))\n",
        "            distances, indices = self.index.search(query_embedding.astype('float32'), vector_k)\n",
        "\n",
        "            # BM25 keyword search\n",
        "            bm25_scores = self.bm25.get_scores(query.lower().split())\n",
        "\n",
        "            # Stop retrieval timer (only covers FAISS + BM25)\n",
        "            self.metrics['T_retrieve'] = time.time() - start_retrieve\n",
        "\n",
        "            # --- Start rerank timer ---\n",
        "            start_rerank = time.perf_counter()\n",
        "\n",
        "            combined_results = []\n",
        "            for i, idx in enumerate(indices[0]):\n",
        "                if idx < len(self.documents):\n",
        "                    vector_score = 1 / (1 + distances[0][i])\n",
        "                    bm25_score = bm25_scores[idx] if idx < len(bm25_scores) else 0\n",
        "                    combined_score = vector_score + bm25_score\n",
        "\n",
        "                    result = {\n",
        "                        'text': self.documents[idx],\n",
        "                        'metadata': self.document_metadata[idx],\n",
        "                        'combined_score': combined_score,\n",
        "                        'vector_score': vector_score,\n",
        "                        'bm25_score': bm25_score,\n",
        "                        'citation': f\"{self.document_metadata[idx]['filename']}, Page {self.document_metadata[idx]['page']}\"\n",
        "                    }\n",
        "                    combined_results.append(result)\n",
        "\n",
        "            # Apply recency boosting to improve retrieval\n",
        "            for result in combined_results:\n",
        "              filename = result['metadata']['filename'].lower()\n",
        "\n",
        "              # Boost recent documents\n",
        "              if any(q in filename for q in ['2q25', '1q25']):\n",
        "                  result['combined_score'] *= 1.5  # 50% boost for most recent\n",
        "              elif any(q in filename for q in ['4q24', '3q24']):\n",
        "                  result['combined_score'] *= 1.3  # 30% boost\n",
        "              elif any(q in filename for q in ['2q24', '1q24']):\n",
        "                  result['combined_score'] *= 1.1  # 10% boost\n",
        "\n",
        "            # Sorting and taking top_k\n",
        "            combined_results.sort(key=lambda x: x['combined_score'], reverse=True)\n",
        "            final_results = combined_results[:top_k]\n",
        "\n",
        "            # Stop rerank timer (store in ms)\n",
        "            self.metrics['T_rerank'] = (time.perf_counter() - start_rerank) * 1000\n",
        "\n",
        "            return final_results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during retrieval: {e}\")\n",
        "            return []\n",
        "\n",
        "\n",
        "    def _save_data(self):\n",
        "        # Save FAISS index\n",
        "        try:\n",
        "            with open(os.path.join(self.persist_dir, 'documents.pkl'), 'wb') as f:\n",
        "                pickle.dump(self.documents, f)\n",
        "\n",
        "            with open(os.path.join(self.persist_dir, 'metadata.pkl'), 'wb') as f:\n",
        "                pickle.dump(self.document_metadata, f)\n",
        "\n",
        "            if self.index is not None:\n",
        "                faiss.write_index(self.index, os.path.join(self.persist_dir, 'faiss_index.bin'))\n",
        "\n",
        "            if self.bm25 is not None:\n",
        "                with open(os.path.join(self.persist_dir, 'bm25.pkl'), 'wb') as f:\n",
        "                    pickle.dump(self.bm25, f)\n",
        "\n",
        "            logger.info(\"Saved ingestion data to disk\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error saving data: {e}\")\n",
        "\n",
        "cfo_rag = CFORAGPipeline()\n",
        "\n",
        "# Ingest documents from data directory\n",
        "print(\"=== Starting document ingestion ===\")\n",
        "ingestion_result = cfo_rag.ingest_documents(data_dir=DATA_DIR) # Use the variable here\n",
        "print(f\"Processed: {ingestion_result['documents_processed']} PDFs\")\n",
        "print(f\"Created: {ingestion_result['chunks_created']} text chunks\")\n",
        "print(f\"Ingestion Time: {ingestion_result['ingestion_duration']:.2f} seconds\")\n",
        "\n",
        "# Test retrieval\n",
        "test_query = \"Net Interest Margin trend over the past 3 years\"\n",
        "retrieved_docs = cfo_rag.hybrid_retrieve(test_query, top_k=3)\n",
        "\n",
        "print(f\"\\n=== Retrieval Test ===\")\n",
        "print(f\"Query: {test_query}\")\n",
        "print(f\"Retrieved {len(retrieved_docs)} documents:\")\n",
        "\n",
        "\n",
        "if retrieved_docs:\n",
        "    for i, doc in enumerate(retrieved_docs, 1):\n",
        "        print(f\"\\nDocument {i}: {doc['citation']}\")\n",
        "        print(f\"Combined Score: {doc['combined_score']:.4f}\")\n",
        "        print(f\"Text Preview: {doc['text'][:150].replace(chr(10), ' ')}...\")  # Print first 150 chars\n",
        "else:\n",
        "    print(\"No documents retrieved.\")\n",
        "\n",
        "# Get tool instances from the RAG class\n",
        "calculator = cfo_rag.calculator_tool\n",
        "table_extractor = cfo_rag.table_extraction_tool\n",
        "doc_comparer = cfo_rag.doc_comparison_tool\n",
        "\n",
        "# Create the function map\n",
        "tool_function_map = {\n",
        "    \"calculate_ratio\": calculator.calculate_ratio,\n",
        "    \"trend_analysis\": calculator.trend_analysis,\n",
        "    \"extract_financial_numbers\": table_extractor.extract_financial_numbers,\n",
        "    \"parse_table_structure\": table_extractor.parse_table_structure,\n",
        "    \"compare_metrics_across_docs\": doc_comparer.compare_metrics_across_docs,\n",
        "}\n",
        "\n",
        "# Define the tool schema for the Gemini API\n",
        "gemini_tools = [\n",
        "    {\n",
        "        \"function_declarations\": [\n",
        "            {\n",
        "                \"name\": \"calculate_ratio\",\n",
        "                \"description\": \"Calculates a ratio from a numerator and denominator. Use for all financial ratios like 'Cost-to-Income', 'Efficiency Ratio', etc.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"numerator\": {\"type\": \"NUMBER\"},\n",
        "                        \"denominator\": {\"type\": \"NUMBER\"},\n",
        "                        \"ratio_name\": {\"type\": \"STRING\", \"description\": \"e.g., 'Efficiency Ratio'\"}\n",
        "                    },\n",
        "                    \"required\": [\"numerator\", \"denominator\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"trend_analysis\",\n",
        "                \"description\": \"Calculates period-over-period changes for a list of values and periods. Use for 'YoY', 'QoQ', or 'trend' questions.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"values\": {\"type\": \"ARRAY\", \"items\": {\"type\": \"NUMBER\"}},\n",
        "                        \"periods\": {\"type\": \"ARRAY\", \"items\": {\"type\": \"STRING\"}},\n",
        "                    },\n",
        "                    \"required\": [\"values\", \"periods\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"extract_financial_numbers\",\n",
        "                \"description\": \"Extracts all financial numbers, percentages, and metrics from a specific chunk of text.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"OBJECT\",\n",
        "                    \"properties\": {\n",
        "                        \"text\": {\"type\": \"STRING\"},\n",
        "                    },\n",
        "                    \"required\": [\"text\"]\n",
        "                }\n",
        "            },\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Agentic tools are defined and mapped.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "540b7020",
      "metadata": {
        "id": "540b7020",
        "ExecuteTime": {
          "end_time": "2025-09-30T09:09:29.110581200Z",
          "start_time": "2025-09-30T09:08:44.027346100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "e195efac-7f9c-40d3-a075-ad67b89675bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models (Baseline and Agentic) are initialized.\n",
            "=== Baseline Answer ===\n",
            "The Net Interest Margin (NIM) trend over the past three years shows a period of decline followed by significant expansion:\n",
            "\n",
            "*   **2023:** The full-year net interest margin expanded by 40 basis points to **2.15%**. Quarterly NIM continued to rise in the first three quarters before easing in the fourth quarter (DBS Annual Report 2023, Page 13).\n",
            "*   **2022:** The net interest margin increased by 62 basis points over the four quarters. For the first half of 2022, it was **1.52%**, which was five basis points higher than the first half of the previous year (DBS Annual Report 2023, Page 13; 2Q22_performance_summary, Page 7). The NIM started to rise in the first quarter of 2022, reversing a three-year decline, and the improvement accelerated in the second quarter (2Q22_performance_summary, Page 7; 1Q22_CFO_presentation, Page 15).\n",
            "*   **2021 (and 2020):** Net interest margin was declining since 2019 and continued to decline up until 2021 (2Q22_performance_summary, Page 7; 1Q22_CFO_presentation, Page 15). Based on the H1 2022 NIM of 1.52% being \"five basis points higher than a year ago,\" the H1 2021 NIM would have been 1.47% (2Q22_performance_summary, Page 7).\n",
            "\n",
            "Citations: ['DBS Annual Report 2023, Page 13', '2Q22_performance_summary, Page 7', '1Q22_CFO_presentation, Page 15']\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# Part 4. Baseline Pipeline\n",
        "# =============================\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- 1. Configure Gemini (as before) ---\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# --- 2. Initialize TWO models ---\n",
        "\n",
        "# (A) The global, tool-enabled model for Section 7 Agent\n",
        "llm_model = genai.GenerativeModel(\n",
        "    \"gemini-2.5-flash\",\n",
        "    tools=gemini_tools\n",
        ")\n",
        "\n",
        "# (B) A new, SIMPLE model for this baseline test\n",
        "baseline_llm_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "\n",
        "# --- 3. Define Agent Helper Functions (for Critique & Refine) ---\n",
        "# We keep these here so Section 7 can use them\n",
        "critique_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "regenerate_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "def parse_gemini_json(raw_text: str) -> dict:\n",
        "    \"\"\"Extracts and parses JSON from Gemini's markdown response.\"\"\"\n",
        "    try:\n",
        "        match = re.search(r\"```json\\n(.*?)\\n```\", raw_text, re.DOTALL)\n",
        "        if match:\n",
        "            json_str = match.group(1)\n",
        "        else:\n",
        "            json_str = raw_text.strip()\n",
        "            if not json_str.startswith('{'):\n",
        "                json_str = '{' + json_str.split('{', 1)[-1]\n",
        "            if not json_str.endswith('}'):\n",
        "                json_str = json_str.rsplit('}', 1)[0] + '}'\n",
        "        return json.loads(json_str)\n",
        "    except Exception as e:\n",
        "        print(f\"JSON Parse Error: {e}\\nRaw Text: {raw_text}\")\n",
        "        return {\"error\": \"Failed to parse critique JSON.\"}\n",
        "\n",
        "def critique_financial_answer(query: str, v1_answer: str) -> dict:\n",
        "    \"\"\"Reviewer agent that critiques the V1 answer.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a meticulous senior financial controller. Review this draft answer.\n",
        "Respond ONLY with a JSON object in the format:\n",
        "```json\n",
        "{{\"score\": 0.0, \"strengths\": [\"...\"], \"gaps\": [\"...\"], \"rewrite_brief\": \"...\"}}\n",
        "```\n",
        "\n",
        "Query: {query}\n",
        "V1 Draft: {v1_answer}\n",
        "\n",
        "Provide your JSON critique:\n",
        "\"\"\"\n",
        "    config = genai.GenerationConfig(response_mime_type=\"application/json\")\n",
        "    response = critique_model.generate_content(prompt, generation_config=config)\n",
        "    return parse_gemini_json(response.text)\n",
        "\n",
        "def regenerate_final_answer(query: str, v1_answer: str, critique: dict) -> str:\n",
        "    \"\"\"Regeneration agent that creates the V2 answer.\"\"\"\n",
        "    critique_str = json.dumps(critique, indent=2)\n",
        "    prompt = f\"\"\"\n",
        "You are a junior analyst. Your manager critiqued your V1 draft.\n",
        "Rewrite the answer to address the critique. Produce only the final, corrected answer.\n",
        "\n",
        "Query: {query}\n",
        "V1 Draft (has errors): {v1_answer}\n",
        "Manager's Critique: {critique_str}\n",
        "\n",
        "Provide the polished, corrected Final Answer:\n",
        "\"\"\"\n",
        "    response = regenerate_model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "print(\"All models (Baseline and Agentic) are initialized.\")\n",
        "\n",
        "\n",
        "# --- 4. Baseline Pipeline Function ---\n",
        "# This function uses the 'baseline_llm_model'\n",
        "\n",
        "def baseline_pipeline(query: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Runs naive RAG pipeline: retrieval + single LLM call.\n",
        "    \"\"\"\n",
        "    # Retrieve relevant docs\n",
        "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k)\n",
        "    if not retrieved_docs:\n",
        "        return {\"error\": \"No documents retrieved.\"}\n",
        "\n",
        "    # Build context\n",
        "    context = \"\\n\\n\".join([f\"{doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
        "\n",
        "    # Prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a financial analyst assistant.\n",
        "Answer the user query based only on the provided reports.\n",
        "Include citations (filename + page).\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Reports:\n",
        "{context}\n",
        "\"\"\"\n",
        "    # Call the simple, non-tool-aware model\n",
        "    response = baseline_llm_model.generate_content(prompt)\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
        "        \"raw_docs\": [doc[\"text\"][:300] for doc in retrieved_docs],  # preview only\n",
        "        \"answer\": response.text.strip()\n",
        "    }\n",
        "\n",
        "result = baseline_pipeline(\"Net Interest Margin trend over the past 3 years\", top_k=3)\n",
        "print(\"=== Baseline Answer ===\")\n",
        "print(result[\"answer\"])\n",
        "print(\"\\nCitations:\", result[\"citations\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Gross Margin Trend (or NIM if Bank)\n",
        "    *   Query: \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
        "    *   Expected Output: A quarterly table of Gross Margin % (or NIM % if bank).\n",
        "\n",
        "*   Operating Expenses (Opex) YoY for 3 Years\n",
        "    *   Query: \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "    *   Expected Output: A 3-year Opex table (absolute numbers and % change).\n",
        "\n",
        "*   Operating Efficiency Ratio\n",
        "    *   Query: \"Calculate the Operating Efficiency Ratio (Opex Ã· Operating Income) for the last 3 fiscal years, showing the working.\"\n",
        "    *   Expected Output: Table with Opex, Operating Income, and calculated ratio for 3 years.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64dbe015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b67cfbd9-e5f3-410e-bc16-17caf72d9948"
      },
      "source": [
        "# =============================\n",
        "# Part 5. Benchmark Runner\n",
        "# =============================\n",
        "\n",
        "# Define the benchmark queries\n",
        "benchmark_queries = [\n",
        "    {\n",
        "        \"name\": \"NIM Quarterly Trend\",\n",
        "        \"query\": \"Report the Net Interest Margin over the last 5 quarters, with values.\",\n",
        "        \"expected\": \"A quarterly table of NIM %\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Opex YoY 3-Year\",\n",
        "        \"query\": \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
        "        \"expected\": \"A 3-year Opex table (absolute numbers and % change)\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Operating Efficiency Ratio\",\n",
        "        \"query\": \"Calculate the Operating Efficiency Ratio (Opex Ã· Operating Income) for the last 3 fiscal years, showing the working.\",\n",
        "        \"expected\": \"Table with Opex, Operating Income, and calculated ratio for 3 years\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Benchmark runner\n",
        "def benchmark_pipeline(query: str, top_k: int = 12):\n",
        "    \"\"\"Pipeline for testing queries without instrumentation\"\"\"\n",
        "\n",
        "    # Retrieve relevant docs\n",
        "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k)\n",
        "    if not retrieved_docs:\n",
        "        return {\"error\": \"No documents retrieved.\"}\n",
        "\n",
        "    context = \"\\n\\n\".join([f\"{doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
        "\n",
        "    # Simple prompt for testing\n",
        "    table_prompt = f\"\"\"\n",
        "You are a financial analyst. Answer this query using ONLY the provided reports.\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "FORMAT REQUIREMENT: Present data in the requested table format using markdown.\n",
        "\n",
        "Reports:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "1. Extract the exact financial figures from the reports\n",
        "2. Present them in the requested table format using markdown\n",
        "3. Include citations (filename, page number) after each table\n",
        "4. If calculations are needed, show the working clearly\n",
        "5. Use proper financial notation (S$ millions, percentages, etc.)\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    response = baseline_llm_model.generate_content(table_prompt)\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
        "        \"answer\": response.text.strip()\n",
        "    }\n",
        "\n",
        "# Test the benchmark queries\n",
        "print(\"=== Testing Benchmark Queries (Simple) ===\")\n",
        "for q in benchmark_queries:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"QUERY: {q['name']}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    result = benchmark_pipeline(q[\"query\"])\n",
        "    print(f\"Answer:\\n{result['answer']}\")\n",
        "    print(f\"\\nCitations: {result['citations']}\")"
      ],
      "id": "64dbe015",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Benchmark Queries (Simple) ===\n",
            "\n",
            "==================================================\n",
            "QUERY: NIM Quarterly Trend\n",
            "==================================================\n",
            "Answer:\n",
            "| Quarter | Net Interest Margin (%) |\n",
            "|:--------|:------------------------|\n",
            "| 2Q24    | 2.14                    |\n",
            "| 3Q24    | 2.11                    |\n",
            "| 4Q24    | 2.15                    |\n",
            "| 1Q25    | 2.12                    |\n",
            "| 2Q25    | 2.05                    |\n",
            "\n",
            "Citations:\n",
            "*   QuartelyResults_2Q25_CFO, Page 6\n",
            "*   QuartelyResults_1Q25_CFO, Page 5\n",
            "*   QuartelyResults_4Q24_CFO, Page 6\n",
            "*   QuartelyResults_3Q24_CFO, Page 8\n",
            "\n",
            "Citations: ['DBS Annual Report 2023, Page 13', 'QuartelyResults_1Q24_CFO, Page 2', 'QuartelyResults_1Q25_CFO, Page 5', 'DBS Annual Report 2023, Page 15', 'QuartelyResults_2Q25_CFO, Page 6', 'QuartelyResults_1Q24_CFO, Page 5', '1Q22_CFO_presentation, Page 5', 'QuartelyResults_1Q23_CFO, Page 5', '3Q22_CFO_presentation, Page 5', 'QuartelyResults_4Q23_CFO, Page 2', 'QuartelyResults_3Q24_CFO, Page 8', 'QuartelyResults_4Q24_CFO, Page 6']\n",
            "\n",
            "==================================================\n",
            "QUERY: Opex YoY 3-Year\n",
            "==================================================\n",
            "Answer:\n",
            "Here are the Operating Expenses for the last 3 fiscal years with year-on-year comparisons:\n",
            "\n",
            "**Operating Expenses (Excluding one-time items)**\n",
            "\n",
            "| Fiscal Year | Operating Expenses ($m) | Year-on-Year Change (%) |\n",
            "|:------------|:------------------------|:------------------------|\n",
            "| FY2024      | 8,895                   | 10.42                   |\n",
            "| FY2023      | 8,056                   | 13.62                   |\n",
            "| FY2022      | 7,090                   | N/A                     |\n",
            "\n",
            "**Working:**\n",
            "*   **FY2024 Operating Expenses:**\n",
            "    *   1st Half 2024 Total Expenses: $4,251m (2Q25_performance_summary, Page 13)\n",
            "    *   2nd Half 2024 Total Expenses: $4,644m (2Q25_performance_summary, Page 13)\n",
            "    *   FY2024 Total Operating Expenses = $4,251m + $4,644m = $8,895m\n",
            "*   **FY2023 Operating Expenses:**\n",
            "    *   FY2023 Total Operating Expenses: $8,056m (4Q23_performance_summary, Page 9)\n",
            "*   **FY2022 Operating Expenses:**\n",
            "    *   FY2022 Total Operating Expenses: $7,090m (4Q22_performance_summary, Page 9)\n",
            "\n",
            "**Year-on-Year Change Calculation:**\n",
            "*   **FY2024 vs FY2023:**\n",
            "    *   (($8,895m - $8,056m) / $8,056m) * 100 = 10.42%\n",
            "*   **FY2023 vs FY2022:**\n",
            "    *   (($8,056m - $7,090m) / $7,090m) * 100 = 13.62%\n",
            "\n",
            "**Citations:**\n",
            "*   2Q25_performance_summary, Page 13\n",
            "*   4Q23_performance_summary, Page 9\n",
            "*   4Q22_performance_summary, Page 9\n",
            "\n",
            "Citations: ['2Q25_performance_summary, Page 13', '2Q25_performance_summary, Page 15', '2Q22_performance_summary, Page 12', '4Q24_performance_summary, Page 15', '4Q22_performance_summary, Page 11', '4Q23_performance_summary, Page 11', '2Q23_performance_summary, Page 11', '2Q22_performance_summary, Page 10', '2Q23_performance_summary, Page 13', '1Q22_CFO_presentation, Page 15', 'QuartelyResults_1Q25_CFO, Page 11', '4Q23_performance_summary, Page 13']\n",
            "\n",
            "==================================================\n",
            "QUERY: Operating Efficiency Ratio\n",
            "==================================================\n",
            "Answer:\n",
            "The Operating Efficiency Ratio is calculated as Operating Expenses divided by Operating Income (Opex Ã· Operating Income).\n",
            "\n",
            "### Working:\n",
            "\n",
            "**Fiscal Year 2023**\n",
            "1.  **Operating Expenses (Opex):**\n",
            "    *   From \"Expenses (SGD million)(1)\" table, \"2023 Total\": S$ 8,056 million\n",
            "    *   *Source: DBS Annual Report 2023, Page 15*\n",
            "2.  **Operating Income (Total Income):**\n",
            "    *   Net interest income (2023): S$ 13,642 million\n",
            "    *   Total net fee and commission income (2023): S$ 3,384 million\n",
            "    *   Other non-interest income (2023): S$ 3,154 million\n",
            "    *   Total Operating Income = 13,642 + 3,384 + 3,154 = S$ 20,180 million\n",
            "    *   *Source: DBS Annual Report 2023, Page 15 (tables for Net interest income, Fee income, Other non-interest income)*\n",
            "3.  **Operating Efficiency Ratio (2023):**\n",
            "    *   Ratio = S$ 8,056 million / S$ 20,180 million = 0.399207 = **39.92%**\n",
            "\n",
            "**Fiscal Year 2022**\n",
            "1.  **Operating Expenses (Opex):**\n",
            "    *   From \"EXPENSES1 ($m)\" table, \"Year 2022 Total\": S$ 7,090 million\n",
            "    *   *Source: 4Q22_performance_summary, Page 11*\n",
            "2.  **Operating Income (Total Income):**\n",
            "    *   Net interest income (2022): S$ 10,941 million\n",
            "    *   Total net fee and commission income (2022): S$ 3,091 million\n",
            "    *   Other non-interest income (2022): S$ 2,470 million\n",
            "    *   Total Operating Income = 10,941 + 3,091 + 2,470 = S$ 16,502 million\n",
            "    *   *Source: DBS Annual Report 2023, Page 15 (tables for Net interest income, Fee income, Other non-interest income)*\n",
            "3.  **Operating Efficiency Ratio (2022):**\n",
            "    *   Ratio = S$ 7,090 million / S$ 16,502 million = 0.429644 = **42.96%**\n",
            "\n",
            "**Fiscal Year 2021**\n",
            "1.  **Operating Expenses (Opex):**\n",
            "    *   From \"EXPENSES1 ($m)\" table, \"Year 2021 Total\": S$ 6,469 million\n",
            "    *   *Source: 4Q22_performance_summary, Page 11*\n",
            "2.  **Operating Income (Total Income):**\n",
            "    *   The full-year Operating Income (Total Income) for Fiscal Year 2021 is not available in the provided reports. Therefore, the Operating Efficiency Ratio for 2021 cannot be calculated.\n",
            "\n",
            "### Operating Efficiency Ratio\n",
            "\n",
            "| Fiscal Year | Operating Expenses (S$ million) | Operating Income (S$ million) | Operating Efficiency Ratio (Opex Ã· Operating Income) |\n",
            "| :---------- | :------------------------------ | :---------------------------- | :-------------------------------------------------- |\n",
            "| 2023        | 8,056                           | 20,180                        | 39.92%                                              |\n",
            "| 2022        | 7,090                           | 16,502                        | 42.96%                                              |\n",
            "| 2021        | 6,469                           | Not Available                 | Not Calculable                                      |\n",
            "\n",
            "Citations: ['4Q22_performance_summary, Page 11', '2Q22_performance_summary, Page 10', 'DBS Annual Report 2023, Page 104', '4Q22_performance_summary, Page 6', 'DBS Annual Report 2023, Page 15', 'QuartelyResults_1Q25_CFO, Page 11', 'QuartelyResults_4Q24_CFO, Page 11', 'QuartelyResults_3Q24_CFO, Page 14', 'QuartelyResults_1Q24_CFO, Page 10', 'QuartelyResults_2Q24_CFO, Page 11', '3Q22_CFO_presentation, Page 9', 'QuartelyResults_1Q23_CFO, Page 10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5",
        "ExecuteTime": {
          "end_time": "2025-09-30T09:13:04.577246400Z",
          "start_time": "2025-09-30T09:11:32.887486200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "20334b19-8d40-46fc-e94c-c2581b88a781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Starting Instrumented BASELINE Benchmark Run ===\n",
            "\n",
            "--- Running Instrumented Baseline: NIM Quarterly Trend ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3766483249.py:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  logs = pd.concat([logs, pd.DataFrame([new_log])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Instrumented Baseline: Opex YoY 3-Year ---\n",
            "--- Running Instrumented Baseline: Operating Efficiency Ratio ---\n",
            "\n",
            "\n",
            "==================================================\n",
            "BASELINE PERFORMANCE LOGS (So Far)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        Query  Pipeline  T_retrieve (sec)  T_rerank (ms)  \\\n",
              "0         NIM Quarterly Trend  Baseline          0.024243       0.179383   \n",
              "1             Opex YoY 3-Year  Baseline          0.023897       0.154073   \n",
              "2  Operating Efficiency Ratio  Baseline          0.028472       0.157051   \n",
              "\n",
              "   T_generate (sec)  T_total (sec) Tokens CacheHits Tools  \n",
              "0          7.740332       7.764829   9233         0  None  \n",
              "1          5.462907       5.487013   9897         0  None  \n",
              "2         30.532314      30.560970  11254         0  None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33764928-e419-4218-a057-b4531cf1c3b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Pipeline</th>\n",
              "      <th>T_retrieve (sec)</th>\n",
              "      <th>T_rerank (ms)</th>\n",
              "      <th>T_generate (sec)</th>\n",
              "      <th>T_total (sec)</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>CacheHits</th>\n",
              "      <th>Tools</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NIM Quarterly Trend</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>0.024243</td>\n",
              "      <td>0.179383</td>\n",
              "      <td>7.740332</td>\n",
              "      <td>7.764829</td>\n",
              "      <td>9233</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Opex YoY 3-Year</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>0.023897</td>\n",
              "      <td>0.154073</td>\n",
              "      <td>5.462907</td>\n",
              "      <td>5.487013</td>\n",
              "      <td>9897</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Operating Efficiency Ratio</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>0.028472</td>\n",
              "      <td>0.157051</td>\n",
              "      <td>30.532314</td>\n",
              "      <td>30.560970</td>\n",
              "      <td>11254</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33764928-e419-4218-a057-b4531cf1c3b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33764928-e419-4218-a057-b4531cf1c3b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33764928-e419-4218-a057-b4531cf1c3b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8376c426-1630-4f02-9004-8e61b34b35bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8376c426-1630-4f02-9004-8e61b34b35bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8376c426-1630-4f02-9004-8e61b34b35bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4d182652-7601-4a56-9444-8a9b9b3e1546\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('logs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4d182652-7601-4a56-9444-8a9b9b3e1546 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('logs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "logs",
              "summary": "{\n  \"name\": \"logs\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NIM Quarterly Trend\",\n          \"Opex YoY 3-Year\",\n          \"Operating Efficiency Ratio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pipeline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_retrieve (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002547536493329796,\n        \"min\": 0.023897171020507812,\n        \"max\": 0.028472423553466797,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.02424311637878418\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_rerank (ms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013833431281044223,\n        \"min\": 0.1540730008855462,\n        \"max\": 0.1793830015230924,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1793830015230924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_generate (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.86323807799593,\n        \"min\": 5.462907473000087,\n        \"max\": 30.53231367599801,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7.740331963999779\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_total (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.865759867767473,\n        \"min\": 5.487012945002789,\n        \"max\": 30.560969512000156,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7.764828655999736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokens\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 9233,\n        \"max\": 11254,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9233\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CacheHits\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tools\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # =============================\n",
        "# # Part 6. Instrumentation (Final Version)\n",
        "# # =============================\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "# --- 1. Initialize the global logs DataFrame ---\n",
        "# Both the baseline and optimized pipelines will write to this.\n",
        "logs = pd.DataFrame(columns=[\n",
        "    'Query', 'Pipeline', 'T_retrieve (sec)', 'T_rerank (ms)',\n",
        "    'T_generate (sec)', 'T_total (sec)', 'Tokens', 'CacheHits', 'Tools'\n",
        "])\n",
        "\n",
        "def instrumented_baseline_pipeline(query: str, query_name: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    This is the instrumented version of your SIMPLE pipeline.\n",
        "    It logs performance but does NOT use agentic tools.\n",
        "    \"\"\"\n",
        "    global logs\n",
        "    timings = {}\n",
        "    start_total = time.perf_counter()\n",
        "\n",
        "    # --- Retrieval & Reranking ---\n",
        "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k) #\n",
        "    timings['T_retrieve'] = cfo_rag.metrics.get('T_retrieve', 0)\n",
        "    timings['T_rerank'] = cfo_rag.metrics.get('T_rerank', 0)\n",
        "\n",
        "    if not retrieved_docs:\n",
        "        return {\"error\": \"No documents retrieved.\"}\n",
        "\n",
        "    context = \"\\n\".join([f\"Source {doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
        "\n",
        "    # --- Simple Prompt (similar to baseline) ---\n",
        "    table_prompt = f\"\"\"\n",
        "    You are a financial analyst. Answer this query using ONLY the provided reports.\n",
        "    Query: {query}\n",
        "    FORMAT REQUIREMENT: Present data as a markdown table.\n",
        "    Reports:\n",
        "    {context}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Generation ---\n",
        "    start_generate = time.perf_counter()\n",
        "\n",
        "    response = baseline_llm_model.generate_content(table_prompt) #\n",
        "\n",
        "    timings['T_generate'] = time.perf_counter() - start_generate\n",
        "    timings['T_total'] = time.perf_counter() - start_total\n",
        "\n",
        "    # --- Logging ---\n",
        "    try:\n",
        "        token_count = response.usage_metadata.total_token_count\n",
        "    except Exception:\n",
        "        token_count = 0\n",
        "\n",
        "    new_log = {\n",
        "        'Query': query_name,\n",
        "        'Pipeline': 'Baseline',\n",
        "        'T_retrieve (sec)': timings['T_retrieve'],\n",
        "        'T_rerank (ms)': timings['T_rerank'],\n",
        "        'T_generate (sec)': timings['T_generate'],\n",
        "        'T_total (sec)': timings['T_total'],\n",
        "        'Tokens': token_count,\n",
        "        'CacheHits': 0,\n",
        "        'Tools': 'None'\n",
        "    }\n",
        "\n",
        "    logs = pd.concat([logs, pd.DataFrame([new_log])], ignore_index=True)\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
        "        \"answer\": response.text.strip()\n",
        "    }\n",
        "\n",
        "def run_baseline_benchmarks(queries, top_k=5):\n",
        "    \"\"\"Runs the instrumented BASELINE pipeline for all benchmark queries.\"\"\"\n",
        "    all_results = []\n",
        "    for q in queries:\n",
        "        print(f\"--- Running Instrumented Baseline: {q['name']} ---\")\n",
        "        output = instrumented_baseline_pipeline(q[\"query\"], q[\"name\"], top_k=top_k)\n",
        "        all_results.append({\"name\": q[\"name\"], **output})\n",
        "    return all_results\n",
        "\n",
        "# --- Execute the Instrumented Baseline Benchmarks ---\n",
        "print(\"=== Starting Instrumented BASELINE Benchmark Run ===\\n\")\n",
        "baseline_benchmark_results = run_baseline_benchmarks(benchmark_queries, top_k=10) #\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*50)\n",
        "print(\"BASELINE PERFORMANCE LOGS (So Far)\")\n",
        "print(\"=\"*50)\n",
        "display(logs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e",
        "ExecuteTime": {
          "end_time": "2025-09-30T08:58:38.646714Z",
          "start_time": "2025-09-30T08:58:38.639026800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5f86ea2-c248-4217-eb75-b25572ba63d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All Optimized Agent definitions are loaded.\n",
            "\n",
            "=== Starting OPTIMIZED AGENT Benchmark Run ===\n",
            "\n",
            "\n",
            "============================================================\n",
            "--- Running Reflective Agent for: NIM Quarterly Trend ---\n",
            "============================================================\n",
            "ðŸ¤– (V1) Agent: Running tools and calculations...\n",
            "ðŸ¤– Agent -> Planning 1 parallel tool call(s)...\n",
            "  - Queuing: trend_analysis({'values': [2.05, 2.12, 2.15, 2.11, 2.14], 'periods': ['2Q25', '1Q25', '4Q24', '3Q24', '2Q24']})\n",
            "  âœ… trend_analysis returned: {'periods': ['2Q25', '1Q25', '4Q24', '3Q24', '2Q24'], 'values': [2.05, 2.12, 2.15, 2.11, 2.14], 'period_changes': [3.41, 1.42, -1.86, 1.42], 'overall_trend': 'increasing', 'average_change': 1.1}\n",
            "ðŸ¤– Agent -> Sending tool results back to model...\n",
            "ðŸ¤– Agent -> Generating Final Answer after tool use.\n",
            "\n",
            "--- V1 DRAFT ---\n",
            "The Net Interest Margin (NIM) over the last five quarters is as follows:\n",
            "\n",
            "*   **2Q25:** 2.05%\n",
            "*   **1Q25:** 2.12%\n",
            "*   **4Q24:** 2.15%\n",
            "*   **3Q24:** 2.11%\n",
            "*   **2Q24:** 2.14%\n",
            "\n",
            "The overall trend for NIM has been increasing over these quarters.\n",
            "----------------\n",
            "ðŸ§ (Reviewer) Agent: Critiquing V1 draft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-708315051.py:225: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  logs = pd.concat([logs, pd.DataFrame([new_log])], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CRITIQUE ---\n",
            "{\n",
            "  \"score\": 0.45,\n",
            "  \"strengths\": [\n",
            "    \"Clear presentation of NIM values for each quarter\",\n",
            "    \"Includes all requested five quarters of data\"\n",
            "  ],\n",
            "  \"gaps\": [\n",
            "    \"The stated overall trend analysis (increasing) is factually incorrect based on the provided data points\",\n",
            "    \"Missing quantification of quarter-over-quarter changes (e.g., absolute or percentage point differences)\",\n",
            "    \"No explanation or context provided for the observed NIM fluctuations\"\n",
            "  ],\n",
            "  \"rewrite_brief\": \"Correct the trend analysis to accurately reflect the data, quantify quarter-over-quarter changes, and briefly explain the key drivers behind NIM movements.\"\n",
            "}\n",
            "--------------\n",
            "âœï¸ (V2) Agent: Regenerating answer (V1 score was 0.45)...\n",
            "\n",
            "--- FINAL V2 ANSWER ---\n",
            "The Net Interest Margin (NIM) over the last five quarters is as follows:\n",
            "\n",
            "*   **2Q25:** 2.05% (down 0.07 percentage points from 1Q25)\n",
            "*   **1Q25:** 2.12% (down 0.03 percentage points from 4Q24)\n",
            "*   **4Q24:** 2.15% (up 0.04 percentage points from 3Q24)\n",
            "*   **3Q24:** 2.11% (down 0.03 percentage points from 2Q24)\n",
            "*   **2Q24:** 2.14%\n",
            "\n",
            "The overall trend for NIM has been generally decreasing over these quarters, moving from 2.14% in 2Q24 to 2.05% in 2Q25. While there was a slight increase in 4Q24, the predominant movement has been downward, with the largest quarter-over-quarter decline observed in 2Q25.\n",
            "\n",
            "This general decline in NIM can typically be attributed to rising funding costs (e.g., higher deposit rates driven by competitive pressures or a tightening interest rate environment) and/or increased competition in the lending market, which can put downward pressure on asset yields.\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "--- Running Reflective Agent for: Opex YoY 3-Year ---\n",
            "============================================================\n",
            "ðŸ¤– (V1) Agent: Running tools and calculations...\n",
            "ðŸ¤– Agent -> Planning 1 parallel tool call(s)...\n",
            "  - Queuing: trend_analysis({'values': [7090.0, 8056.0, 8895.0], 'periods': ['2022', '2023', '2024']})\n",
            "  âœ… trend_analysis returned: {'periods': ['2022', '2023', '2024'], 'values': [7090.0, 8056.0, 8895.0], 'period_changes': [13.62, 10.41], 'overall_trend': 'increasing', 'average_change': 12.02}\n",
            "ðŸ¤– Agent -> Sending tool results back to model...\n",
            "ðŸ¤– Agent -> Generating Final Answer after tool use.\n",
            "\n",
            "--- V1 DRAFT ---\n",
            "Operating expenses for the last three fiscal years are as follows:\n",
            "\n",
            "*   **2022:** $7,090 million\n",
            "*   **2023:** $8,056 million (a 13.62% increase from 2022)\n",
            "*   **2024:** $8,895 million (a 10.41% increase from 2023)\n",
            "\n",
            "The operating expenses show an increasing trend over the last three fiscal years, with an average year-on-year increase of 12.02%.\n",
            "----------------\n",
            "ðŸ§ (Reviewer) Agent: Critiquing V1 draft...\n",
            "\n",
            "--- CRITIQUE ---\n",
            "{\n",
            "  \"score\": 0.88,\n",
            "  \"strengths\": [\n",
            "    \"Comprehensive presentation of operating expenses for all requested years\",\n",
            "    \"Accurate calculation and inclusion of year-on-year percentage increases\",\n",
            "    \"Clear summary of the overall trend\"\n",
            "  ],\n",
            "  \"gaps\": [\n",
            "    \"Missing source citation for the financial data\",\n",
            "    \"Lacks brief contextual commentary on the drivers of the expense increases\"\n",
            "  ],\n",
            "  \"rewrite_brief\": \"Include a specific source for the financial data and add a concise explanation for the reasons behind the observed expense increases.\"\n",
            "}\n",
            "--------------\n",
            "âœï¸ (V2) Agent: Regenerating answer (V1 score was 0.88)...\n",
            "\n",
            "--- FINAL V2 ANSWER ---\n",
            "Operating expenses for the last three fiscal years are as follows:\n",
            "\n",
            "*   **2022:** $7,090 million\n",
            "*   **2023:** $8,056 million (a 13.62% increase from 2022)\n",
            "*   **2024:** $8,895 million (a 10.41% increase from 2023)\n",
            "\n",
            "The operating expenses show an increasing trend over the last three fiscal years, with an average year-on-year increase of 12.02%. This growth is primarily attributable to strategic investments in research and development, expansion into new operational markets, and rising personnel-related costs.\n",
            "\n",
            "*Source: Company's Annual Reports (Form 10-K)*\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "--- Running Reflective Agent for: Operating Efficiency Ratio ---\n",
            "============================================================\n",
            "ðŸ¤– (V1) Agent: Running tools and calculations...\n",
            "ðŸ¤– Agent -> Planning 1 parallel tool call(s)...\n",
            "  - Queuing: calculate_ratio({'ratio_name': 'Operating Efficiency Ratio for FY24', 'numerator': 8895.0, 'denominator': 22237.5})\n",
            "  âœ… calculate_ratio returned: {'ratio_name': 'Operating Efficiency Ratio for FY24', 'numerator': 8895.0, 'denominator': 22237.5, 'result': 40.0, 'formula': '8895.0 / 22237.5'}\n",
            "ðŸ¤– Agent -> Sending tool results back to model...\n",
            "ðŸ¤– Agent -> Planning 1 parallel tool call(s)...\n",
            "  - Queuing: calculate_ratio({'ratio_name': 'Operating Efficiency Ratio for FY23', 'numerator': 8056.0, 'denominator': 20140.0})\n",
            "  âœ… calculate_ratio returned: {'ratio_name': 'Operating Efficiency Ratio for FY23', 'numerator': 8056.0, 'denominator': 20140.0, 'result': 40.0, 'formula': '8056.0 / 20140.0'}\n",
            "ðŸ¤– Agent -> Sending tool results back to model...\n",
            "ðŸ¤– Agent -> Generating Final Answer after tool use.\n",
            "\n",
            "--- V1 DRAFT ---\n",
            "**For Fiscal Year 2022 (FY22):**\n",
            "\n",
            "From \"4Q22_performance_summary, Page 11\":\n",
            "*   Total Operating Expenses (Opex) for Year 2022 = $7,090 million.\n",
            "\n",
            "However, a clear, overall \"Cost / income (%)\" for the *full fiscal year 2022* is not explicitly provided in the given context. While there are mentions of quarterly cost-income ratios and a cost-income ratio for the second half *excluding specific items*, there is no definitive full-year ratio or operating income provided to calculate the Operating Efficiency Ratio for FY22 without making assumptions not supported by the context.\n",
            "\n",
            "Therefore, I can only provide the Operating Efficiency Ratio for FY24 and FY23.\n",
            "\n",
            "**Operating Efficiency Ratios:**\n",
            "\n",
            "*   **For Fiscal Year 2024 (FY24):**\n",
            "    *   Total Operating Expenses = S$8,895 million\n",
            "    *   Operating Income = S$22,237.5 million\n",
            "    *   Operating Efficiency Ratio = (S$8,895 million / S$22,237.5 million) * 100 = **40%**\n",
            "\n",
            "*   **For Fiscal Year 2023 (FY23):**\n",
            "    *   Total Operating Expenses = S$8,056 million\n",
            "    *   Operating Income = S$20,140 million\n",
            "    *   Operating Efficiency Ratio = (S$8,056 million / S$20,140 million) * 100 = **40%**\n",
            "----------------\n",
            "ðŸ§ (Reviewer) Agent: Critiquing V1 draft...\n",
            "\n",
            "--- CRITIQUE ---\n",
            "{\n",
            "  \"score\": 0.85,\n",
            "  \"strengths\": [\n",
            "    \"Accurate calculations for years provided\",\n",
            "    \"Clear presentation of working and formula\",\n",
            "    \"Explicitly addresses the inability to provide data for FY22\"\n",
            "  ],\n",
            "  \"gaps\": [\n",
            "    \"Missing calculation for one of the three requested fiscal years\",\n",
            "    \"Lack of comparative analysis and interpretation of the stable ratios\",\n",
            "    \"Inconsistent citation of data sources for all figures\"\n",
            "  ],\n",
            "  \"rewrite_brief\": \"Add period-over-period comparison and interpretation of the ratios.\"\n",
            "}\n",
            "--------------\n",
            "âœï¸ (V2) Agent: Regenerating answer (V1 score was 0.85)...\n",
            "\n",
            "--- FINAL V2 ANSWER ---\n",
            "Here is the corrected answer, addressing the manager's critique:\n",
            "\n",
            "**Operating Efficiency Ratios for Fiscal Years 2024, 2023, and 2022**\n",
            "\n",
            "The Operating Efficiency Ratio (Opex Ã· Operating Income) has been calculated for the last three fiscal years where data is available. The ratio remained consistent at 40.0% for FY24 and FY23, indicating stable operational efficiency. The ratio for FY22 cannot be calculated due to the unavailability of full-year operating income.\n",
            "\n",
            "---\n",
            "\n",
            "**1. Detailed Calculations:**\n",
            "\n",
            "*   **For Fiscal Year 2024 (FY24):**\n",
            "    *   Total Operating Expenses (Opex) = S$8,895 million (Source: [FY24 Annual Report/Financial Statement, Page X])\n",
            "    *   Operating Income = S$22,237.5 million (Source: [FY24 Annual Report/Financial Statement, Page Y])\n",
            "    *   Operating Efficiency Ratio = (S$8,895 million / S$22,237.5 million) * 100 = **40.0%**\n",
            "\n",
            "*   **For Fiscal Year 2023 (FY23):**\n",
            "    *   Total Operating Expenses (Opex) = S$8,056 million (Source: [FY23 Annual Report/Financial Statement, Page X])\n",
            "    *   Operating Income = S$20,140 million (Source: [FY23 Annual Report/Financial Statement, Page Y])\n",
            "    *   Operating Efficiency Ratio = (S$8,056 million / S$20,140 million) * 100 = **40.0%**\n",
            "\n",
            "*   **For Fiscal Year 2022 (FY22):**\n",
            "    *   Total Operating Expenses (Opex) = S$7,090 million (Source: \"4Q22_performance_summary, Page 11\")\n",
            "    *   The full fiscal year operating income for 2022 is not explicitly provided in the available context. While quarterly and half-yearly cost-income ratios are mentioned (excluding specific items), a definitive full-year operating income figure required for this calculation is unavailable without making unsupported assumptions. Therefore, the Operating Efficiency Ratio for FY22 cannot be calculated with the provided information.\n",
            "\n",
            "---\n",
            "\n",
            "**2. Period-over-Period Comparison and Interpretation:**\n",
            "\n",
            "The Operating Efficiency Ratio for Fiscal Year 2024 and Fiscal Year 2023 has remained consistent at **40.0%**. This stability indicates a maintained level of operational efficiency where for every S$1 of operating income generated, S$0.40 was spent on operating expenses in both periods.\n",
            "\n",
            "Despite a significant year-over-year increase in both Total Operating Expenses (from S$8,056 million in FY23 to S$8,895 million in FY24) and Operating Income (from S$20,140 million in FY23 to S$22,237.5 million in FY24), their proportional relationship has been consistently maintained. This suggests that the company's cost growth has been in line with its income growth, reflecting strong and predictable cost management relative to its expanding operations. A stable Operating Efficiency Ratio like this is generally a positive indicator, demonstrating the business's ability to scale its operations without a disproportionate increase in its cost base.\n",
            "-----------------\n",
            "\n",
            "\n",
            "==================================================\n",
            "FINAL AGENTIC PERFORMANCE LOGS\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        Query  T_retrieve (sec)  T_rerank (ms)  \\\n",
              "0         NIM Quarterly Trend          0.068707       0.232836   \n",
              "1             Opex YoY 3-Year          0.064559       0.238648   \n",
              "2  Operating Efficiency Ratio          0.031275       0.165330   \n",
              "\n",
              "   T_reason (sec)  T_total (sec) Tokens CacheHits            Tools  \n",
              "0        6.946093       7.015135   8946         0   trend_analysis  \n",
              "1        6.436687       6.501564   9811         0   trend_analysis  \n",
              "2       29.056873      29.088337  12079         0  calculate_ratio  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4270435-110e-43c9-85fc-3960837f91d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>T_retrieve (sec)</th>\n",
              "      <th>T_rerank (ms)</th>\n",
              "      <th>T_reason (sec)</th>\n",
              "      <th>T_total (sec)</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>CacheHits</th>\n",
              "      <th>Tools</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NIM Quarterly Trend</td>\n",
              "      <td>0.068707</td>\n",
              "      <td>0.232836</td>\n",
              "      <td>6.946093</td>\n",
              "      <td>7.015135</td>\n",
              "      <td>8946</td>\n",
              "      <td>0</td>\n",
              "      <td>trend_analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Opex YoY 3-Year</td>\n",
              "      <td>0.064559</td>\n",
              "      <td>0.238648</td>\n",
              "      <td>6.436687</td>\n",
              "      <td>6.501564</td>\n",
              "      <td>9811</td>\n",
              "      <td>0</td>\n",
              "      <td>trend_analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Operating Efficiency Ratio</td>\n",
              "      <td>0.031275</td>\n",
              "      <td>0.165330</td>\n",
              "      <td>29.056873</td>\n",
              "      <td>29.088337</td>\n",
              "      <td>12079</td>\n",
              "      <td>0</td>\n",
              "      <td>calculate_ratio</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4270435-110e-43c9-85fc-3960837f91d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4270435-110e-43c9-85fc-3960837f91d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4270435-110e-43c9-85fc-3960837f91d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a5b3707-0773-4e55-b296-4434bc99aa04\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a5b3707-0773-4e55-b296-4434bc99aa04')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a5b3707-0773-4e55-b296-4434bc99aa04 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_af6545c7-25ce-402f-9ef2-26e336004942\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('logs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_af6545c7-25ce-402f-9ef2-26e336004942 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('logs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "logs",
              "summary": "{\n  \"name\": \"logs\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NIM Quarterly Trend\",\n          \"Opex YoY 3-Year\",\n          \"Operating Efficiency Ratio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_retrieve (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02051922691549929,\n        \"min\": 0.03127479553222656,\n        \"max\": 0.06870722770690918,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06870722770690918,\n          0.0645589828491211,\n          0.03127479553222656\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_rerank (ms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04075612170695135,\n        \"min\": 0.1653299987083301,\n        \"max\": 0.23864799732109532,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.23283600239665247,\n          0.23864799732109532,\n          0.1653299987083301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_reason (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.915229734188763,\n        \"min\": 6.436686575998465,\n        \"max\": 29.056873164001445,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.946092563001002,\n          6.436686575998465,\n          29.056873164001445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T_total (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.894781382774049,\n        \"min\": 6.501564292000694,\n        \"max\": 29.088337244000286,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7.015135072000703,\n          6.501564292000694,\n          29.088337244000286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokens\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 8946,\n        \"max\": 12079,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          8946,\n          9811,\n          12079\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CacheHits\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tools\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"calculate_ratio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š PERFORMANCE SUMMARY:\n",
            "Average Response Time: 14.202s\n",
            "P95 Response Time: 26.881s\n",
            "Average Tokens Used: 10279\n",
            "Fastest Query: Opex YoY 3-Year (6.502s)\n",
            "Slowest Query: Operating Efficiency Ratio (29.088s)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import asyncio\n",
        "import json\n",
        "import re\n",
        "import functools\n",
        "from tabulate import tabulate\n",
        "import google.generativeai as genai\n",
        "from google.ai import generativelanguage as glm\n",
        "\n",
        "# --- 0. Initialize Logs DataFrame ---\n",
        "logs = pd.DataFrame(columns=[\n",
        "    'Query', 'T_retrieve (sec)', 'T_rerank (ms)', 'T_reason (sec)',\n",
        "    'T_total (sec)', 'Tokens', 'CacheHits', 'Tools'\n",
        "])\n",
        "\n",
        "# --- 1. Define Critique & Regeneration Agents ---\n",
        "critique_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "regenerate_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "def parse_gemini_json(raw_text: str) -> dict:\n",
        "    \"\"\"Extracts and parses JSON from Gemini's markdown response.\"\"\"\n",
        "    try:\n",
        "        match = re.search(r\"```json\\n(.*?)\\n```\", raw_text, re.DOTALL)\n",
        "        if match:\n",
        "            json_str = match.group(1)\n",
        "        else:\n",
        "            json_str = raw_text.strip()\n",
        "            if not json_str.startswith('{'):\n",
        "                json_str = '{' + json_str.split('{', 1)[-1]\n",
        "            if not json_str.endswith('}'):\n",
        "                json_str = json_str.rsplit('}', 1)[0] + '}'\n",
        "        return json.loads(json_str)\n",
        "    except Exception as e:\n",
        "        print(f\"JSON Parse Error: {e}\\nRaw Text: {raw_text}\")\n",
        "        return {\"error\": \"Failed to parse critique JSON.\"}\n",
        "\n",
        "def critique_financial_answer(query: str, v1_answer: str) -> dict:\n",
        "    \"\"\"Reviewer agent that critiques the V1 answer.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a meticulous senior financial controller. Review this draft answer.\n",
        "Respond ONLY with a JSON object in the EXACT format below.\n",
        "\n",
        "CRITICAL: The score must be between 0.0 and 1.0 (where 0.0 = terrible, 1.0 = perfect).\n",
        "```json\n",
        "{{\"score\": 0.85, \"strengths\": [\"Accurate numbers\", \"Good citations\"], \"gaps\": [\"Missing trend analysis\"], \"rewrite_brief\": \"Add period-over-period comparison\"}}\n",
        "```\n",
        "\n",
        "Query: {query}\n",
        "V1 Draft: {v1_answer}\n",
        "\n",
        "Provide your JSON critique with a score between 0.0 and 1.0:\n",
        "\"\"\"\n",
        "    config = genai.GenerationConfig(response_mime_type=\"application/json\")\n",
        "    response = critique_model.generate_content(prompt, generation_config=config)\n",
        "    critique = parse_gemini_json(response.text)\n",
        "\n",
        "    # Ensure score is between 0.0 and 1.0\n",
        "    if \"score\" in critique:\n",
        "        score = critique[\"score\"]\n",
        "        if score > 1.0:\n",
        "            critique[\"score\"] = score / 10.0  # Normalize if out of range\n",
        "\n",
        "    return critique\n",
        "\n",
        "def regenerate_final_answer(query: str, v1_answer: str, critique: dict) -> str:\n",
        "    \"\"\"Regeneration agent that creates the V2 answer.\"\"\"\n",
        "    critique_str = json.dumps(critique, indent=2)\n",
        "    prompt = f\"\"\"\n",
        "You are a junior analyst. Your manager critiqued your V1 draft.\n",
        "Rewrite the answer to address the critique. Produce only the final, corrected answer.\n",
        "\n",
        "Query: {query}\n",
        "V1 Draft (has errors): {v1_answer}\n",
        "Manager's Critique: {critique_str}\n",
        "\n",
        "Provide the polished, corrected Final Answer:\n",
        "\"\"\"\n",
        "    response = regenerate_model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# --- 2. Define the Core Tool-Calling Agent (V1) ---\n",
        "\n",
        "async def run_agentic_pipeline(query: str, query_name: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Runs the RAG pipeline using a plan-then-act agentic loop with PARALLEL TOOL CALLS.\n",
        "    \"\"\"\n",
        "    global logs\n",
        "    timings = {}\n",
        "    tools_invoked = []\n",
        "    total_tokens = 0\n",
        "    start_total = time.perf_counter()\n",
        "\n",
        "    retrieved_docs = cfo_rag.hybrid_retrieve(query, top_k=top_k)\n",
        "    timings['T_retrieve'] = cfo_rag.metrics.get('T_retrieve', 0)\n",
        "    timings['T_rerank'] = cfo_rag.metrics.get('T_rerank', 0)\n",
        "\n",
        "    if not retrieved_docs:\n",
        "        return {\"error\": \"No documents retrieved.\"}\n",
        "\n",
        "    context = \"\\n\".join([f\"Source {doc['citation']}: {doc['text']}\" for doc in retrieved_docs])\n",
        "    start_reasoning = time.perf_counter()\n",
        "\n",
        "    chat = llm_model.start_chat(history=[\n",
        "        {\"role\": \"user\", \"parts\": [\n",
        "            f\"You are an expert financial analyst. Answer the user's query based *only* on the provided context. \"\n",
        "            f\"If the query requires calculation (like a ratio or trend), you *must* use your tools. \"\n",
        "            f\"After using tools, synthesize the results into a clear final answer. \"\n",
        "            f\"Do not make up numbers.\\n\\n\"\n",
        "            f\"--- CONTEXT ---\\n{context}\\n\\n\"\n",
        "            f\"--- QUERY ---\\n{query}\"\n",
        "        ]}\n",
        "    ])\n",
        "\n",
        "    final_answer = \"Agent loop started but did not produce an answer.\"\n",
        "\n",
        "    for turn in range(5):  # Loop limit\n",
        "        # Don't send \"Continue.\" on first turn - the initial message is enough\n",
        "        if turn == 0:\n",
        "            response = chat.send_message(\"Please answer the query using tools if needed.\", tools=gemini_tools)\n",
        "        else:\n",
        "            response = chat.send_message(\"Continue with your answer.\", tools=gemini_tools)\n",
        "\n",
        "        try:\n",
        "            total_tokens += response.usage_metadata.total_token_count\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Check for function calls first\n",
        "        function_calls = [part.function_call for part in response.candidates[0].content.parts if part.function_call]\n",
        "\n",
        "        if function_calls:\n",
        "            print(f\"Agent -> Planning {len(function_calls)} parallel tool call(s)...\")\n",
        "            tool_response_parts = []\n",
        "            tasks = []\n",
        "\n",
        "            for fc in function_calls:\n",
        "                tool_name = fc.name\n",
        "                tool_args = {k: v for k, v in fc.args.items()}\n",
        "                tools_invoked.append(tool_name)\n",
        "                print(f\"  - Queuing: {tool_name}({tool_args})\")\n",
        "\n",
        "                if tool_name in tool_function_map:\n",
        "                    loop = asyncio.get_event_loop()\n",
        "                    func = functools.partial(tool_function_map[tool_name], **tool_args)\n",
        "                    task = loop.run_in_executor(None, func)\n",
        "                    tasks.append((tool_name, task))\n",
        "                else:\n",
        "                    # Tool not found - create error response part\n",
        "                    tool_response_parts.append(\n",
        "                        glm.Part(\n",
        "                            function_response=glm.FunctionResponse(\n",
        "                                name=tool_name,\n",
        "                                response={\"error\": \"Tool not found\"}\n",
        "                            )\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            # Execute tool calls in parallel\n",
        "            results = await asyncio.gather(*[task for _, task in tasks])\n",
        "\n",
        "            # Build proper FunctionResponse Parts\n",
        "            for i, tool_result in enumerate(results):\n",
        "                tool_name = tasks[i][0]\n",
        "                print(f\"  {tool_name} returned: {tool_result}\")\n",
        "                tool_response_parts.append(\n",
        "                    glm.Part(\n",
        "                        function_response=glm.FunctionResponse(\n",
        "                            name=tool_name,\n",
        "                            response={\"result\": tool_result}\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            # Send tool results back to the model\n",
        "            print(\"Agent -> Sending tool results back to model...\")\n",
        "            response = chat.send_message(tool_response_parts)\n",
        "\n",
        "            # After sending tool results, check if model has text response\n",
        "            try:\n",
        "                if response.text and response.text.strip():\n",
        "                    print(\"Agent -> Generating Final Answer after tool use.\")\n",
        "                    final_answer = response.text.strip()\n",
        "                    break\n",
        "            except ValueError:\n",
        "                # No text yet, continue loop\n",
        "                continue\n",
        "\n",
        "        # Check if there's actual text in the response\n",
        "        else:\n",
        "            try:\n",
        "                if response.text and response.text.strip():\n",
        "                    print(\"Agent -> Generating Final Answer.\")\n",
        "                    final_answer = response.text.strip()\n",
        "                    break\n",
        "            except ValueError:\n",
        "                # No text available, check if we should continue\n",
        "                if turn < 4:  # Not the last turn\n",
        "                    print(\"Agent -> No text yet, continuing...\")\n",
        "                    continue\n",
        "                else:\n",
        "                    print(\"Agent -> Max turns reached without final answer\")\n",
        "                    final_answer = \"Agent completed tool calls but did not generate a final text answer.\"\n",
        "                    break\n",
        "    else:\n",
        "        final_answer = \"Agent exceeded max turns.\"\n",
        "\n",
        "    timings['T_reason'] = time.perf_counter() - start_reasoning\n",
        "    timings['T_total'] = time.perf_counter() - start_total\n",
        "\n",
        "    new_log = {\n",
        "        'Query': query_name,\n",
        "        'T_retrieve (sec)': timings['T_retrieve'],\n",
        "        'T_rerank (ms)': timings['T_rerank'],\n",
        "        'T_reason (sec)': timings['T_reason'],\n",
        "        'T_total (sec)': timings['T_total'],\n",
        "        'Tokens': total_tokens,\n",
        "        'CacheHits': 0,\n",
        "        'Tools': \", \".join(list(set(tools_invoked))) if tools_invoked else 'None'\n",
        "    }\n",
        "    logs = pd.concat([logs, pd.DataFrame([new_log])], ignore_index=True)\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"citations\": [doc[\"citation\"] for doc in retrieved_docs],\n",
        "        \"answer\": final_answer,\n",
        "        \"tools_used\": list(set(tools_invoked))\n",
        "    }\n",
        "\n",
        "# --- 3. Define the Master \"Reflective\" Pipeline (V2) ---\n",
        "\n",
        "async def run_full_reflective_pipeline(query: str, query_name: str, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Runs the full Tool-Calling -> Critique -> Reflection pipeline.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\\n--- Running Reflective Agent for: {query_name} ---\\n{'='*60}\")\n",
        "\n",
        "    # Step 1: Get V1 Draft\n",
        "    print(\"(V1) Agent: Running tools and calculations...\")\n",
        "    v1_result = await run_agentic_pipeline(query, query_name, top_k)\n",
        "    v1_answer = v1_result['answer']\n",
        "    print(f\"\\n--- V1 DRAFT ---\\n{v1_answer}\\n----------------\")\n",
        "\n",
        "    # Step 2: Get Critique\n",
        "    print(\"(Reviewer) Agent: Critiquing V1 draft...\")\n",
        "    critique = critique_financial_answer(query, v1_answer)\n",
        "    print(f\"\\n--- CRITIQUE ---\\n{json.dumps(critique, indent=2)}\\n--------------\")\n",
        "\n",
        "    # BUG FIX: Check score is valid before comparison\n",
        "    score = critique.get(\"score\", 0.0)\n",
        "    if score >= 0.95:\n",
        "        print(f\"(Reviewer) Agent: V1 answer is excellent (score: {score}). No rewrite needed.\")\n",
        "        return v1_result\n",
        "\n",
        "    # Step 3: Get V2 Answer\n",
        "    print(f\"(V2) Agent: Regenerating answer (V1 score was {score})...\")\n",
        "    final_answer = regenerate_final_answer(query, v1_answer, critique)\n",
        "    print(f\"\\n--- FINAL V2 ANSWER ---\\n{final_answer}\\n-----------------\")\n",
        "\n",
        "    v1_result['answer'] = final_answer\n",
        "    v1_result['critique'] = critique\n",
        "    return v1_result\n",
        "\n",
        "print(\"âœ… All Optimized Agent definitions are loaded.\")\n",
        "\n",
        "# =================================================================\n",
        "# --- 4. Define and Run the Optimized Benchmark ---\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=== Starting OPTIMIZED AGENT Benchmark Run ===\\n\")\n",
        "\n",
        "# Define an async function to run all benchmarks\n",
        "async def run_all_benchmarks():\n",
        "    all_results = []\n",
        "    for q in benchmark_queries:\n",
        "        result = await run_full_reflective_pipeline(\n",
        "            q[\"query\"],\n",
        "            q[\"name\"]\n",
        "        )\n",
        "        all_results.append(result)\n",
        "    return all_results\n",
        "\n",
        "# --- Run the Benchmark ---\n",
        "final_benchmark_results = await run_all_benchmarks()\n",
        "\n",
        "# --- Display Final Logs & Summary ---\n",
        "print(\"\\n\\n\" + \"=\"*50)\n",
        "print(\"FINAL AGENTIC PERFORMANCE LOGS\")\n",
        "print(\"=\"*50)\n",
        "display(logs)\n",
        "\n",
        "if not logs.empty:\n",
        "    print(f\"\\nPERFORMANCE SUMMARY:\")\n",
        "    print(f\"Average Response Time: {logs['T_total (sec)'].mean():.3f}s\")\n",
        "    print(f\"P95 Response Time: {logs['T_total (sec)'].quantile(0.95):.3f}s\")\n",
        "    print(f\"Average Tokens Used: {logs['Tokens'].mean():.0f}\")\n",
        "    print(f\"Fastest Query: {logs.loc[logs['T_total (sec)'].idxmin(), 'Query']} ({logs['T_total (sec)'].min():.3f}s)\")\n",
        "    print(f\"Slowest Query: {logs.loc[logs['T_total (sec)'].idxmax(), 'Query']} ({logs['T_total (sec)'].max():.3f}s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Total Response Time per Query and Token Usage Barcharts for the PPT Submission\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3163da73"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure numeric types\n",
        "logs['T_total (sec)'] = logs['T_total (sec)'].astype(float)\n",
        "logs['T_generate (sec)'] = logs['T_generate (sec)'].astype(float)\n",
        "logs['T_retrieve (sec)'] = logs['T_retrieve (sec)'].astype(float)\n",
        "logs['T_rerank (ms)'] = logs['T_rerank (ms)'].astype(float)\n",
        "logs['Tokens'] = logs['Tokens'].astype(float)\n",
        "\n",
        "# ------------------------------------------\n",
        "# BAR CHART â€“ Total Response Time per Query\n",
        "# ------------------------------------------\n",
        "plt.figure(figsize=(7,4))\n",
        "bars = plt.bar(logs['Query'], logs['T_total (sec)'], color=['#2E86AB','#F6C85F','#6FB98F'])\n",
        "plt.title('Total Response Time per Query', fontsize=13, weight='bold')\n",
        "plt.ylabel('Total Time (seconds)')\n",
        "plt.xlabel('Query')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "# Label bars with values\n",
        "for bar in bars:\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "             f\"{bar.get_height():.2f}s\", ha='center', fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------\n",
        "# BAR CHART â€“ Token Usage per Query\n",
        "# ------------------------------------------\n",
        "plt.figure(figsize=(7,4))\n",
        "bars = plt.bar(logs['Query'], logs['Tokens'], color=['#F79D65','#84C318','#2D728F'])\n",
        "plt.title('Token Usage per Query', fontsize=13, weight='bold')\n",
        "plt.ylabel('Tokens Used')\n",
        "plt.xlabel('Query')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "# Label bars\n",
        "for bar in bars:\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 200,\n",
        "             f\"{int(bar.get_height())}\", ha='center', fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "3163da73",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3",
        "ExecuteTime": {
          "end_time": "2025-09-30T08:58:38.648719100Z",
          "start_time": "2025-09-30T08:58:38.642546300Z"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'logs' DataFrame is available from previous steps\n",
        "# Make sure logs DataFrame is accessible (if not defined globally elsewhere)\n",
        "try:\n",
        "    logs\n",
        "except NameError:\n",
        "    print(\"Logs DataFrame not found. Please run the benchmark first.\")\n",
        "    logs = pd.DataFrame() # Create empty DataFrame to avoid errors\n",
        "\n",
        "if not logs.empty:\n",
        "    # Calculate p50 and p95 latencies\n",
        "    latency_summary = logs.groupby('Query')['T_total (sec)'].agg(['median', lambda x: x.quantile(0.95)]).reset_index()\n",
        "    latency_summary.columns = ['Query', 'p50 Latency (sec)', 'p95 Latency (sec)']\n",
        "\n",
        "    print(\"\\n=== Latency Summary (p50 and p95) ===\")\n",
        "    print(tabulate(latency_summary, headers=\"keys\", tablefmt=\"github\"))\n",
        "\n",
        "    # Plotting Total Latency\n",
        "    plt.figure(figsize=(12, 7)) # Increase figure size\n",
        "    plt.bar(latency_summary['Query'], latency_summary['p50 Latency (sec)'], label='p50 Latency')\n",
        "    plt.bar(latency_summary['Query'], latency_summary['p95 Latency (sec)'] - latency_summary['p50 Latency (sec)'],\n",
        "            bottom=latency_summary['p50 Latency (sec)'], label='p95 Latency (additional)')\n",
        "    plt.ylabel('Latency (seconds)')\n",
        "    plt.title('Baseline Pipeline Latency (p50 and p95)')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.subplots_adjust(bottom=0.25) # Adjust bottom margin\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting breakdown of latencies\n",
        "    # Exclude T_ingest as it's done once\n",
        "    timing_cols = ['T_retrieve (sec)', 'T_rerank (ms)', 'T_generate (sec)']\n",
        "\n",
        "    # Convert ms to sec for plotting consistency\n",
        "    logs['T_rerank (sec)'] = logs['T_rerank (ms)'] / 1000\n",
        "    timing_cols_sec = ['T_retrieve (sec)', 'T_rerank (sec)', 'T_generate (sec)']\n",
        "\n",
        "\n",
        "    # Group by query and calculate mean for breakdown\n",
        "    timing_breakdown = logs.groupby('Query')[timing_cols_sec].mean().reset_index()\n",
        "\n",
        "    timing_breakdown.set_index('Query').plot(kind='bar', stacked=True, figsize=(12, 7))\n",
        "    plt.ylabel('Average Time (seconds)')\n",
        "    plt.title('Average Time Breakdown per Stage')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend(title='Stage', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.subplots_adjust(bottom=0.25) # Adjust bottom margin\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"No data in logs DataFrame to plot.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Evaluation\n",
        "\n",
        "**Objective:**  \n",
        "To assess the overall effectiveness and reliability of the Retrieval-Augmented Generation (RAG) pipeline across both retrieval and generation stages.  \n",
        "*These metrics are used for testing and justification purposes to evaluate model performance and design choices.*\n",
        "\n",
        "**Evaluation Metrics**\n",
        "\n",
        "### 1. Hit Rate (HR)\n",
        "Measures how often the correct or relevant document appears within the top-k retrieved results.  \n",
        "A higher Hit Rate indicates better retrieval accuracy.\n",
        "\n",
        "### 2. Mean Reciprocal Rank (MRR)\n",
        "Evaluates the ranking quality of retrieved documents by considering the position of the first relevant result.  \n",
        "Higher MRR values reflect more efficient ranking and prioritization of relevant context.\n",
        "\n",
        "### 3. Relevancy Score\n",
        "Quantifies the semantic similarity between the query and retrieved context.  \n",
        "This measures how contextually aligned the retrieved information is with the user query.\n",
        "\n",
        "### 4. Precision and Recall\n",
        "Used to evaluate the quality of generated responses in relation to retrieved context.  \n",
        "- **Precision**: Fraction of generated tokens grounded in retrieved evidence (factual accuracy).  \n",
        "- **Recall**: Fraction of relevant evidence successfully reflected in the generated answer (coverage).  \n",
        "Balanced precision and recall indicate a factually consistent and comprehensive response.\n"
      ],
      "metadata": {
        "id": "mpSZGCiao1AZ"
      },
      "id": "mpSZGCiao1AZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import re, math, statistics\n",
        "import pandas as pd\n",
        "\n",
        "display(Markdown(\"# RAG Evaluation\\n**Metrics to Evaluate RAG Pipeline (used for testing / justification purposes)**\"))\n",
        "\n",
        "# Verify pipeline has documents\n",
        "if not hasattr(cfo_rag, 'documents') or len(cfo_rag.documents) == 0:\n",
        "    raise RuntimeError(\"Pipeline has no documents! Run ingestion first.\")\n",
        "\n",
        "pipeline = cfo_rag\n",
        "print(f\"Using pipeline with {len(pipeline.documents)} documents\")\n",
        "\n",
        "# Initialize semantic model\n",
        "eval_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Test queries\n",
        "queries = [\n",
        "    \"What is DBS's Net Interest Margin for 2023?\",\n",
        "    \"What was DBS's CET1 ratio in 2023?\",\n",
        "    \"Show DBS operating expenses for 2024\",\n",
        "    \"Calculate DBS cost-to-income ratio for FY2023\",\n",
        "    \"What is DBS's total income growth rate in 2023?\"\n",
        "]\n",
        "\n",
        "# Helper functions\n",
        "_stop = set(\"a an the of for and to in on with by from as is was were be been are that this these those it its at which\".split())\n",
        "\n",
        "def tokenise(t):\n",
        "    return [x for x in re.sub(r\"[^\\w\\s]\", \" \", str(t).lower()).split() if x and x not in _stop]\n",
        "\n",
        "def overlap_score(q, d):\n",
        "    \"\"\"Token overlap (backup method)\"\"\"\n",
        "    q, d = set(tokenise(q)), set(tokenise(d))\n",
        "    return len(q & d) / len(q | d) if q and d else 0.0\n",
        "\n",
        "def semantic_relevance(query, doc_text):\n",
        "    \"\"\"Semantic similarity (preferred method)\"\"\"\n",
        "    q_emb = eval_model.encode(query, convert_to_tensor=True)\n",
        "    d_emb = eval_model.encode(doc_text, convert_to_tensor=True)\n",
        "    return util.cos_sim(q_emb, d_emb).item()\n",
        "\n",
        "def retrieve_docs(pipeline, query, k=5):\n",
        "    \"\"\"Retrieve docs from pipeline (no fallback)\"\"\"\n",
        "    docs = []\n",
        "    try:\n",
        "        if hasattr(pipeline, \"hybrid_retrieve\"):\n",
        "            docs = pipeline.hybrid_retrieve(query, top_k=k)\n",
        "        elif hasattr(pipeline, \"retrieve\"):\n",
        "            docs = pipeline.retrieve(query, top_k=k)\n",
        "    except Exception as e:\n",
        "        print(f\"Retrieval error for query '{query}': {e}\")\n",
        "        return []\n",
        "\n",
        "    # Test for actual retrieval\n",
        "    if not docs:\n",
        "        print(f\"No docs retrieved for query: {query}\")\n",
        "        return []\n",
        "\n",
        "    # Type check\n",
        "    cleaned = []\n",
        "    for d in docs:\n",
        "        if isinstance(d, str):\n",
        "            cleaned.append({\"text\": d})\n",
        "        elif isinstance(d, dict) and \"text\" in d:\n",
        "            cleaned.append(d)\n",
        "        else:\n",
        "            cleaned.append({\"text\": str(d)})\n",
        "    return cleaned\n",
        "\n",
        "def compute_metrics(pipeline, queries, k=5, use_semantic=True, thr=0.4):\n",
        "    \"\"\"\n",
        "    Compute retrieval metrics using semantic similarity (preferred) or token overlap\n",
        "    \"\"\"\n",
        "    hits3 = hits5 = mrr_sum = 0\n",
        "    relevancies = []\n",
        "\n",
        "    scoring_fn = semantic_relevance if use_semantic else overlap_score\n",
        "    score_type = \"semantic\" if use_semantic else \"overlap\"\n",
        "\n",
        "    for q in queries:\n",
        "        docs = retrieve_docs(pipeline, q, k)\n",
        "\n",
        "        if not docs:\n",
        "            relevancies.append(0)\n",
        "            print(f\"No docs retrieved for: {q}\")\n",
        "            continue\n",
        "\n",
        "        scores = [scoring_fn(q, d[\"text\"]) for d in docs]\n",
        "        relevancies.append(statistics.mean(scores) if scores else 0)\n",
        "\n",
        "        found = next((i for i, s in enumerate(scores) if s >= thr), None)\n",
        "        if found is not None:\n",
        "            if found < 3: hits3 += 1\n",
        "            hits5 += 1\n",
        "            mrr_sum += 1 / (found + 1)\n",
        "            print(f\"Found relevant doc at position {found+1} for: {q[:50]}... (score: {scores[found]:.3f})\")\n",
        "        else:\n",
        "            print(f\"No relevant doc found for: {q} (max score: {max(scores):.3f}, threshold: {thr})\")\n",
        "\n",
        "    n = len(queries)\n",
        "    return {\n",
        "        \"HitRate@3\": round(hits3 / n, 3),\n",
        "        \"HitRate@5\": round(hits5 / n, 3),\n",
        "        \"MRR@10\": round(mrr_sum / n, 3),\n",
        "        \"Relevancy\": round(statistics.mean(relevancies), 3),\n",
        "        \"ScoreType\": score_type\n",
        "    }\n",
        "\n",
        "def detect_hallucination(answer, docs):\n",
        "    \"\"\"Check if answer is grounded in retrieved docs\"\"\"\n",
        "    a = set(tokenise(answer))\n",
        "    c = set(tokenise(\" \".join(d.get(\"text\",\"\") for d in docs)))\n",
        "    if not a or not c:\n",
        "        return {\"Precision\": 0.0, \"Recall\": 0.0}\n",
        "    match = a & c\n",
        "    return {\n",
        "        \"Precision\": round(len(match) / len(a), 3),  # How much of answer is in docs?\n",
        "        \"Recall\": round(len(match) / len(c), 3)      # How much of docs is in answer?\n",
        "    }\n",
        "\n",
        "# Run Evaluation with Semantic Scoring\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RUNNING RAG EVALUATION (Semantic Scoring)\")\n",
        "print(\"=\"*60)\n",
        "metrics = compute_metrics(pipeline, queries, k=5, use_semantic=True, thr=0.4)\n",
        "\n",
        "# Test hallucination on first query\n",
        "sample_q = queries[0]\n",
        "docs = retrieve_docs(pipeline, sample_q)\n",
        "\n",
        "# Try to get answer from pipeline\n",
        "ans = None\n",
        "for method in (\"generate_answer\", \"answer\", \"call\"):\n",
        "    if hasattr(pipeline, method):\n",
        "        try:\n",
        "            ans = getattr(pipeline, method)(sample_q, docs)\n",
        "            break\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Fallback answer for hallucination test only\n",
        "if not ans:\n",
        "    ans = \"DBS's Net Interest Margin was 2.15% in 2023.\"\n",
        "    print(f\"Using fallback answer for hallucination test\")\n",
        "\n",
        "hall = detect_hallucination(ans, docs)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BASELINE METRICS\")\n",
        "print(\"=\"*60)\n",
        "df = pd.DataFrame([\n",
        "    {\"Metric\": \"HitRate@3\", \"Baseline\": metrics[\"HitRate@3\"]},\n",
        "    {\"Metric\": \"HitRate@5\", \"Baseline\": metrics[\"HitRate@5\"]},\n",
        "    {\"Metric\": \"MRR@10\", \"Baseline\": metrics[\"MRR@10\"]},\n",
        "    {\"Metric\": \"Relevancy\", \"Baseline\": metrics[\"Relevancy\"]},\n",
        "    {\"Metric\": \"Precision (Hallucination)\", \"Baseline\": hall[\"Precision\"]},\n",
        "    {\"Metric\": \"Recall (Hallucination)\", \"Baseline\": hall[\"Recall\"]}\n",
        "])\n",
        "display(df)\n",
        "\n",
        "print(f\"\\nScoring Method: {metrics['ScoreType']}\")"
      ],
      "metadata": {
        "id": "09BJfpsvptpn"
      },
      "id": "09BJfpsvptpn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM and Embedding Model Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "CEW0D97i2of8"
      },
      "id": "CEW0D97i2of8"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "display(Markdown(\"# LLM Testing\\n**Model Comparison (Controlled + Real Data)**\"))\n",
        "\n",
        "import os, time, re, numpy as np, pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Helper Functions\n",
        "def cosine_sim(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def tokens(x):\n",
        "    return set(re.findall(r\"\\w+\", x.lower()))\n",
        "\n",
        "def overlap_pr(ans, src):\n",
        "    a, c = tokens(ans), tokens(src)\n",
        "    if not a or not c:\n",
        "        return (0, 0)\n",
        "    m = a & c\n",
        "    return (len(m) / len(a), len(m) / len(c))\n",
        "\n",
        "def count_tokens(text):\n",
        "    return len(re.findall(r\"\\w+\", text))\n",
        "\n",
        "# ========================================\n",
        "# 1. EMBEDDING TEST (CONTROLLED)\n",
        "# ========================================\n",
        "print(\"\\n=== Embedding Model Comparison (Controlled Test) ===\")\n",
        "print(\"Purpose: Isolate embedding quality with clear ground truth\\n\")\n",
        "\n",
        "# Controlled synthetic documents\n",
        "documents = [\n",
        "    \"DBS reported a Net Interest Margin (NIM) of 2.15% for full year 2023, up from 2.03% in 2022.\",\n",
        "    \"DBS maintained a Common Equity Tier 1 (CET1) capital ratio of 15.9% as of December 2023.\",\n",
        "    \"DBS achieved record net profit of SGD 10.3 billion in 2023, driven by higher net interest income.\"\n",
        "]\n",
        "\n",
        "queries = [\n",
        "    \"What is DBS's Net Interest Margin for 2023?\",\n",
        "    \"What was DBS's CET1 ratio in 2023?\"\n",
        "]\n",
        "\n",
        "ground_truth = [0, 1]\n",
        "\n",
        "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Test MiniLM\n",
        "t0 = time.perf_counter()\n",
        "emb_d_st = st_model.encode(documents)\n",
        "emb_q_st = st_model.encode(queries)\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "# Test OpenAI\n",
        "openai_emb_d = []\n",
        "openai_emb_q = []\n",
        "t2 = time.perf_counter()\n",
        "for d in documents:\n",
        "    e = openai_client.embeddings.create(model=\"text-embedding-3-small\", input=d)\n",
        "    openai_emb_d.append(e.data[0].embedding)\n",
        "for q in queries:\n",
        "    e = openai_client.embeddings.create(model=\"text-embedding-3-small\", input=q)\n",
        "    openai_emb_q.append(e.data[0].embedding)\n",
        "t3 = time.perf_counter()\n",
        "\n",
        "def retrieval_eval(q_embs, d_embs, ground_truth_indices):\n",
        "    hits = []\n",
        "    mrr_scores = []\n",
        "    relevancies = []\n",
        "\n",
        "    for i, q in enumerate(q_embs):\n",
        "        sims = [cosine_sim(q, d) for d in d_embs]\n",
        "        idx = np.argsort(sims)[::-1]\n",
        "        correct_idx = ground_truth_indices[i]\n",
        "        hits.append(1 if idx[0] == correct_idx else 0)\n",
        "        try:\n",
        "            rank = list(idx).index(correct_idx) + 1\n",
        "            mrr_scores.append(1 / rank)\n",
        "        except ValueError:\n",
        "            mrr_scores.append(0)\n",
        "        relevancies.append(sims[correct_idx])\n",
        "\n",
        "    return {\n",
        "        \"HitRate\": np.mean(hits),\n",
        "        \"MRR\": np.mean(mrr_scores),\n",
        "        \"Relevancy\": np.mean(relevancies)\n",
        "    }\n",
        "\n",
        "res_minilm = retrieval_eval(emb_q_st, emb_d_st, ground_truth)\n",
        "res_openai = retrieval_eval(openai_emb_q, openai_emb_d, ground_truth)\n",
        "\n",
        "emb_table = pd.DataFrame([\n",
        "    {\n",
        "        \"Model\": \"all-MiniLM-L6-v2\",\n",
        "        \"EncodeTime(s)\": round(t1 - t0, 3),\n",
        "        \"Hit@1\": round(res_minilm[\"HitRate\"], 3),\n",
        "        \"MRR\": round(res_minilm[\"MRR\"], 3),\n",
        "        \"Relevancy\": round(res_minilm[\"Relevancy\"], 3)\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"text-embedding-3-small\",\n",
        "        \"EncodeTime(s)\": round(t3 - t2, 3),\n",
        "        \"Hit@1\": round(res_openai[\"HitRate\"], 3),\n",
        "        \"MRR\": round(res_openai[\"MRR\"], 3),\n",
        "        \"Relevancy\": round(res_openai[\"Relevancy\"], 3)\n",
        "    }\n",
        "])\n",
        "display(emb_table)\n",
        "\n",
        "speedup = (t3 - t2) / (t1 - t0)\n",
        "print(f\"\\nSpeed: MiniLM {speedup:.1f}x faster\")\n",
        "print(f\"Quality: Both achieve Hit@1 = {res_minilm['HitRate']:.1f}, {res_openai['HitRate']:.1f}\")\n",
        "\n",
        "# ========================================\n",
        "# 2. LLM TEST (REAL PIPELINE DATA)\n",
        "# ========================================\n",
        "print(\"\\n=== LLM Comparison (Real Pipeline Context) ===\")\n",
        "print(\"Purpose: Test generation quality with production-like retrieval\\n\")\n",
        "\n",
        "# Verify pipeline\n",
        "if not hasattr(cfo_rag, 'documents') or len(cfo_rag.documents) == 0:\n",
        "    raise RuntimeError(\"Pipeline has no documents!\")\n",
        "\n",
        "print(f\"Using CFO RAG pipeline ({len(cfo_rag.documents)} documents)\")\n",
        "\n",
        "NUM_RUNS = 3\n",
        "gemini_all_results = []\n",
        "gpt_all_results = []\n",
        "\n",
        "gem = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "for run in range(NUM_RUNS):\n",
        "    print(f\"Run {run + 1}/{NUM_RUNS}...\", end=\" \")\n",
        "\n",
        "    for query in queries:\n",
        "        # Retrieve real context\n",
        "        retrieved = cfo_rag.hybrid_retrieve(query, top_k=3)\n",
        "        if not retrieved:\n",
        "            continue\n",
        "\n",
        "        context = \"\\n\".join([doc[\"text\"] for doc in retrieved])\n",
        "        prompt = f\"{query}\\n\\nContext:\\n{context}\"\n",
        "\n",
        "        # Gemini\n",
        "        g_start = time.perf_counter()\n",
        "        g_response = gem.generate_content(prompt)\n",
        "        g_end = time.perf_counter()\n",
        "        g_text = g_response.text\n",
        "        g_p, g_r = overlap_pr(g_text, context)\n",
        "\n",
        "        gemini_all_results.append({\n",
        "            \"time\": g_end - g_start,\n",
        "            \"tokens\": count_tokens(g_text),\n",
        "            \"precision\": g_p,\n",
        "            \"recall\": g_r\n",
        "        })\n",
        "\n",
        "        # GPT-4o\n",
        "        o_start = time.perf_counter()\n",
        "        o_response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        o_end = time.perf_counter()\n",
        "        o_text = o_response.choices[0].message.content\n",
        "        o_p, o_r = overlap_pr(o_text, context)\n",
        "\n",
        "        gpt_all_results.append({\n",
        "            \"time\": o_end - o_start,\n",
        "            \"tokens\": count_tokens(o_text),\n",
        "            \"precision\": o_p,\n",
        "            \"recall\": o_r\n",
        "        })\n",
        "\n",
        "    print(\"Done\")\n",
        "\n",
        "# Average results\n",
        "avg_g_time = np.mean([r[\"time\"] for r in gemini_all_results])\n",
        "avg_o_time = np.mean([r[\"time\"] for r in gpt_all_results])\n",
        "avg_g_tokens = np.mean([r[\"tokens\"] for r in gemini_all_results])\n",
        "avg_o_tokens = np.mean([r[\"tokens\"] for r in gpt_all_results])\n",
        "avg_g_p = np.mean([r[\"precision\"] for r in gemini_all_results])\n",
        "avg_o_p = np.mean([r[\"precision\"] for r in gpt_all_results])\n",
        "avg_g_r = np.mean([r[\"recall\"] for r in gemini_all_results])\n",
        "avg_o_r = np.mean([r[\"recall\"] for r in gpt_all_results])\n",
        "\n",
        "llm_table = pd.DataFrame([\n",
        "    {\n",
        "        \"Model\": \"Gemini 2.5 Flash\",\n",
        "        \"Avg Time (s)\": round(avg_g_time, 3),\n",
        "        \"Avg Tokens\": int(avg_g_tokens),\n",
        "        \"Precision\": round(avg_g_p, 3),\n",
        "        \"Recall\": round(avg_g_r, 3)\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"GPT-4o-mini\",\n",
        "        \"Avg Time (s)\": round(avg_o_time, 3),\n",
        "        \"Avg Tokens\": int(avg_o_tokens),\n",
        "        \"Precision\": round(avg_o_p, 3),\n",
        "        \"Recall\": round(avg_o_r, 3)\n",
        "    }\n",
        "])\n",
        "\n",
        "display(llm_table)\n",
        "\n",
        "print(f\"\\nSpeed: {'Gemini' if avg_g_time < avg_o_time else 'GPT-4o'} faster by {abs(avg_g_time - avg_o_time):.3f}s\")\n",
        "print(f\"Tokens: {'Gemini' if avg_g_tokens < avg_o_tokens else 'GPT-4o'} more concise ({int(abs(avg_g_tokens - avg_o_tokens))} fewer)\")\n",
        "print(f\"Precision: {'Gemini' if avg_g_p > avg_o_p else 'GPT-4o'} higher by {abs(avg_g_p - avg_o_p):.3f}\")\n",
        "print(f\"Recall: {'Gemini' if avg_g_r > avg_o_r else 'GPT-4o'} higher by {abs(avg_g_r - avg_o_r):.3f}\")"
      ],
      "metadata": {
        "id": "P1RDoCZvqGi1"
      },
      "id": "P1RDoCZvqGi1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9e802a308ae488f94ff6dfd60cf50b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ef7975a28414ee4b7b45092d74b9c64",
              "IPY_MODEL_513979dfda264d11b08bac5951b6f599",
              "IPY_MODEL_43d8ab5582e74965837db5b8b7450057"
            ],
            "layout": "IPY_MODEL_64b0daeb496f4a6f959c2dd810e2b22f"
          }
        },
        "2ef7975a28414ee4b7b45092d74b9c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff93e2e6f1b4a41b64cabbe4e123a08",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7002d145df5c4faa88a01e46f19e9a39",
            "value": "Batches:â€‡100%"
          }
        },
        "513979dfda264d11b08bac5951b6f599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bc98f63858419eabed273cc9286807",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c43bc3acdae1438d9a509aa2275656f2",
            "value": 30
          }
        },
        "43d8ab5582e74965837db5b8b7450057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa135e14e604ddb91f513936896581c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70c478aadf0146479350f4dbdb7b0360",
            "value": "â€‡30/30â€‡[01:42&lt;00:00,â€‡â€‡1.56s/it]"
          }
        },
        "64b0daeb496f4a6f959c2dd810e2b22f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff93e2e6f1b4a41b64cabbe4e123a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7002d145df5c4faa88a01e46f19e9a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23bc98f63858419eabed273cc9286807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43bc3acdae1438d9a509aa2275656f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fa135e14e604ddb91f513936896581c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70c478aadf0146479350f4dbdb7b0360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}